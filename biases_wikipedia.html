<html><body>
<div class='bias'>
<h2>Availability heuristic</h2>
<a href='https://en.wikipedia.org/wiki/Availability_heuristic' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>availability heuristic</b>, also known as <b>availability bias</b>, is a mental shortcut that relies on immediate examples that come to a given person's mind when evaluating a specific topic, concept, method, or decision. This heuristic, operating on the notion that, if something can be recalled, it must be important, or at least more important than alternative solutions not as readily recalled, is inherently biased toward recently acquired information.
</p><p>The mental availability of an action's consequences is positively related to those consequences' perceived magnitude. In other words, the easier it is to recall the consequences of something, the greater those consequences are often perceived to be. Most notably, people often rely on the content of their recall if its implications are not called into question by the difficulty they have in recalling it.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Availability_heuristic'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Attentional bias</h2>
<a href='https://en.wikipedia.org/wiki/Attentional_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Attentional bias</b> refers to how a person's perception is affected by selective factors in their attention. Attentional biases may explain an individual's failure to consider alternative possibilities when occupied with an existing train of thought. For example, cigarette smokers have been shown to possess an attentional bias for smoking-related cues around them, due to their brain's altered reward sensitivity. Attentional bias has also been associated with clinically relevant symptoms such as anxiety and depression.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Attentional_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Illusory truth effect</h2>
<a href='https://en.wikipedia.org/wiki/Illusory_truth_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">

</p><p>The <b>illusory truth effect</b> (also known as the <b>illusion of truth effect</b>, <b>validity effect</b>, <b>truth effect</b>, or the <b>reiteration effect</b>) is the tendency to believe false information to be correct after repeated exposure. This phenomenon was first identified in a 1977 study at Villanova University and Temple University. When truth is assessed, people rely on whether the information is in line with their understanding or if it feels familiar. The first condition is logical, as people compare new information with what they already know to be true. Repetition makes statements easier to process relative to new, unrepeated statements, leading people to believe that the repeated conclusion is more truthful. The illusory truth effect has also been linked to hindsight bias, in which the recollection of confidence is skewed after the truth has been received.
</p><p>In a 2015 study, researchers discovered that familiarity can overpower rationality and that repetitively hearing that a certain statement is wrong can paradoxically cause it to feel right. Researchers observed the illusory truth effect's impact even on participants who knew the correct answer to begin with but were persuaded to believe otherwise through the repetition of a falsehood, to "processing fluency".
</p><p>The illusory truth effect plays a significant role in fields such as advertising, news media, political propaganda, and religious indoctrination.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Illusory_truth_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Mere–exposure effect</h2>
<a href='https://en.wikipedia.org/wiki/Mere-exposure_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>mere-exposure effect</b> is a psychological phenomenon by which people tend to develop a liking or disliking for things merely because they are familiar with them. In social psychology, this effect is sometimes called the <b>familiarity principle</b>. The effect has been demonstrated with many kinds of things, including words, Chinese characters, paintings, pictures of faces, geometric figures, and sounds. In studies of interpersonal attraction, the more often people see a person, the more pleasing and likeable they find that person.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Mere-exposure_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Context effect</h2>
<a href='https://en.wikipedia.org/wiki/Context_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>

<p>A <b>context effect</b> is an aspect of cognitive psychology that describes the influence of environmental factors on one's perception of a stimulus.  The impact of context effects is considered to be part of top-down design.  The concept is supported by the theoretical approach to perception known as constructive perception.  Context effects can impact our daily lives in many ways such as word recognition, learning abilities, memory, and object recognition.  It can have an extensive effect on marketing and consumer decisions.  For example, research has shown that the comfort level of the floor that shoppers are standing on while reviewing products can affect their assessments of product's quality, leading to higher assessments if the floor is comfortable and lower ratings if it is uncomfortable. Because of effects such as this, context effects are currently studied predominantly in marketing.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Context_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Cue–dependent forgetting</h2>
<a href='https://en.wikipedia.org/wiki/Cue-dependent_forgetting' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Cue-dependent forgetting</b>, or <b>retrieval failure</b>, is the failure to recall information without memory <i>cues</i>. The term either pertains to <i>semantic cues</i>, <i>state-dependent</i> cues or <i>context-dependent</i> cues.
</p><p>Upon performing a search for files in a computer, its memory is scanned for words. Relevant files containing this word or string of words are displayed. This is <i>not</i> how memory in the human mind works. Instead, information stored in the memory is retrieved by way of association with other memories. Some memories can not be recalled by simply thinking about them. Rather, one must think about something associated with it.
</p><p>For example, if someone tries and fails to recollect the memories they had about a vacation they went on, and someone mentions the fact that they hired a classic car during this vacation, this may make them remember all sorts of things from that trip, such as what they ate there, where they went and what books they read.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Cue-dependent_forgetting'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Mood–congruent memory bias</h2>
<a href='https://en.wikipedia.org/wiki/Mood_congruence' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In psychology, <b>mood congruence</b> is the consistency between a person's emotional state with the broader situations and circumstances being experienced by the person at that time. By contrast, <b>mood incongruence</b> occurs when the individual's reactions or emotional state appear to be in conflict with the situation. In the context of psychosis, hallucinations and delusions may be considered mood congruent (such as feelings of personal inadequacy, guilt, or worthlessness during a bipolar disorder depressive episode) or incongruent.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Mood_congruence'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Frequency illusion</h2>
<a href='https://en.wikipedia.org/wiki/Frequency_illusion' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>frequency illusion</b> (also known as the <b>Baader–Meinhof phenomenon</b>) is a cognitive bias in which a person notices a specific concept, word, or product more frequently after recently becoming aware of it.
</p><p>The name "Baader–Meinhof phenomenon" was coined in 1994 by Terry Mullen in a letter to the <i>St. Paul Pioneer Press</i>. The letter describes how, after mentioning the name of the German militant group Baader–Meinhof once, he kept noticing it. This led to other readers sharing their own experiences of the phenomenon, leading it to gain recognition. It was not until 2005, when Stanford linguistics professor Arnold Zwicky wrote about this effect on his blog, that the name "frequency illusion" was coined.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Frequency_illusion'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Baader–Meinhof Phenomenon</h2>
<a href='https://en.wikipedia.org/wiki/Frequency_illusion' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>frequency illusion</b> (also known as the <b>Baader–Meinhof phenomenon</b>) is a cognitive bias in which a person notices a specific concept, word, or product more frequently after recently becoming aware of it.
</p><p>The name "Baader–Meinhof phenomenon" was coined in 1994 by Terry Mullen in a letter to the <i>St. Paul Pioneer Press</i>. The letter describes how, after mentioning the name of the German militant group Baader–Meinhof once, he kept noticing it. This led to other readers sharing their own experiences of the phenomenon, leading it to gain recognition. It was not until 2005, when Stanford linguistics professor Arnold Zwicky wrote about this effect on his blog, that the name "frequency illusion" was coined.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Frequency_illusion'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Empathy gap</h2>
<a href='https://en.wikipedia.org/wiki/Empathy_gap' target='_blank'>Wikipedia Link</a>
<div class='content'><p>An <b>empathy gap</b>, sometimes referred to as an <b>empathy bias</b>, is a breakdown or reduction in empathy (the ability to recognize, understand, and share another's thoughts and feelings) where it might otherwise be expected to occur. Empathy gaps may occur due to a failure in the process of empathizing or as a consequence of stable personality characteristics, and may reflect either a lack of ability or motivation to empathize.
</p><p>Empathy gaps can be interpersonal (toward others) or intrapersonal (toward the self, e.g. when predicting one's own future preferences). A great deal of social psychological research has focused on intergroup empathy gaps, their underlying psychological and neural mechanisms, and their implications for downstream behavior (e.g. prejudice toward outgroup members).
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Empathy_gap'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Omission bias</h2>
<a href='https://en.wikipedia.org/wiki/Omission_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Omission bias</b> is the phenomenon in which people prefer omission (inaction) over commission (action), and tend to judge harm as a result of commission more negatively than harm as a result of omission. It can occur due to a number of processes, including psychological inertia, the perception of transaction costs, and the perception that commissions are more causal than omissions.
</p><p>In social political terms the Universal Declaration of Human Rights establishes how basic human rights are to be assessed in article 2, as "without distinction of any kind, such as race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status." criteria that are often subject to one or another form of omission bias.   It is controversial as to whether omission bias is a cognitive bias or is often rational. The bias is often showcased through the trolley problem and has also been described as an explanation for the endowment effect and status quo bias.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Omission_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Base rate fallacy</h2>
<a href='https://en.wikipedia.org/wiki/Base_rate_fallacy' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>base rate fallacy</b>, also called <b>base rate neglect</b> or <b>base rate bias</b>, is a type of fallacy in which people tend to ignore the base rate (e.g., general prevalence) in favor of the individuating information (i.e., information pertaining only to a specific case). For example, if someone hears that a friend is very shy and quiet, they might think the friend is more likely to be a librarian than a salesperson. However, there are far more salespeople than librarians overall—hence making it more likely that their friend is actually a salesperson, even if a greater proportion of librarians fit the description of being shy and quiet. Base rate neglect is a specific form of the more general extension neglect.
</p><p>It is also called the <b>prosecutor's fallacy</b> or <b>defense attorney's fallacy</b> when applied to the results of statistical tests (such as DNA tests) in the context of law proceedings. These terms were introduced by William C. Thompson and Edward Schumann in 1987, although it has been argued that their definition of the prosecutor's fallacy extends to many additional invalid imputations of guilt or liability that are not analyzable as errors in base rates or Bayes's theorem.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Base_rate_fallacy'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Bizarreness effect</h2>
<a href='https://en.wikipedia.org/wiki/Bizarreness_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Bizarreness effect </b>is the tendency of bizarre material to be better remembered than common material. The scientific evidence for its existence is contested. Some research suggests it does exist, some suggests it doesn't exist and some suggests it leads to worse remembering.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Bizarreness_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Humor effect</h2>
<a href='https://en.wikipedia.org/wiki/List_of_cognitive_biases#Humor_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>

<p>Cognitive biases are systematic patterns of deviation from norm and/or rationality in judgment.  They are often studied in psychology, sociology and behavioral economics.
</p><p>Although the reality of most of these biases is confirmed by reproducible research, there are often controversies about how to classify these biases or how to explain them. Several theoretical causes are known for some cognitive biases, which provides a classification of biases by their common generative mechanism (such as noisy information-processing). Gerd Gigerenzer has criticized the framing of cognitive biases as errors in judgment, and favors interpreting them as arising from rational deviations from logical thought.
</p><p>Explanations include information-processing rules (i.e., mental shortcuts), called <i>heuristics</i>, that the brain uses to produce decisions or judgments. Biases have a variety of forms and appear as cognitive ("cold") bias, such as mental noise, or motivational ("hot") bias, such as when beliefs are distorted by wishful thinking. Both effects can be present at the same time.
</p><p>There are also controversies over some of these biases as to whether they count as useless or irrational, or whether they result in useful attitudes or behavior. For example, when getting to know others, people tend to ask leading questions which seem biased towards confirming their assumptions about the person. However, this kind of confirmation bias has also been argued to be an example of social skill; a way to establish a connection with the other person.
</p><p>Although this research overwhelmingly involves human subjects, some studies have found bias in non-human animals as well. For example, loss aversion has been shown in monkeys and hyperbolic discounting has been observed in rats, pigeons, and monkeys.
</p>

<h2 data-mw-anchor="Belief,_decision-making_and_behavioral" data-mw-fallback-anchor="Belief.2C_decision-making_and_behavioral">Belief, decision-making and behavioral</h2>
<p>These biases affect belief formation, reasoning processes, business and economic decisions, and human behavior in general.
</p>
<h3 data-mw-anchor="Anchoring_bias">Anchoring bias</h3>

<p>The anchoring bias, or focalism, is the tendency to rely too heavily—to "anchor"—on one trait or piece of information when making decisions (usually the first piece of information acquired on that subject).
Anchoring bias includes or involves the following:
</p>
<ul><li>Common source bias, the tendency to combine or compare research studies from the same source, or from sources that use the same methodologies or data.</li>
<li>Conservatism bias, the tendency to insufficiently revise one's belief when presented with new evidence.</li>
<li>Functional fixedness, a tendency limiting a person to using an object only in the way it is traditionally used.</li>
<li>Law of the instrument, an over-reliance on a familiar tool or methods, ignoring or under-valuing alternative approaches. "If all you have is a hammer, everything looks like a nail."</li></ul>
<h3 data-mw-anchor="Apophenia">Apophenia</h3>

<p>The tendency to perceive meaningful connections between unrelated things.
The following are types of apophenia:
</p>
<ul><li>Clustering illusion, the tendency to overestimate the importance of small runs, streaks, or clusters in large samples of random data (that is, seeing phantom patterns).</li>
<li>Illusory correlation, a tendency to inaccurately perceive a relationship between two unrelated events.</li>
<li>Pareidolia, a tendency to perceive a vague and random stimulus (often an image or sound) as significant, e.g., seeing images of animals or faces in clouds, the man in the Moon, and hearing non-existent hidden messages on records played in reverse.</li></ul>
<h3 data-mw-anchor="Availability_heuristic">Availability heuristic</h3>

<p>The availability heuristic (also known as the availability bias) is the tendency to overestimate the likelihood of events with greater "availability" in memory, which can be influenced by how recent the memories are or how unusual or emotionally charged they may be. The availability heuristic includes or involves the following:
</p>
<ul><li>Anthropocentric thinking, the tendency to use human analogies as a basis for reasoning about other, less familiar, biological phenomena.</li>
<li>Anthropomorphism is characterization of animals, objects, and abstract concepts as possessing human traits, emotions, or intentions. The opposite bias, of not attributing feelings or thoughts to another person, is dehumanised perception, a type of objectification.</li>
<li>Attentional bias, the tendency of perception to be affected by recurring thoughts.</li>
<li>Frequency illusion or Baader–Meinhof phenomenon. The frequency illusion is that once something has been noticed then every instance of that thing is noticed, leading to the belief it has a high frequency of occurrence (a form of selection bias). The Baader–Meinhof phenomenon is the illusion where something that has recently come to one's attention suddenly seems to appear with improbable frequency shortly afterwards. It was named after an incidence of frequency illusion in which the Baader–Meinhof Group was mentioned.</li>
<li>Implicit association, where the speed with which people can match words depends on how closely they are associated.</li>
<li>Salience bias, the tendency to focus on items that are more prominent or emotionally striking and ignore those that are unremarkable, even though this difference is often irrelevant by objective standards. See also von Restorff effect.</li>
<li>Selection bias, which happens when the members of a statistical sample are not chosen completely at random, which leads to the sample not being representative of the population.</li>
<li>Survivorship bias, which is concentrating on the people or things that "survived" some process and inadvertently overlooking those that did not because of their lack of visibility.</li>
<li>Quantification bias, the tendency to ascribe more weight to measured/quantified metrics than to unquantifiable values. See also: McNamara fallacy.</li>
<li>Well travelled road effect, the tendency to underestimate the duration taken to traverse oft-travelled routes and overestimate the duration taken to traverse less familiar routes.</li></ul>
<h3 data-mw-anchor="Cognitive_dissonance">Cognitive dissonance</h3>

<p>Cognitive dissonance is the perception of contradictory information and the mental toll of it.
</p>
<ul><li>Normalcy bias, a form of cognitive dissonance, is the refusal to plan for, or react to, a disaster which has never happened before.</li>
<li>Effort justification is a person's tendency to attribute greater value to an outcome if they had to put effort into achieving it. This can result in more value being applied to an outcome than it actually has. An example of this is the IKEA effect, the tendency for people to place a disproportionately high value on objects that they partially assembled themselves, such as furniture from IKEA, regardless of the quality of the end product.</li>
<li>Ben Franklin effect, where a person who has performed a favor for someone is more likely to do another favor for that person than they would be if they had <i>received</i> a favor from that person.</li></ul>
<h3 data-mw-anchor="Confirmation_bias">Confirmation bias</h3>

<p>Confirmation bias is the tendency to search for, interpret, focus on and remember information in a way that confirms one's preconceptions. There are multiple other cognitive biases which involve or are types of confirmation bias:
</p>
<ul><li>Backfire effect, a tendency to react to disconfirming evidence by strengthening one's previous beliefs.</li>
<li>Congruence bias, the tendency to test hypotheses exclusively through direct testing, instead of testing possible alternative hypotheses.</li>
<li>Experimenter's or expectation bias, the tendency for experimenters to believe, certify, and publish data that agree with their expectations for the outcome of an experiment, and to disbelieve, discard, or downgrade the corresponding weightings for data that appear to conflict with those expectations.</li>
<li>Observer-expectancy effect, when a researcher expects a given result and therefore unconsciously manipulates an experiment or misinterprets data in order to find it (see also subject-expectancy effect).</li>
<li>Selective perception, the tendency for expectations to affect perception.</li>
<li>Semmelweis reflex, the tendency to reject new evidence that contradicts a paradigm.</li></ul>
<h3 data-mw-anchor="Egocentric_bias">Egocentric bias</h3>

<p>Egocentric bias is the tendency to rely too heavily on one's own perspective and/or have a different perception of oneself relative to others. The following are forms of egocentric bias:
</p>
<ul><li>Bias blind spot, the tendency to see oneself as less biased than other people, or to be able to identify more cognitive biases in others than in oneself.</li>
<li>False consensus effect, the tendency for people to overestimate the degree to which others agree with them.</li>
<li>False uniqueness bias, the tendency of people to see their projects and themselves as more singular than they actually are.</li>
<li>Forer effect or Barnum effect, the tendency for individuals to give high accuracy ratings to descriptions of their personality that supposedly are tailored specifically for them, but are in fact vague and general enough to apply to a wide range of people. This effect can provide a partial explanation for the widespread acceptance of some beliefs and practices, such as astrology, fortune telling, graphology, and some types of personality tests.</li>
<li>Illusion of asymmetric insight, where people perceive their knowledge of their peers to surpass their peers' knowledge of them.</li>
<li>Illusion of control, the tendency to overestimate one's degree of influence over other external events.</li>
<li>Illusion of transparency, the tendency for people to overestimate the degree to which their personal mental state is known by others, and to overestimate how well they understand others' personal mental states.</li>
<li>Illusion of validity, the tendency to overestimate the accuracy of one's judgments, especially when available information is consistent or inter-correlated.</li>
<li>Illusory superiority, the tendency to overestimate one's desirable qualities, and underestimate undesirable qualities, relative to other people. (Also known as "Lake Wobegon effect", "better-than-average effect", or "superiority bias".)</li>
<li>Naïve cynicism, expecting more egocentric bias in others than in oneself.</li>
<li>Naïve realism, the belief that we see reality as it really is—objectively and without bias; that the facts are plain for all to see; that rational people will agree with us; and that those who do not are either uninformed, lazy, irrational, or biased.</li>
<li>Overconfidence effect, a tendency to have excessive confidence in one's own answers to questions. For example, for certain types of questions, answers that people rate as "99% certain" turn out to be wrong 40% of the time.</li>
<li>Planning fallacy, the tendency for people to underestimate the time it will take them to complete a given task.</li>
<li>Restraint bias, the tendency to overestimate one's ability to show restraint in the face of temptation.</li>
<li>Trait ascription bias, the tendency for people to view themselves as relatively variable in terms of personality, behavior, and mood while viewing others as much more predictable.</li>
<li>Third-person effect, a tendency to believe that mass-communicated media messages have a greater effect on others than on themselves.</li></ul>
<h3 data-mw-anchor="Extension_neglect">Extension neglect</h3>

<p>Extension neglect occurs where the quantity of the sample size is not sufficiently taken into consideration when assessing the outcome, relevance or judgement. The following are forms of extension neglect:
</p>
<ul><li>Base rate fallacy or base rate neglect, the tendency to ignore general information and focus on information only pertaining to the specific case, even when the general information is more important.</li>
<li>Compassion fade, the tendency to behave more compassionately towards a small number of identifiable victims than to a large number of anonymous ones.</li>
<li>Conjunction fallacy, the tendency to assume that specific conditions are more probable than a more general version of those same conditions.</li>
<li>Duration neglect, the neglect of the duration of an episode in determining its value.</li>
<li>Hyperbolic discounting, where discounting is the tendency for people to have a stronger preference for more immediate payoffs relative to later payoffs. Hyperbolic discounting leads to choices that are inconsistent over time—people make choices today that their future selves would prefer not to have made, despite using the same reasoning. Also known as current moment bias or present bias, and related to Dynamic inconsistency. A good example of this is a study showed that when making food choices for the coming week, 74% of participants chose fruit, whereas when the food choice was for the current day, 70% chose chocolate.</li>
<li>Insensitivity to sample size, the tendency to under-expect variation in small samples.</li>
<li>Less-is-better effect, the tendency to prefer a smaller set to a larger set judged separately, but not jointly.</li>
<li>Neglect of probability, the tendency to completely disregard probability when making a decision under uncertainty.</li>
<li>Scope neglect or scope insensitivity, the tendency to be insensitive to the size of a problem when evaluating it. For example, being willing to pay as much to save 2,000 children or 20,000 children.</li>
<li>Zero-risk bias, the preference for reducing a small risk to zero over a greater reduction in a larger risk.</li></ul>
<h3 data-mw-anchor="False_priors">False priors</h3>

<p>False priors are initial beliefs and knowledge which interfere with the unbiased evaluation of factual evidence and lead to incorrect conclusions. Biases based on false priors include:
</p>
<ul><li>Agent detection bias, the inclination to presume the purposeful intervention of a sentient or intelligent agent.</li>
<li>Automation bias, the tendency to depend excessively on automated systems which can lead to erroneous automated information overriding correct decisions.</li>
<li>Gender bias, a widespread set of implicit biases that discriminate against a gender. For example, the assumption that women are less suited to jobs requiring high intellectual ability. Or the assumption that people or animals are male in the absence of any indicators of gender.</li>
<li>Sexual overperception bias, the tendency to overestimate sexual interest of another person in oneself, and sexual underperception bias, the tendency to underestimate it.</li>
<li>Stereotyping, expecting a member of a group to have certain characteristics without having actual information about that individual.</li></ul>
<h3 data-mw-anchor="Framing_effect">Framing effect</h3>

<p>The framing effect is the tendency to draw different conclusions from the same information, depending on how that information is presented. Forms of the framing effect include:
</p>
<ul><li>Contrast effect, the enhancement or reduction of a certain stimulus's perception when compared with a recently observed, contrasting object.</li>
<li>Decoy effect, where preferences for either option A or B change in favor of option B when option C is presented, which is completely dominated by option B (inferior in all respects) and partially dominated by option A.</li>
<li>Default effect, the tendency to favor the default option when given a choice between several options.</li>
<li>Denomination effect, the tendency to spend more money when it is denominated in small amounts (e.g., coins) rather than large amounts (e.g., bills).</li>
<li>Distinction bias, the tendency to view two options as more dissimilar when evaluating them simultaneously than when evaluating them separately.</li>
<li>Domain neglect bias, the tendency to neglect relevant domain knowledge while solving interdisciplinary problems.</li>
<li>Context neglect bias, the tendency to neglect the human context of technological challenges.</li></ul>
<h3 data-mw-anchor="Logical_fallacy">Logical fallacy</h3>

<ul><li>Berkson's paradox, the tendency to misinterpret statistical experiments involving conditional probabilities.</li>
<li>Escalation of commitment, irrational escalation, or sunk cost fallacy, where people justify increased investment in a decision, based on the cumulative prior investment, despite new evidence suggesting that the decision was probably wrong.</li>
<li>G. I. Joe fallacy, the tendency to think that knowing about cognitive bias is enough to overcome it.</li>
<li>Gambler's fallacy, the tendency to think that future probabilities are altered by past events, when in reality they are unchanged. The fallacy arises from an erroneous conceptualization of the law of large numbers. For example, "I've flipped heads with this coin five times consecutively, so the chance of tails coming out on the sixth flip is much greater than heads."</li>
<li>Hot-hand fallacy (also known as "hot hand phenomenon" or "hot hand"), the belief that a person who has experienced success with a random event has a greater chance of further success in additional attempts.</li>
<li>Plan continuation bias, failure to recognize that the original plan of action is no longer appropriate for a changing situation or for a situation that is different from anticipated.</li>
<li>Subadditivity effect, the tendency to judge the probability of the whole to be less than the probabilities of the parts.</li>
<li>Time-saving bias, a tendency to underestimate the time that could be saved (or lost) when increasing (or decreasing) from a relatively low speed, and to overestimate the time that could be saved (or lost) when increasing (or decreasing) from a relatively high speed.</li>
<li>Zero-sum bias, where a situation is incorrectly perceived to be like a zero-sum game (i.e., to be a situation whereby one person gains at the expense of another).</li></ul>
<h3 data-mw-anchor="Prospect_theory">Prospect theory</h3>


<p>The following relate to prospect theory:
</p>
<ul><li>Ambiguity effect, the tendency to avoid options for which the probability of a favorable outcome is unknown.</li>
<li>Disposition effect, the tendency to sell an asset that has accumulated in value and resist selling an asset that has declined in value.</li>
<li>Dread aversion, just as losses yield double the emotional impact of gains, dread yields double the emotional impact of savouring.</li>
<li>Endowment effect, the tendency for people to demand much more to give up an object than they would be willing to pay to acquire it.</li>
<li>Loss aversion, where the perceived disutility of giving up an object is greater than the utility associated with acquiring it. (see also Sunk cost fallacy)</li>
<li>Pseudocertainty effect, the tendency to make risk-averse choices if the expected outcome is positive, but make risk-seeking choices to avoid negative outcomes.</li>
<li>Status quo bias, the tendency to prefer things to stay relatively the same.</li>
<li>System justification, the tendency to defend and bolster the status quo. Existing social, economic, and political arrangements tend to be preferred, and alternatives disparaged, sometimes even at the expense of individual and collective self-interest.</li></ul>
<h3 data-mw-anchor="Self-assessment">Self-assessment</h3>
<ul><li>Dunning–Kruger effect, the tendency for unskilled individuals to overestimate their own ability and the tendency for experts to underestimate their own ability.</li>
<li>Hot-cold empathy gap, the tendency to underestimate the influence of visceral drives on one's attitudes, preferences, and behaviors.</li>
<li>Hard–easy effect, the tendency to overestimate one's ability to accomplish hard tasks, and underestimate one's ability to accomplish easy tasks.</li>
<li>Illusion of explanatory depth, the tendency to believe that one understands a topic much better than one actually does. The effect is strongest for explanatory knowledge, whereas people tend to be better at self-assessments for procedural, narrative, or factual knowledge.</li>
<li>Impostor Syndrome, a psychological occurrence in which an individual doubts their skills, talents, or accomplishments and has a persistent internalized fear of being exposed as a fraud.  Also known as impostor phenomenon.</li>
<li>Objectivity illusion, the phenomena where people tend to believe that they are more objective and unbiased than others. This bias can apply to itself – where people are able to see when others are affected by the objectivity illusion, but unable to see it in themselves. See also <i>bias blind spot.</i></li></ul>
<h3 data-mw-anchor="Truth_judgment">Truth judgment</h3>
<ul><li>Belief bias, an effect where someone's evaluation of the logical strength of an argument is biased by the believability of the conclusion.</li>
<li>Illusory truth effect, the tendency to believe that a statement is true if it is easier to process, or if it has been stated multiple times, regardless of its actual veracity. These are specific cases of truthiness.</li>
<li>Rhyme as reason effect, where rhyming statements are perceived as more truthful.</li>
<li>Subjective validation, where statements are perceived as true if a subject's belief demands it to be true. Also assigns perceived connections between coincidences. (Compare confirmation bias.)</li></ul>
<h3 data-mw-anchor="Other">Other</h3>

<h3 data-mw-anchor="Social">Social</h3>
<h4 data-mw-anchor="Association_fallacy">Association fallacy</h4>

<p>Association fallacies include:
</p>
<ul><li>Authority bias, the tendency to attribute greater accuracy to the opinion of an authority figure (unrelated to its content) and be more influenced by that opinion.</li>
<li>Cheerleader effect, the tendency for people to appear more attractive in a group than in isolation.</li>
<li>Halo effect, the tendency for a person's positive or negative traits to "spill over" from one personality area to another in others' perceptions of them (see also physical attractiveness stereotype).</li></ul>
<h4 data-mw-anchor="Attribution_bias">Attribution bias</h4>

<p>Attribution bias includes:
</p>
<ul><li>Actor-observer bias, the tendency for explanations of other individuals' behaviors to overemphasize the influence of their personality and underemphasize the influence of their situation (see also Fundamental attribution error), and for explanations of one's own behaviors to do the opposite (that is, to overemphasize the influence of our situation and underemphasize the influence of our own personality).</li>
<li>Defensive attribution hypothesis, a tendency to attribute more blame to a harm-doer as the outcome becomes more severe or as personal or situational similarity to the victim decreases.</li>
<li>Extrinsic incentives bias, an exception to the <i>fundamental attribution error</i>, where people view others as having (situational) extrinsic motivations and (dispositional) intrinsic motivations for oneself</li>
<li>Fundamental attribution error, the tendency for people to overemphasize personality-based explanations for behaviors observed in others while under-emphasizing the role and power of situational influences on the same behavior (see also actor-observer bias, group attribution error, positivity effect, and negativity effect).</li>
<li>Group attribution error, the biased belief that the characteristics of an individual group member are reflective of the group as a whole or the tendency to assume that group decision outcomes reflect the preferences of group members, even when information is available that clearly suggests otherwise.</li>
<li>Hostile attribution bias, the tendency to interpret others' behaviors as having hostile intent, even when the behavior is ambiguous or benign.</li>
<li>Intentionality bias, the tendency to judge human action to be intentional rather than accidental.</li>
<li>Just-world fallacy, the tendency for people to want to believe that the world is fundamentally just, causing them to rationalize an otherwise inexplicable injustice as deserved by the victim(s).</li>
<li>Moral luck, the tendency for people to ascribe greater or lesser moral standing based on the outcome of an event.</li>
<li>Puritanical bias, the tendency to attribute cause of an undesirable outcome or wrongdoing by an individual to a moral deficiency or lack of self-control rather than taking into account the impact of broader societal determinants .</li>
<li>Self-serving bias, the tendency to claim more responsibility for successes than failures. It may also manifest itself as a tendency for people to evaluate ambiguous information in a way beneficial to their interests (see also group-serving bias).</li>
<li>Ultimate attribution error, similar to the fundamental attribution error, in this error a person is likely to make an internal attribution to an entire group instead of the individuals within the group.</li></ul>
<h4 data-mw-anchor="Conformity">Conformity</h4>

<p>Conformity is involved in the following:
</p>
<ul><li>Availability cascade, a self-reinforcing process in which a collective belief gains more and more plausibility through its increasing repetition in public discourse (or "repeat something long enough and it will become true"). See also availability heuristic.</li>
<li>Bandwagon effect, the tendency to do (or believe) things because many other people do (or believe) the same. Related to groupthink and herd behavior.</li>
<li><span><span id="Courtesy_bias"></span><span>Courtesy bias</span></span>, the tendency to give an opinion that is more socially correct than one's true opinion, so as to avoid offending anyone.</li>
<li>Groupthink, the psychological phenomenon that occurs within a group of people in which the desire for harmony or conformity in the group results in an irrational or dysfunctional decision-making outcome. Group members try to minimize conflict and reach a consensus decision without critical evaluation of alternative viewpoints by actively suppressing dissenting viewpoints, and by isolating themselves from outside influences.</li>
<li>Groupshift, the tendency for decisions to be more risk-seeking or risk-averse than the group as a whole, if the group is already biased in that direction</li>
<li>Social desirability bias, the tendency to over-report socially desirable characteristics or behaviours in oneself and under-report socially undesirable characteristics or behaviours. See also: § Courtesy bias.</li>
<li>Truth bias is people's inclination towards believing, to some degree, the communication of another person, regardless of whether or not that person is actually lying or being untruthful.</li></ul>
<h4 data-mw-anchor="Ingroup_bias">Ingroup bias</h4>

<p>Ingroup bias is the tendency for people to give preferential treatment to others they perceive to be members of their own groups. It is related to the following:
</p>
<ul><li>Not invented here, an aversion to contact with or use of products, research, standards, or knowledge developed outside a group.</li>
<li>Outgroup homogeneity bias, where individuals see members of other groups as being relatively less varied than members of their own group.</li></ul>
<h4 data-mw-anchor="Other_social_biases">Other social biases</h4>

<h2 data-mw-anchor="Memory">Memory <span id="Memory_biases"></span></h2>
<p>In psychology and cognitive science, a memory bias is a cognitive bias that either enhances or impairs the recall of a memory (either the chances that the memory will be recalled at all, or the amount of time it takes for it to be recalled, or both), or that alters the content of a reported memory. There are many types of memory bias, including:
</p>
<h3 data-mw-anchor="Misattribution_of_memory">Misattribution of memory</h3>


<p>The misattributions include:
</p>
<ul><li>Cryptomnesia, where a memory is mistaken for novel thought or imagination, because there is no subjective experience of it being a memory.</li>
<li>False memory, where imagination is mistaken for a memory.</li>
<li>Social cryptomnesia, a failure by people and society in general to remember the origin of a change, in which people know that a change has occurred in society, but forget how this change occurred; that is, the steps that were taken to bring this change about, and who took these steps. This has led to reduced social credit towards the minorities who made major sacrifices that led to a change in societal values.</li>
<li>Source confusion, episodic memories are confused with other information, creating distorted memories.</li>
<li>Suggestibility, where ideas suggested by a questioner are mistaken for memory.</li>
<li>The Perky effect, where real images can influence imagined images, or be misremembered as imagined rather than real</li></ul>
<h3 data-mw-anchor="Other_memory_biases">Other memory biases</h3>

<h2 data-mw-anchor="See_also">See also</h2>


<h2 data-mw-anchor="Footnotes">Footnotes</h2>

<h2 data-mw-anchor="References">References</h2>

<h2 data-mw-anchor="Further_reading">Further reading</h2>

<h2 data-mw-anchor="External_links">External links</h2>
<ul><li><span typeof="mw:File"></span> Media related to Memory biases at Wikimedia Commons</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/List_of_cognitive_biases#Humor_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Von Restorff effect</h2>
<a href='https://en.wikipedia.org/wiki/Von_Restorff_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>Von Restorff effect</b>, also known as the "<b>isolation effect</b>", predicts that when multiple homogeneous stimuli are presented, the stimulus that differs from the rest is more likely to be remembered. The theory was coined by German psychiatrist and pediatrician Hedwig von Restorff (1906–1962), who, in her 1933 study, found that when participants were presented with a list of categorically similar items with one distinctive, isolated item on the list, memory for the item was improved.
</p><p>The study utilized the <i>isolation paradigm</i>, which refers to a distinctive feature of an item in a list that differs from the others by way of dimension. Such distinctiveness, leading to the von Restorff effect, can be generated from changing the meaningfulness or physical nature of the stimulus in some way, such as in size, shape, color, spacing and underlining.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Von_Restorff_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Picture superiority effect</h2>
<a href='https://en.wikipedia.org/wiki/Picture_superiority_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>picture superiority effect</b> refers to the phenomenon in which pictures and images are more likely to be remembered than words. This effect has been demonstrated in numerous experiments using different methods. It is based on the notion that "human memory is extremely sensitive to the symbolic modality of presentation of event information." Explanations for the picture superiority effect are not concrete and are still being debated, however an evolutionary explanation is that sight has a long history stretching back millions of years and was crucial to survival in the past, whereas reading is a relatively recent invention, and requires specific cognitive processes, such as decoding symbols and linking them to meaning.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Picture_superiority_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Self–relevance effect</h2>
<a href='https://en.wikipedia.org/wiki/Self-reference_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>self-reference effect</b> is a tendency for people to encode information differently depending on whether they are implicated in the information. When people are asked to remember information when it is related in some way to themselves, the recall rate can be improved.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Self-reference_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Negativity bias</h2>
<a href='https://en.wikipedia.org/wiki/Negativity_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>negativity bias</b>, also known as the <b>negativity effect</b>, is a cognitive bias that, even when positive or neutral things of equal intensity occur, things of a more negative nature (e.g. unpleasant thoughts, emotions, or social interactions; harmful/traumatic events) have a greater effect on one's psychological state and processes than neutral or positive things.  In other words, something very positive will generally have less of an impact on a person's behavior and cognition than something equally emotional but negative.  The negativity bias has been investigated within many different domains, including the formation of impressions and general evaluations; attention, learning, and memory; and decision-making and risk considerations.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Negativity_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Anchoring</h2>
<a href='https://en.wikipedia.org/wiki/Anchoring_(cognitive_bias)' target='_blank'>Wikipedia Link</a>
<div class='content'></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Anchoring_(cognitive_bias)'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Conservatism</h2>
<a href='https://en.wikipedia.org/wiki/Conservatism_(belief_revision)' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In cognitive psychology and decision science, <b>conservatism</b> or <b>conservatism bias</b> is a bias  which refers to the tendency to revise one's belief insufficiently when presented with new evidence. This bias describes human belief revision in which people over-weigh the prior distribution (base rate) and under-weigh new sample evidence when compared to Bayesian belief-revision.
</p><p>According to the theory, "opinion change is very orderly, and usually proportional to the numbers of Bayes' theorem – but it is insufficient in amount". In other words, people update their prior beliefs as new evidence becomes available, but they do so more slowly than they would if they used Bayes' theorem.
</p><p>This bias was discussed by Ward Edwards in 1968, who reported on experiments like the following one:
</p>
<blockquote><p>There are two bookbags, one containing 700 red and 300 blue chips, the other containing 300 red and 700 blue. Take one of the bags. Now, you sample, randomly, with replacement after each chip. In 12 samples, you get 8 reds and 4 blues. what is the probability that this is the predominantly red bag?</p></blockquote>
<p>Most subjects chose an answer around .7. The correct answer according to Bayes' theorem is closer to .97 ( based on Bayes' theorem:<span><span><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle {\frac {0.7^{8}\times 0.3^{4}}{0.7^{8}\times 0.3^{4}+0.3^{8}\times 0.7^{4}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <msup>
                <mn>0.7</mn>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>8</mn>
                </mrow>
              </msup>
              <mo>×<!-- × --></mo>
              <msup>
                <mn>0.3</mn>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>4</mn>
                </mrow>
              </msup>
            </mrow>
            <mrow>
              <msup>
                <mn>0.7</mn>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>8</mn>
                </mrow>
              </msup>
              <mo>×<!-- × --></mo>
              <msup>
                <mn>0.3</mn>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>4</mn>
                </mrow>
              </msup>
              <mo>+</mo>
              <msup>
                <mn>0.3</mn>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>8</mn>
                </mrow>
              </msup>
              <mo>×<!-- × --></mo>
              <msup>
                <mn>0.7</mn>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>4</mn>
                </mrow>
              </msup>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\frac {0.7^{8}\times 0.3^{4}}{0.7^{8}\times 0.3^{4}+0.3^{8}\times 0.7^{4}}}}</annotation>
  </semantics>
</math></span></span>). Edwards suggested that people updated beliefs conservatively, in accordance with Bayes' theorem, but more slowly. They updated from .5 incorrectly according to an observed bias in several experiments.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Conservatism_(belief_revision)'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Contrast effect</h2>
<a href='https://en.wikipedia.org/wiki/Contrast_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>A <b>contrast effect</b> is the enhancement or diminishment, relative to normal, of perception, cognition or related performance as a result of successive (immediately previous) or simultaneous exposure to a stimulus of lesser or greater value in the same dimension. (Here, normal perception, cognition or performance is that which would be obtained in the absence of the comparison stimulus—i.e., one based on all previous experience.)
</p><p>Perception example: A neutral gray target will appear lighter or darker than it does in isolation when immediately preceded by, or simultaneously compared to, respectively, a dark gray or light gray target.
</p><p>Cognition example: A person will appear more or less attractive than that person does in isolation when immediately preceded by, or simultaneously compared to, respectively, a less or more attractive person.
</p><p>Performance example: A laboratory rat will work faster, or slower, during a stimulus predicting a given amount of reward when that stimulus and reward are immediately preceded by, or alternated with, respectively, different stimuli associated with either a lesser or greater amount of reward.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Contrast_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Distinction bias</h2>
<a href='https://en.wikipedia.org/wiki/Distinction_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Distinction bias</b>, a concept of decision theory, is the tendency to view two options as more distinctive when evaluating them simultaneously than when evaluating them separately.
</p><p>One writer has presented what he called "a simplistic view" of distinction bias: When asked if someone would like an apple, they may say "Yes". So, an apple is placed before them and they begin to eat it and are happy. But what if two apples were placed on the table - one was the one they would have happily eaten and the other which is slightly fresher looking. The individual will choose the fresher apple and eat it and be happy but if asked, "would you have enjoyed eating that other apple", they would likely say "No". Even though in the alternate, no-choice reality they were perfectly happy with the apple. Moreover, if presented with five apples on a table, they might examine each apple so that they would be sure they had the best one, even though the time spent making that decision would be wasted. The reason for this is that distinction bias causes individuals to "over-examine and over-value the differences between things as we scrutinize them."
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Distinction_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Focusing effect</h2>
<a href='https://en.wikipedia.org/wiki/Anchoring_(cognitive_bias)' target='_blank'>Wikipedia Link</a>
<div class='content'></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Anchoring_(cognitive_bias)'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Framing effect</h2>
<a href='https://en.wikipedia.org/wiki/Framing_effect_(psychology)' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Framing effect</b> is a cognitive bias where people’s decisions change depending on how options are framed, even when the options are logically identical.Studies show that when both choices are framed positively as gains, the majority of people prefer a certain gain over a probable gain. On the other hand, when both choices are framed negatively as losses, people tend to choose an uncertain loss over an inevitable loss. Though the choices across the positive and negative framing conditions are logically equivalent, people in different conditions make different decisions. Gain and loss are defined within the scenario as outcomes, for example, lives lost or saved, patients treated or not treated, monetary gains or losses.
</p><p>Prospect theory posits that a loss is more significant than the equivalent gain, that a sure gain (certainty effect and pseudocertainty effect) is favored over a probabilistic gain, and that a probabilistic loss is preferred to a definite loss. One of the dangers of framing effects is that people are often provided with options within the context of only one of the two frames.
</p><p>The concept helps to develop an understanding of frame analysis within social movements, and also in the formation of political opinion where spin plays a large role in political opinion polls that are framed to encourage a response beneficial to the organization that has commissioned the poll. It has been suggested that the use of the technique is discrediting political polls themselves. The effect is reduced, or even eliminated, if ample credible information is provided to people.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Framing_effect_(psychology)'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Money illusion</h2>
<a href='https://en.wikipedia.org/wiki/Money_illusion' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In economics, <b>money illusion</b>, or <b>price illusion</b>, is a cognitive bias where money is thought of in nominal, rather than real terms. In other words, the face value (nominal value) of money is mistaken for its purchasing power (real value) at a previous point in time. Viewing purchasing power as measured by the nominal value is false, as modern fiat currencies have no intrinsic value and their real value depends purely on the price level. The term was coined by Irving Fisher in <i>Stabilizing the Dollar</i>. It was popularized by John Maynard Keynes in the early twentieth century, and Irving Fisher wrote an important book on the subject, <i>The Money Illusion</i>, in 1928.
</p><p>The existence of money illusion is disputed by monetary economists  who contend that people act rationally (i.e. think in real prices) with regard to their wealth. Eldar Shafir, Peter A. Diamond, and Amos Tversky (1997) have provided  empirical evidence for the existence of the effect and it has been shown to affect behaviour in a variety of experimental and real-world situations.
</p><p>Shafir et al. also state that money illusion influences economic behaviour in three main ways:
</p>
<ul><li>Price stickiness. Money illusion has been proposed as one reason why nominal prices are slow to change even where inflation has caused real prices to fall or costs to rise.</li>
<li>Contracts and laws are not indexed to inflation as frequently as one would rationally expect.</li>
<li>Social discourse, in formal media and more generally, reflects some confusion about real and nominal value.</li></ul>
<p>Money illusion can also influence people's perceptions of outcomes. Experiments have shown that people generally perceive an approximate 2% cut in nominal income with no change in monetary value as unfair, but see a 2% rise in nominal income where there is 4% inflation as fair, despite them being almost rational equivalents. This result is consistent with the 'Myopic Loss Aversion theory'. Furthermore, the money illusion means nominal changes in price can influence demand even if real prices have remained constant.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Money_illusion'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Weber–Fechner law</h2>
<a href='https://en.wikipedia.org/wiki/Weber–Fechner_law' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>Weber–Fechner laws</b> are two related scientific laws in the field of psychophysics, known as <b>Weber's law</b> and <b>Fechner's law</b>. Both relate to human perception, more specifically the relation between the actual change in a physical stimulus and the perceived change. This includes stimuli to all senses: vision, hearing, taste, touch, and smell.
</p><p>Ernst Heinrich Weber states that "the minimum increase of stimulus which will produce a perceptible increase of sensation is proportional to the pre-existent stimulus," while Gustav Fechner's law is an inference from Weber's law (with additional assumptions) which states that the intensity of our sensation increases as the logarithm of an increase in energy rather than as rapidly as the increase.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Weber–Fechner_law'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Confirmation bias</h2>
<a href='https://en.wikipedia.org/wiki/Confirmation_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p>

<b>Confirmation bias</b> (also <b>confirmatory bias</b>, <b>myside bias</b> or <b>congeniality bias</b>) is the tendency to search for, interpret, favor and recall information in a way that confirms or supports one's prior beliefs or values. People display this bias when they select information that supports their views, ignoring contrary information or when they interpret ambiguous evidence as supporting their existing attitudes. The effect is strongest for desired outcomes, for emotionally charged issues and for deeply entrenched beliefs.
</p><p>Biased search for information, biased interpretation of this information and biased memory recall, have been invoked to explain four specific effects:
</p>
<ol><li><i>attitude polarization</i> (when a disagreement becomes more extreme even though the different parties are exposed to the same evidence)</li>
<li><i>belief perseverance</i> (when beliefs persist after the evidence for them is shown to be false)</li>
<li>the <i>irrational primacy effect</i> (a greater reliance on information encountered early in a series)</li>
<li><i>illusory correlation</i> (when people falsely perceive an association between two events or situations).</li></ol>
<p>A series of psychological experiments in the 1960s suggested that people are biased toward confirming their existing beliefs. Later work re-interpreted these results as a tendency to test ideas in a one-sided way, focusing on one possibility and ignoring alternatives. Explanations for the observed biases include wishful thinking and the limited human capacity to process information. Another proposal is that people show confirmation bias because they are pragmatically assessing the costs of being wrong rather than investigating in a neutral, scientific way.
</p><p>Flawed decisions due to confirmation bias have been found in a wide range of political, organizational, financial and scientific contexts. These biases contribute to overconfidence in personal beliefs and can maintain or strengthen beliefs in the face of contrary evidence. For example, confirmation bias produces systematic errors in scientific research based on inductive reasoning (the gradual accumulation of supportive evidence). Similarly, a police detective may identify a suspect early in an investigation but then may only seek confirming rather than disconfirming evidence. A medical practitioner may prematurely focus on a particular disorder early in a diagnostic session and then seek only confirming evidence. In social media, confirmation bias is amplified by the use of filter bubbles, or "algorithmic editing", which display to individuals only information they are likely to agree with, while excluding opposing views.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Confirmation_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Congruence bias</h2>
<a href='https://en.wikipedia.org/wiki/Congruence_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Congruence bias</b> is the tendency of people to over-rely on testing their initial hypothesis (the most <i>congruent</i> one) while neglecting to test alternative hypotheses. That is, people rarely try experiments that could disprove their initial belief, but rather try to repeat their initial results. It is a special case of the confirmation bias.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Congruence_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Post–purchase rationalization</h2>
<a href='https://en.wikipedia.org/wiki/Choice-supportive_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Choice-supportive bias</b> or <b>post-purchase rationalization</b> is the tendency to retroactively ascribe positive attributes to an option one has selected and/or to demote the forgone options. It is part of cognitive science, and is a distinct cognitive bias that occurs once a decision is made. For example, if a person chooses option A instead of option B, they are likely to ignore or downplay the faults of option A while amplifying or ascribing new negative faults to option B. Conversely, they are also likely to notice and amplify the advantages of option A and not notice or de-emphasize those of option B.
</p><p>What is remembered about a decision can be as important as the decision itself, especially in determining how much regret or satisfaction one experiences. Research indicates that the process of making and remembering choices yields memories that tend to be distorted in predictable ways.
</p><p>In cognitive science, one predictable way that memories of choice options are distorted is that positive aspects tend to be remembered as part of the chosen option, whether or not they originally were part of that option, and negative aspects tend to be remembered as part of rejected options. Once an action has been taken, the ways in which we evaluate the effectiveness of what we did may be biased. It is believed this may influence our future decision-making. These biases may be stored as memories, which are attributions that we make about our mental experiences based on their subjective qualities, our prior knowledge and beliefs, our motives and goals, and the social context. True and false memories arise by the same mechanism because when the brain processes and stores information, it cannot tell the difference where they came from.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Choice-supportive_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Choice–supportive bias</h2>
<a href='https://en.wikipedia.org/wiki/Choice-supportive_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Choice-supportive bias</b> or <b>post-purchase rationalization</b> is the tendency to retroactively ascribe positive attributes to an option one has selected and/or to demote the forgone options. It is part of cognitive science, and is a distinct cognitive bias that occurs once a decision is made. For example, if a person chooses option A instead of option B, they are likely to ignore or downplay the faults of option A while amplifying or ascribing new negative faults to option B. Conversely, they are also likely to notice and amplify the advantages of option A and not notice or de-emphasize those of option B.
</p><p>What is remembered about a decision can be as important as the decision itself, especially in determining how much regret or satisfaction one experiences. Research indicates that the process of making and remembering choices yields memories that tend to be distorted in predictable ways.
</p><p>In cognitive science, one predictable way that memories of choice options are distorted is that positive aspects tend to be remembered as part of the chosen option, whether or not they originally were part of that option, and negative aspects tend to be remembered as part of rejected options. Once an action has been taken, the ways in which we evaluate the effectiveness of what we did may be biased. It is believed this may influence our future decision-making. These biases may be stored as memories, which are attributions that we make about our mental experiences based on their subjective qualities, our prior knowledge and beliefs, our motives and goals, and the social context. True and false memories arise by the same mechanism because when the brain processes and stores information, it cannot tell the difference where they came from.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Choice-supportive_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Selective perception</h2>
<a href='https://en.wikipedia.org/wiki/Selective_perception' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Selective perception</b> is the tendency not to notice and more quickly forget stimuli that cause emotional discomfort and contradict prior beliefs. For example, a teacher may have a favorite student because they are biased by in-group favoritism. The teacher ignores the student's poor attainment. Conversely, they might not notice the progress of their least favorite student. It can also occur when consuming mass media, allowing people to see facts and opinions they like while ignoring those that do not fit with particular opinions, values, beliefs, or frame of reference. Psychologists believe this process occurs automatically.
</p><p>Selective perception has roots in cognitive psychology, where it is studied as a fundamental part of how individuals filter and process information based on biases, expectations, and past experiences. It is closely related to concepts like confirmation bias—favoring information that aligns with one’s beliefs—and cognitive dissonance, the discomfort of holding conflicting thoughts, both of which shape perception. Its applications extend beyond psychology, playing key roles in marketing (shaping consumer focus), politics (influencing voter perception), and mental health (understanding biases in disorders), highlighting its impact on both individual behaviors and societal trends.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Selective_perception'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Observer–expectancy effect</h2>
<a href='https://en.wikipedia.org/wiki/Observer-expectancy_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>observer-expectancy effect</b> is a form of reactivity in which a researcher's cognitive bias causes them to subconsciously influence the participants of an experiment. Confirmation bias can lead to the experimenter interpreting results incorrectly because of the tendency to look for information that conforms to their hypothesis, and overlook information that argues against it. It is a significant threat to a study's internal validity, and is therefore typically controlled using a double-blind experimental design.
</p><p>It may include conscious or unconscious influences on subject behavior including creation of demand characteristics that influence subjects, and altered or selective recording of experimental results themselves.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Observer-expectancy_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Experimenter's bias</h2>
<a href='https://en.wikipedia.org/wiki/Observer-expectancy_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>observer-expectancy effect</b> is a form of reactivity in which a researcher's cognitive bias causes them to subconsciously influence the participants of an experiment. Confirmation bias can lead to the experimenter interpreting results incorrectly because of the tendency to look for information that conforms to their hypothesis, and overlook information that argues against it. It is a significant threat to a study's internal validity, and is therefore typically controlled using a double-blind experimental design.
</p><p>It may include conscious or unconscious influences on subject behavior including creation of demand characteristics that influence subjects, and altered or selective recording of experimental results themselves.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Observer-expectancy_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Observer effect</h2>
<a href='https://en.wikipedia.org/wiki/Observer-expectancy_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>observer-expectancy effect</b> is a form of reactivity in which a researcher's cognitive bias causes them to subconsciously influence the participants of an experiment. Confirmation bias can lead to the experimenter interpreting results incorrectly because of the tendency to look for information that conforms to their hypothesis, and overlook information that argues against it. It is a significant threat to a study's internal validity, and is therefore typically controlled using a double-blind experimental design.
</p><p>It may include conscious or unconscious influences on subject behavior including creation of demand characteristics that influence subjects, and altered or selective recording of experimental results themselves.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Observer-expectancy_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Expectation bias</h2>
<a href='https://en.wikipedia.org/wiki/Observer-expectancy_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>observer-expectancy effect</b> is a form of reactivity in which a researcher's cognitive bias causes them to subconsciously influence the participants of an experiment. Confirmation bias can lead to the experimenter interpreting results incorrectly because of the tendency to look for information that conforms to their hypothesis, and overlook information that argues against it. It is a significant threat to a study's internal validity, and is therefore typically controlled using a double-blind experimental design.
</p><p>It may include conscious or unconscious influences on subject behavior including creation of demand characteristics that influence subjects, and altered or selective recording of experimental results themselves.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Observer-expectancy_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Ostrich effect</h2>
<a href='https://en.wikipedia.org/wiki/Ostrich_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>ostrich effect</b>, also known as the <b>ostrich problem</b>, was originally coined by Galai &amp; Sade (2003). The name comes from the common (but false) legend that ostriches bury their heads in the sand to avoid danger. This effect is a cognitive bias where people tend to “bury their head in the sand” and avoid potentially negative but useful information, such as feedback on progress, to avoid psychological discomfort.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Ostrich_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Subjective validation</h2>
<a href='https://en.wikipedia.org/wiki/Subjective_validation' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Subjective validation</b>, sometimes called <b>personal validation effect</b>, is a cognitive bias by which people will consider a statement or another piece of information to be correct if it has any personal meaning or significance to them. People whose opinion is affected by subjective validation will perceive two unrelated events (i.e., a coincidence) to be related because their personal beliefs demand that they be related. Closely related to the Forer effect, subjective validation is an important element in cold reading. It is considered to be the main reason behind most reports of paranormal phenomena. According to Bob Carroll, psychologist Ray Hyman is considered to be the foremost expert on cold reading.
</p><p>The term <i>subjective validation</i> first appeared in the 1980 book <i>The Psychology of the Psychic</i> by David F. Marks and Richard Kammann.
</p><p>Subjective validation describes the tendency of people to believe or accept an idea or statement if it presents to them in a personal and positive way. An example of subjective validation can be found in horoscopes, which often make vague, easily generalized personal statements, sometimes referred to as "Barnum statements", designed to apply to nearly any individual, such as: "You have a great deal of unused capacity, which you have not turned to your advantage." This can cause one to attribute future success to the horoscope and feel as if their belief in it has been validated. In essence, subjective validation is a confirmation bias towards information that personally benefits one's self-esteem.
</p><p>Many of the validations that are given are not necessarily because they are true about recipients but because people wish it was true about themselves; people tend to think of themselves in terms of values that are important to them, even if they don't show those values. They tend to believe they do, and they tend to believe it the more they hear it and read it about themselves.
</p><p>This effect can be seen when it comes to health. For example, if someone enjoys eating bacon and they were to come across an article that talks about bacon being healthy, they will tend to believe it more because this "validates" eating more bacon.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Subjective_validation'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Continued influence effect</h2>
<a href='https://en.wikipedia.org/wiki/Confirmation_bias#continued_influence_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>

<b>Confirmation bias</b> (also <b>confirmatory bias</b>, <b>myside bias</b> or <b>congeniality bias</b>) is the tendency to search for, interpret, favor and recall information in a way that confirms or supports one's prior beliefs or values. People display this bias when they select information that supports their views, ignoring contrary information or when they interpret ambiguous evidence as supporting their existing attitudes. The effect is strongest for desired outcomes, for emotionally charged issues and for deeply entrenched beliefs.
</p><p>Biased search for information, biased interpretation of this information and biased memory recall, have been invoked to explain four specific effects:
</p>
<ol><li><i>attitude polarization</i> (when a disagreement becomes more extreme even though the different parties are exposed to the same evidence)</li>
<li><i>belief perseverance</i> (when beliefs persist after the evidence for them is shown to be false)</li>
<li>the <i>irrational primacy effect</i> (a greater reliance on information encountered early in a series)</li>
<li><i>illusory correlation</i> (when people falsely perceive an association between two events or situations).</li></ol>
<p>A series of psychological experiments in the 1960s suggested that people are biased toward confirming their existing beliefs. Later work re-interpreted these results as a tendency to test ideas in a one-sided way, focusing on one possibility and ignoring alternatives. Explanations for the observed biases include wishful thinking and the limited human capacity to process information. Another proposal is that people show confirmation bias because they are pragmatically assessing the costs of being wrong rather than investigating in a neutral, scientific way.
</p><p>Flawed decisions due to confirmation bias have been found in a wide range of political, organizational, financial and scientific contexts. These biases contribute to overconfidence in personal beliefs and can maintain or strengthen beliefs in the face of contrary evidence. For example, confirmation bias produces systematic errors in scientific research based on inductive reasoning (the gradual accumulation of supportive evidence). Similarly, a police detective may identify a suspect early in an investigation but then may only seek confirming rather than disconfirming evidence. A medical practitioner may prematurely focus on a particular disorder early in a diagnostic session and then seek only confirming evidence. In social media, confirmation bias is amplified by the use of filter bubbles, or "algorithmic editing", which display to individuals only information they are likely to agree with, while excluding opposing views.
</p>

<h2 data-mw-anchor="Definition_and_context">Definition and context</h2>
<p>Confirmation bias, previously used as a "catch-all phrase", was refined by English psychologist Peter Wason, as "a preference for information that is consistent with a hypothesis rather than information which opposes it."
</p><p>Confirmation biases are effects in information processing. They differ from what is sometimes called the <i>behavioral confirmation effect</i>, commonly known as <i>self-fulfilling prophecy</i>, in which a person's expectations influence their own behavior, bringing about the expected result.
</p><p>Some psychologists restrict the term "confirmation bias" to selective collection of evidence that supports what one already believes while ignoring or rejecting evidence that supports a different conclusion. Others apply the term more broadly to the tendency to preserve one's existing beliefs when searching for evidence, interpreting it, or recalling it from memory. Confirmation bias is a result of automatic, unintentional strategies rather than deliberate deception.
</p>
<h2 data-mw-anchor="Types">Types</h2>
<h3 data-mw-anchor="Biased_search_for_information">Biased search for information</h3>

<p>Experiments have found repeatedly that people tend to test hypotheses in a one-sided way, by searching for evidence consistent with their current hypothesis.<sup class="reference nowrap"><span title="Page / location: 177–178">: 177–178 </span></sup> Rather than searching through all the relevant evidence, they phrase questions to receive an affirmative answer that supports their theory. They look for the consequences that they would expect if their hypothesis was true, rather than what would happen if it was false. For example, someone using yes/no questions to find a number they suspect to be the number 3 might ask, "Is it an odd number?" People prefer this type of question, called a "positive test", even when a negative test such as "Is it an even number?" would yield exactly the same information. However, this does not mean that people seek tests that guarantee a positive answer. In studies where subjects could select either such pseudo-tests or genuinely diagnostic ones, they favored the genuinely diagnostic.
</p><p>The preference for positive tests in itself is not a bias, since positive tests can be highly informative. However, in combination with other effects, this strategy can confirm existing beliefs or assumptions, independently of whether they are true. In real-world situations, evidence is often complex and mixed. For example, various contradictory ideas about someone could each be supported by concentrating on one aspect of his or her behavior. Thus any search for evidence in favor of a hypothesis is likely to succeed. One illustration of this is the way the phrasing of a question can significantly change the answer. For example, people who are asked, "Are you happy with your social life?" report greater satisfaction than those asked, "Are you <i>un</i>happy with your social life?"
</p><p>Even a small change in a question's wording can affect how people search through available information, and hence the conclusions they reach. This was shown using a fictional child custody case. Participants read that Parent A was moderately suitable to be the guardian in multiple ways. Parent B had a mix of salient positive and negative qualities: a close relationship with the child but a job that would take them away for long periods of time. When asked, "Which parent should have custody of the child?" the majority of participants chose Parent B, looking mainly for positive attributes. However, when asked, "Which parent should be denied custody of the child?" they looked for negative attributes and the majority answered that Parent B should be denied custody, implying that Parent A should have custody.
</p><p>Similar studies have demonstrated how people engage in a biased search for information, but also that this phenomenon may be limited by a preference for genuine diagnostic tests. In an initial experiment, participants rated another person on the introversion–extroversion personality dimension on the basis of an interview. They chose the interview questions from a given list. When the interviewee was introduced as an introvert, the participants chose questions that presumed introversion, such as, "What do you find unpleasant about noisy parties?" When the interviewee was described as extroverted, almost all the questions presumed extroversion, such as, "What would you do to liven up a dull party?" These loaded questions gave the interviewees little or no opportunity to falsify the hypothesis about them. A later version of the experiment gave the participants less presumptive questions to choose from, such as, "Do you shy away from social interactions?" Participants preferred to ask these more diagnostic questions, showing only a weak bias towards positive tests. This pattern, of a main preference for diagnostic tests and a weaker preference for positive tests, has been replicated in other studies.
</p><p>Personality traits influence and interact with biased search processes. Individuals vary in their abilities to defend their attitudes from external attacks in relation to selective exposure. Selective exposure occurs when individuals search for information that is consistent, rather than inconsistent, with their personal beliefs. An experiment examined the extent to which individuals could refute arguments that contradicted their personal beliefs. People with high confidence levels more readily seek out contradictory information to their personal position to form an argument. This can take the form of an <i>oppositional news consumption</i>, where individuals seek opposing partisan news in order to counterargue. Individuals with low confidence levels do not seek out contradictory information and prefer information that supports their personal position. People generate and evaluate evidence in arguments that are biased towards their own beliefs and opinions. Heightened confidence levels decrease preference for information that supports individuals' personal beliefs.
</p><p>Another experiment gave participants a complex rule-discovery task that involved moving objects simulated by a computer. Objects on the computer screen followed specific laws, which the participants had to figure out. So, participants could "fire" objects across the screen to test their hypotheses. Despite making many attempts over a ten-hour session, none of the participants figured out the rules of the system. They typically attempted to confirm rather than falsify their hypotheses, and were reluctant to consider alternatives. Even after seeing objective evidence that refuted their working hypotheses, they frequently continued doing the same tests. Some of the participants were taught proper hypothesis-testing, but these instructions had almost no effect.
</p>
<h3 data-mw-anchor="Biased_interpretation_of_information">Biased interpretation of information</h3>

<p>Confirmation biases are not limited to the collection of evidence. Even if two individuals have the same information, the way they interpret it can be biased.
</p><p>A team at Stanford University conducted an experiment involving participants who felt strongly about capital punishment, with half in favor and half against it. Each participant read descriptions of two studies: a comparison of U.S. states with and without the death penalty, and a comparison of murder rates in a state before and after the introduction of the death penalty. After reading a quick description of each study, the participants were asked whether their opinions had changed. Then, they read a more detailed account of each study's procedure and had to rate whether the research was well-conducted and convincing. In fact, the studies were fictional. Half the participants were told that one kind of study supported the deterrent effect and the other undermined it, while for other participants the conclusions were swapped.
</p><p>The participants, whether supporters or opponents, reported shifting their attitudes slightly in the direction of the first study they read. Once they read the more detailed descriptions of the two studies, they almost all returned to their original belief regardless of the evidence provided, pointing to details that supported their viewpoint and disregarding anything contrary. Participants described studies supporting their pre-existing view as superior to those that contradicted it, in detailed and specific ways. Writing about a study that seemed to undermine the deterrence effect, a death penalty proponent wrote, "The research didn't cover a long enough period of time," while an opponent's comment on the same study said, "No strong evidence to contradict the researchers has been presented." The results illustrated that people set higher standards of evidence for hypotheses that go against their current expectations. This effect, known as "disconfirmation bias", has been supported by other experiments.
</p><p>Another study of biased interpretation occurred during the 2004 U.S. presidential election and involved participants who reported having strong feelings about the candidates. They were shown apparently contradictory pairs of statements, either from Republican candidate George W. Bush, Democratic candidate John Kerry or a politically neutral public figure. They were also given further statements that made the apparent contradiction seem reasonable. From these three pieces of information, they had to decide whether each individual's statements were inconsistent.<sup class="reference nowrap"><span title="Page / location: 1948">: 1948 </span></sup> There were strong differences in these evaluations, with participants much more likely to interpret statements from the candidate they opposed as contradictory.<sup class="reference nowrap"><span title="Page / location: 1951">: 1951 </span></sup>
</p>

<p>In this experiment, the participants made their judgments while in a magnetic resonance imaging (MRI) scanner which monitored their brain activity. As participants evaluated contradictory statements by their favored candidate, emotional centers of their brains were aroused. This did not happen with the statements by the other figures. The experimenters inferred that the different responses to the statements were not due to passive reasoning errors. Instead, the participants were actively reducing the cognitive dissonance induced by reading about their favored candidate's irrational or hypocritical behavior.<sup class="reference nowrap"><span title="Page / location: 1956">: 1956 </span></sup>
</p><p>Biases in belief interpretation are persistent, regardless of intelligence level. Participants in an experiment took the SAT test (a college admissions test used in the United States) to assess their intelligence levels. They then read information regarding safety concerns for vehicles, and the experimenters manipulated the national origin of the car. American participants provided their opinion if the car should be banned on a six-point scale, where one indicated "definitely yes" and six indicated "definitely no". Participants firstly evaluated if they would allow a dangerous German car on American streets and a dangerous American car on German streets. Participants believed that the dangerous German car on American streets should be banned more quickly than the dangerous American car on German streets. There was no difference among intelligence levels at the rate participants would ban a car.
</p><p>Biased interpretation is not restricted to emotionally significant topics. In another experiment, participants were told a story about a theft. They had to rate the evidential importance of statements arguing either for or against a particular character being responsible. When they hypothesized that character's guilt, they rated statements supporting that hypothesis as more important than conflicting statements.
</p>
<h3 data-mw-anchor="Biased_recall_of_information">Biased recall of information</h3>
<p>People may remember evidence selectively to reinforce their expectations, even if they gather and interpret evidence in a neutral manner. This effect is called "selective recall", "confirmatory memory", or "access-biased memory". Psychological theories differ in their predictions about selective recall. Schema theory predicts that information matching prior expectations will be more easily stored and recalled than information that does not match. Some alternative approaches say that surprising information stands out and so is memorable. Predictions from both these theories have been confirmed in different experimental contexts, with no theory winning outright.
</p><p>In one study, participants read a profile of a woman which described a mix of introverted and extroverted behaviors. They later had to recall examples of her introversion and extroversion. One group was told this was to assess the woman for a job as a librarian, while a second group were told it was for a job in real estate sales. There was a significant difference between what these two groups recalled, with the "librarian" group recalling more examples of introversion and the "sales" groups recalling more extroverted behavior. A selective memory effect has also been shown in experiments that manipulate the desirability of personality types. In one of these, a group of participants were shown evidence that extroverted people are more successful than introverts. Another group were told the opposite. In a subsequent, apparently unrelated study, participants were asked to recall events from their lives in which they had been either introverted or extroverted. Each group of participants provided more memories connecting themselves with the more desirable personality type, and recalled those memories more quickly.
</p><p>Changes in emotional states can also influence memory recall. Participants rated how they felt when they had first learned that O. J. Simpson had been acquitted of murder charges. They described their emotional reactions and confidence regarding the verdict one week, two months, and one year after the trial. Results indicated that participants' assessments for Simpson's guilt changed over time. The more that participants' opinion of the verdict had changed, the less stable were the participant's memories regarding their initial emotional reactions. When participants recalled their initial emotional reactions two months and a year later, past appraisals closely resembled current appraisals of emotion. People demonstrate sizable myside bias when discussing their opinions on controversial topics. Memory recall and construction of experiences undergo revision in relation to corresponding emotional states.
</p><p>Myside bias has been shown to influence the accuracy of memory recall. In an experiment, widows and widowers rated the intensity of their experienced grief six months and five years after the deaths of their spouses. Participants noted a higher experience of grief at six months rather than at five years. Yet, when the participants were asked after five years how they had felt six months after the death of their significant other, the intensity of grief participants recalled was highly correlated with their current level of grief. Individuals appear to utilize their current emotional states to analyze how they must have felt when experiencing past events. Emotional memories are reconstructed by current emotional states.
</p><p>One study showed how selective memory can maintain belief in extrasensory perception (ESP). Believers and disbelievers were each shown descriptions of ESP experiments. Half of each group were told that the experimental results supported the existence of ESP, while the others were told they did not. In a subsequent test, participants recalled the material accurately, apart from believers who had read the non-supportive evidence. This group remembered significantly less information and some of them incorrectly remembered the results as supporting ESP.
</p>
<h2 data-mw-anchor="Individual_differences">Individual differences</h2>
<p>Myside bias was once believed to be correlated with intelligence; however, studies have shown that myside bias can be more influenced by ability to rationally think as opposed to level of intelligence. Myside bias can cause an inability to effectively and logically evaluate the opposite side of an argument. Studies have stated that myside bias is an absence of "active open-mindedness", meaning the active search for why an initial idea may be wrong. Typically, myside bias is operationalized in empirical studies as the quantity of evidence used in support of their side in comparison to the opposite side.
</p><p>A study has found individual differences in myside bias. This study investigates individual differences that are acquired through learning in a cultural context and are mutable. The researcher found important individual difference in argumentation. Studies have suggested that individual differences such as deductive reasoning ability, ability to overcome belief bias, epistemological understanding, and thinking disposition are significant predictors of the reasoning and generating arguments, counterarguments, and rebuttals.
</p><p>A study by Christopher Wolfe and Anne Britt also investigated how participants' views of "what makes a good argument?" can be a source of myside bias that influences the way a person formulates their own arguments. The study investigated individual differences of argumentation schema and asked participants to write essays. The participants were randomly assigned to write essays either for or against their preferred side of an argument and were given research instructions that took either a balanced or an unrestricted approach. The balanced-research instructions directed participants to create a "balanced" argument, i.e., that included both pros and cons; the unrestricted-research instructions included nothing on how to create the argument.
</p><p>Overall, the results revealed that the balanced-research instructions significantly increased the incidence of opposing information in arguments. These data also reveal that personal belief is not a <i>source</i> of myside bias; however, that those participants, who believe that a good argument is one that is based on facts, are more likely to exhibit myside bias than other participants. This evidence is consistent with the claims proposed in Baron's article—that people's opinions about what makes good thinking can influence how arguments are generated.
</p>
<h2 data-mw-anchor="Discovery">Discovery</h2>
<h3 data-mw-anchor="Informal_observations">Informal observations</h3>

<p>Before psychological research on confirmation bias, the phenomenon had been observed throughout history. Beginning with the Greek historian Thucydides (<abbr title="circa">c.</abbr><span> 460 BC</span> – <abbr title="circa">c.</abbr><span> 395 BC</span>), who wrote of misguided reason in <i>The Peloponnesian War</i>; "... for it is a habit of mankind to entrust to careless hope what they long for, and to use sovereign reason to thrust aside what they do not fancy". Italian poet Dante Alighieri (1265–1321) noted it in the <i>Divine Comedy</i>, in which St. Thomas Aquinas cautions Dante upon meeting in Paradise, "opinion—hasty—often can incline to the wrong side, and then affection for one's own opinion binds, confines the mind". Ibn Khaldun noticed the same effect in his <i>Muqaddimah</i>:
</p>
<blockquote class="templatequote"><p>Untruth naturally afflicts historical information. There are various reasons that make this unavoidable. One of them is partisanship for opinions and schools. ... if the soul is infected with partisanship for a particular opinion or sect, it accepts without a moment's hesitation the information that is agreeable to it. Prejudice and partisanship obscure the critical faculty and preclude critical investigation. The result is that falsehoods are accepted and transmitted.</p></blockquote><p> In the <i>Novum Organum</i>, English philosopher and scientist Francis Bacon (1561–1626) noted that biased assessment of evidence drove "all superstitions, whether in astrology, dreams, omens, divine judgments or the like". He wrote:
</p><blockquote class="templatequote"><p>The human understanding when it has once adopted an opinion ... draws all things else to support and agree with it. And though there be a greater number and weight of instances to be found on the other side, yet these it either neglects or despises, or else by some distinction sets aside or rejects[.]</p></blockquote>
<p>In the second volume of his <i>The World as Will and Representation</i> (1844), German philosopher Arthur Schopenhauer observed that "An adopted hypothesis gives us lynx-eyes for everything that confirms it and makes us blind to everything that contradicts it."
</p><p>In his essay (1897) <i>What Is Art?</i>, Russian novelist Leo Tolstoy wrote:
</p>
<blockquote class="templatequote"><p>I know that most men—not only those considered clever, but even those who are very clever, and capable of understanding most difficult scientific, mathematical, or philosophic problems—can very seldom discern even the simplest and most obvious truth if it be such as to oblige them to admit the falsity of conclusions they have formed, perhaps with much difficulty—conclusions of which they are proud, which they have taught to others, and on which they have built their lives.</p></blockquote><p> In his essay (1894) <i>The Kingdom of God Is Within You</i>, Tolstoy had earlier written:
</p><blockquote class="templatequote"><p>The most difficult subjects can be explained to the most slow-witted man if he has not formed any idea of them already; but the simplest thing cannot be made clear to the most intelligent man if he is firmly persuaded that he knows already, without a shadow of doubt, what is laid before him.</p></blockquote>
<h3 data-mw-anchor="Hypothesis-testing_(falsification)_explanation_(Wason)" data-mw-fallback-anchor="Hypothesis-testing_.28falsification.29_explanation_.28Wason.29">Hypothesis-testing (falsification) explanation (Wason)</h3>

<p>In Peter Wason's initial experiment published in 1960 (which does not mention the term "confirmation bias"), he repeatedly challenged participants to identify a rule applying to triples of numbers. They were told that (2,4,6) fits the rule. They generated triples, and the experimenter told them whether each triple conformed to the rule.<sup class="reference nowrap"><span title="Page / location: 179">: 179 </span></sup>
</p><p>The actual rule was simply "any ascending sequence", but participants had great difficulty in finding it, often announcing rules that were far more specific, such as "the middle number is the average of the first and last". The participants seemed to test only positive examples—triples that obeyed their hypothesized rule. For example, if they thought the rule was, "Each number is two greater than its predecessor," they would offer a triple that fitted (confirmed) this rule, such as (11,13,15) rather than a triple that violated (falsified) it, such as (11,12,19).
</p><p>Wason interpreted his results as showing a preference for confirmation over falsification, hence he coined the term "confirmation bias". Wason also used confirmation bias to explain the results of his selection task experiment. Participants repeatedly performed badly on various forms of this test, in most cases ignoring information that could potentially refute (falsify) the specified rule.
</p>
<h3 data-mw-anchor="Hypothesis_testing_(positive_test_strategy)_explanation_(Klayman_and_Ha)" data-mw-fallback-anchor="Hypothesis_testing_.28positive_test_strategy.29_explanation_.28Klayman_and_Ha.29">Hypothesis testing (positive test strategy) explanation (Klayman and Ha)</h3>
<p>Klayman and Ha's 1987 paper argues that the Wason experiments do not actually demonstrate a bias towards confirmation, but instead a tendency to make tests consistent with the working hypothesis. They called this the "positive test strategy". This strategy is an example of a heuristic: a reasoning shortcut that is imperfect but easy to compute. Klayman and Ha used Bayesian probability and information theory as their standard of hypothesis-testing, rather than the falsificationism used by Wason. According to these ideas, each answer to a question yields a different amount of information, which depends on the person's prior beliefs. Thus a scientific test of a hypothesis is one that is expected to produce the most information. Since the information content depends on initial probabilities, a positive test can either be highly informative or uninformative. Klayman and Ha argued that when people think about realistic problems, they are looking for a specific answer with a small initial probability. In this case, positive tests are usually more informative than negative tests. However, in Wason's rule discovery task the answer—three numbers in ascending order—is very broad, so positive tests are unlikely to yield informative answers. Klayman and Ha supported their analysis by citing an experiment that used the labels "DAX" and "MED" in place of "fits the rule" and "doesn't fit the rule". This avoided implying that the aim was to find a low-probability rule. Participants had much more success with this version of the experiment.
</p>

<p>In light of this and other critiques, the focus of research moved away from confirmation versus falsification of an hypothesis, to examining whether people test hypotheses in an informative way, or an uninformative but positive way. The search for "true" confirmation bias led psychologists to look at a wider range of effects in how people process information.
</p>
<h2 data-mw-anchor="Information_processing_explanations">Information processing explanations</h2>
<p>There are currently three main information processing explanations of confirmation bias, plus a recent addition.
</p>
<h3 data-mw-anchor="Cognitive_versus_motivational">Cognitive versus motivational</h3>

<p>According to Robert MacCoun, most biased evidence processing occurs through a combination of "cold" (cognitive) and "hot" (motivated) mechanisms.
</p><p>Cognitive explanations for confirmation bias are based on limitations in people's ability to handle complex tasks, and the shortcuts, called <i>heuristics</i>, that they use. For example, people may judge the reliability of evidence by using the <i>availability heuristic</i> that is, how readily a particular idea comes to mind. It is also possible that people can only focus on one thought at a time, so find it difficult to test alternative hypotheses in parallel.<sup class="reference nowrap"><span title="Page / location: 198–199">: 198–199 </span></sup> Another heuristic is the positive test strategy identified by Klayman and Ha, in which people test a hypothesis by examining cases where they expect a property or event to occur. This heuristic avoids the difficult or impossible task of working out how diagnostic each possible question will be. However, it is not universally reliable, so people can overlook challenges to their existing beliefs.<sup class="reference nowrap"><span title="Page / location: 200">: 200 </span></sup>
</p><p>Motivational explanations involve an effect of desire on belief.<sup class="reference nowrap"><span title="Page / location: 197">: 197 </span></sup> It is known that people prefer positive thoughts over negative ones in a number of ways: this is called the "Pollyanna principle". Applied to arguments or sources of evidence, this could explain why desired conclusions are more likely to be believed true. According to experiments that manipulate the desirability of the conclusion, people demand a high standard of evidence for unpalatable ideas and a low standard for preferred ideas. In other words, they ask, "Can I believe this?" for some suggestions and, "Must I believe this?" for others. Although consistency is a desirable feature of attitudes, an excessive drive for consistency is another potential source of bias because it may prevent people from neutrally evaluating new, surprising information. Social psychologist Ziva Kunda combines the cognitive and motivational theories, arguing that motivation creates the bias, but cognitive factors determine the size of the effect.<sup class="reference nowrap"><span title="Page / location: 198">: 198 </span></sup>
</p>
<h3 data-mw-anchor="Cost-benefit">Cost-benefit</h3>
<p>Explanations in terms of cost-benefit analysis assume that people do not just test hypotheses in a disinterested way, but assess the costs of different errors. Using ideas from evolutionary psychology, James Friedrich suggests that people do not primarily aim at truth in testing hypotheses, but try to avoid the most costly errors. For example, employers might ask one-sided questions in job interviews because they are focused on weeding out unsuitable candidates. Yaacov Trope and Akiva Liberman's refinement of this theory assumes that people compare the two different kinds of error: accepting a false hypothesis or rejecting a true hypothesis. For instance, someone who underestimates a friend's honesty might treat him or her suspiciously and so undermine the friendship. Overestimating the friend's honesty may also be costly, but less so. In this case, it would be rational to seek, evaluate or remember evidence of their honesty in a biased way. When someone gives an initial impression of being introverted or extroverted, questions that match that impression come across as more empathic. This suggests that when talking to someone who seems to be an introvert, it is a sign of better social skills to ask, "Do you feel awkward in social situations?" rather than, "Do you like noisy parties?" The connection between confirmation bias and social skills was corroborated by a study of how college students get to know other people. Highly self-monitoring students, who are more sensitive to their environment and to social norms, asked more matching questions when interviewing a high-status staff member than when getting to know fellow students.
</p>
<h3 data-mw-anchor="Exploratory_versus_confirmatory">Exploratory versus confirmatory</h3>
<p>Psychologists Jennifer Lerner and Philip Tetlock distinguish two different kinds of thinking process. <i>Exploratory thought</i> neutrally considers multiple points of view and tries to anticipate all possible objections to a particular position, while <i>confirmatory thought</i> seeks to justify a specific point of view. Lerner and Tetlock say that when people expect to justify their position to others whose views they already know, they will tend to adopt a similar position to those people, and then use confirmatory thought to bolster their own credibility. However, if the external parties are overly aggressive or critical, people will disengage from thought altogether, and simply assert their personal opinions without justification. Lerner and Tetlock say that people only push themselves to think critically and logically when they know in advance they will need to explain themselves to others who are well-informed, genuinely interested in the truth, and whose views they do not already know. Because those conditions rarely exist, they argue, most people are using confirmatory thought most of the time.
</p>
<h3 data-mw-anchor="Make-believe">Make-believe</h3>
<p>Developmental psychologist Eve Whitmore has argued that beliefs and biases involved in confirmation bias have their roots in childhood coping through make-believe, which becomes "the basis for more complex forms of self-deception and illusion into adulthood." The friction brought on by questioning as an adolescent with developing critical thinking can lead to the rationalization of false beliefs, and the habit of such rationalization can become unconscious over the years.
</p>
<h3 data-mw-anchor="Optimal_information_acquisition">Optimal information acquisition</h3>
<p>Recent research in economics has challenged the traditional view of confirmation bias as purely a cognitive flaw. Under conditions where acquiring and processing information is costly, seeking confirmatory evidence can actually be an optimal strategy. Instead of pursuing contrarian or disconfirming evidence, it may be more efficient to focus on sources likely to align with one's existing beliefs, given the constraints on time and resources.
</p><p>Economist Weijie Zhong has developed a model demonstrating that individuals who must make decisions under time pressure, and who face costs for obtaining more information, will often prefer confirmatory signals. According to this model, when individuals believe strongly in a certain hypothesis, they optimally seek information that confirms it, allowing them to build confidence more efficiently. If the expected confirmatory signals are not received, their confidence in the initial hypothesis will gradually decline, leading to belief updating. This approach shows that seeking confirmation is not necessarily biased but may be a rational allocation of limited attention and resources.
</p>
<h2 data-mw-anchor="Real-world_effects">Real-world effects</h2>
<h3 data-mw-anchor="Social_media">Social media</h3>
<p>In social media, confirmation bias is amplified by the use of filter bubbles, or "algorithmic editing", which displays to individuals only information they are likely to agree with, while excluding opposing views. Some have argued that confirmation bias is the reason why society can never escape from filter bubbles, because individuals are psychologically hardwired to seek information that agrees with their preexisting values and beliefs. Others have further argued that the mixture of the two is degrading democracy—claiming that this "algorithmic editing" removes diverse viewpoints and information—and that unless filter bubble algorithms are removed, voters will be unable to make fully informed political decisions.
</p><p>The rise of social media has contributed greatly to the rapid spread of fake news, that is, false and misleading information that is presented as credible news from a seemingly reliable source. Confirmation bias (selecting or reinterpreting evidence to support one's beliefs) is one of three main hurdles cited as to why critical thinking goes astray in these circumstances. The other two are shortcut heuristics (when overwhelmed or short of time, people rely on simple rules such as group consensus or trusting an expert or role model) and social goals (social motivation or peer pressure can interfere with objective analysis of facts at hand).
</p><p>In combating the spread of fake news, social media sites have considered turning toward "digital nudging". This can currently be done in two different forms of nudging. This includes nudging of information and nudging of presentation. Nudging of information entails social media sites providing a disclaimer or label questioning or warning users of the validity of the source while nudging of presentation includes exposing users to new information which they may not have sought out but could introduce them to viewpoints that may combat their own confirmation biases.
</p>
<h3 data-mw-anchor="Science_and_scientific_research">Science and scientific research</h3>

<p>A distinguishing feature of scientific thinking is the search for confirming or supportive evidence (inductive reasoning) as well as falsifying evidence (deductive reasoning).
</p><p>Many times in the history of science, scientists have resisted new discoveries by selectively interpreting or ignoring unfavorable data.<sup class="reference nowrap"><span title="Page / location: 192–194">: 192–194 </span></sup> Several studies have shown that scientists rate studies that report findings consistent with their prior beliefs more favorably than studies reporting findings inconsistent with their previous beliefs.
</p><p>However, assuming that the research question is relevant, the experimental design adequate and the data are clearly and comprehensively described, the empirical data obtained should be important to the scientific community and should not be viewed prejudicially, regardless of whether they conform to current theoretical predictions. In practice, researchers may misunderstand, misinterpret, or not read at all studies that contradict their preconceptions, or wrongly cite them anyway as if they actually supported their claims.
</p><p>Further, confirmation biases can sustain scientific theories or research programs in the face of inadequate or even contradictory evidence. The discipline of parapsychology is often cited as an example.
</p><p>An experimenter's confirmation bias can potentially affect which data are reported. Data that conflict with the experimenter's expectations may be more readily discarded as unreliable, producing the so-called file drawer effect. To combat this tendency, scientific training teaches ways to prevent bias. For example, experimental design of randomized controlled trials (coupled with their systematic review) aims to minimize sources of bias.
</p><p>The social process of peer review aims to mitigate the effect of individual scientists' biases, even though the peer review process itself may be susceptible to such biases Confirmation bias may thus be especially harmful to objective evaluations regarding nonconforming results since biased individuals may regard opposing evidence to be weak in principle and give little serious thought to revising their beliefs. Scientific innovators often meet with resistance from the scientific community, and research presenting controversial results frequently receives harsh peer review.
</p>
<h3 data-mw-anchor="Finance">Finance</h3>

<p>Confirmation bias can lead investors to be overconfident, ignoring evidence that their strategies will lose money. In studies of political stock markets, investors made more profit when they resisted bias. For example, participants who interpreted a candidate's debate performance in a neutral rather than partisan way were more likely to profit. To combat the effect of confirmation bias, investors can try to adopt a contrary viewpoint "for the sake of argument". In one technique, they imagine that their investments have collapsed and ask themselves why this might happen.
</p>
<h3 data-mw-anchor="Medicine_and_health">Medicine and health</h3>
<p>Cognitive biases are important variables in clinical decision-making by medical general practitioners (GPs) and medical specialists. Two important ones are confirmation bias and the overlapping availability bias. A GP may make a diagnosis early on during an examination, and then seek confirming evidence rather than falsifying evidence. This cognitive error is partly caused by the availability of evidence about the supposed disorder being diagnosed. For example, the client may have mentioned the disorder, or the GP may have recently read a much-discussed paper about the disorder. The basis of this cognitive shortcut or heuristic (termed anchoring) is that the doctor does not consider multiple possibilities based on evidence, but prematurely latches on (or anchors to) a single cause. In emergency medicine, because of time pressure, there is a high density of decision-making, and shortcuts are frequently applied. The potential failure rate of these cognitive decisions needs to be managed by education about the 30 or more cognitive biases that can occur, so as to set in place proper debiasing strategies. Confirmation bias may also cause doctors to perform unnecessary medical procedures due to pressure from adamant patients.
</p><p>Raymond Nickerson, a psychologist, blames confirmation bias for the ineffective medical procedures that were used for centuries before the arrival of scientific medicine.<sup class="reference nowrap"><span title="Page / location: 192">: 192 </span></sup> If a patient recovered, medical authorities counted the treatment as successful, rather than looking for alternative explanations such as that the disease had run its natural course. Biased assimilation is a factor in the modern appeal of alternative medicine, whose proponents are swayed by positive anecdotal evidence but treat scientific evidence hyper-critically.
</p><p>Cognitive therapy was developed by Aaron T. Beck in the early 1960s and has become a popular approach. According to Beck, biased information processing is a factor in depression. His approach teaches people to treat evidence impartially, rather than selectively reinforcing negative outlooks. Phobias and hypochondria have also been shown to involve confirmation bias for threatening information.
</p>
<h3 data-mw-anchor="Politics,_law_and_policing" data-mw-fallback-anchor="Politics.2C_law_and_policing">Politics, law and policing</h3>

<p>Nickerson argues that reasoning in judicial and political contexts is sometimes subconsciously biased, favoring conclusions that judges, juries or governments have already committed to.<sup class="reference nowrap"><span title="Page / location: 191–193">: 191–193 </span></sup> Since the evidence in a jury trial can be complex, and jurors often reach decisions about the verdict early on, it is reasonable to expect an attitude polarization effect. The prediction that jurors will become more extreme in their views as they see more evidence has been borne out in experiments with mock trials. Both inquisitorial and adversarial criminal justice systems are affected by confirmation bias.
</p><p>Confirmation bias can be a factor in creating or extending conflicts, from emotionally charged debates to wars: by interpreting the evidence in their favor, each opposing party can become overconfident that it is in the stronger position. On the other hand, confirmation bias can result in people ignoring or misinterpreting the signs of an imminent or incipient conflict. For example, psychologists Stuart Sutherland and Thomas Kida have each argued that U.S. Navy Admiral Husband E. Kimmel showed confirmation bias when playing down the first signs of the Japanese attack on Pearl Harbor.
</p><p>A two-decade study of political pundits by Philip E. Tetlock found that, on the whole, their predictions were not much better than chance. Tetlock divided experts into "foxes" who maintained multiple hypotheses, and "hedgehogs" who were more dogmatic. In general, the hedgehogs were much less accurate. Tetlock blamed their failure on confirmation bias, and specifically on their inability to make use of new information that contradicted their existing theories.
</p><p>In police investigations, a detective may identify a suspect early in an investigation, but then sometimes largely seek supporting or confirming evidence, ignoring or downplaying falsifying evidence.
</p>
<h3 data-mw-anchor="Social_psychology">Social psychology</h3>
<p>Social psychologists have identified two tendencies in the way people seek or interpret information about themselves. <i>Self-verification</i> is the drive to reinforce the existing self-image and <i>self-enhancement</i> is the drive to seek positive feedback. Both are served by confirmation biases. In experiments where people are given feedback that conflicts with their self-image, they are less likely to attend to it or remember it than when given self-verifying feedback. They reduce the impact of such information by interpreting it as unreliable. Similar experiments have found a preference for positive feedback, and the people who give it, over negative feedback.
</p>
<h3 data-mw-anchor="Mass_delusions">Mass delusions</h3>
<p>Confirmation bias can play a key role in the propagation of mass delusions. Witch trials are frequently cited as an example.
</p><p>For another example, in the Seattle windshield pitting epidemic, there seemed to be a "pitting epidemic" in which windshields were damaged due to an unknown cause. As news of the apparent wave of damage spread, more and more people checked their windshields, discovered that their windshields too had been damaged, thus confirming belief in the supposed epidemic. In fact, the windshields were previously damaged, but the damage went unnoticed until people checked their windshields as the delusion spread.
</p>
<h3 data-mw-anchor="Paranormal_beliefs">Paranormal beliefs</h3>
<p>One factor in the appeal of alleged psychic readings is that listeners apply a confirmation bias which fits the psychic's statements to their own lives. By making a large number of ambiguous statements in each sitting, the psychic gives the client more opportunities to find a match. This is one of the techniques of cold reading, with which a psychic can deliver a subjectively impressive reading without any prior information about the client. Investigator James Randi compared the transcript of a reading to the client's report of what the psychic had said, and found that the client showed a strong selective recall of the "hits".
</p><p>As a striking illustration of confirmation bias in the real world, Nickerson mentions numerological pyramidology: the practice of finding meaning in the proportions of the Egyptian pyramids.<sup class="reference nowrap"><span title="Page / location: 190">: 190 </span></sup> There are many different length measurements that can be made of, for example, the Great Pyramid of Giza and many ways to combine or manipulate them. Hence it is almost inevitable that people who look at these numbers selectively will find superficially impressive correspondences, for example with the dimensions of the Earth.<sup class="reference nowrap"><span title="Page / location: 190">: 190 </span></sup>
</p>
<h3 data-mw-anchor="Recruitment_and_selection">Recruitment and selection</h3>
<p>Unconscious cognitive bias (including confirmation bias) in job recruitment affects hiring decisions and can potentially prohibit a diverse and inclusive workplace. There are a variety of unconscious biases that affects recruitment decisions but confirmation bias is one of the major ones, especially during the interview stage. The interviewer will often select a candidate that confirms their own beliefs, even though other candidates are equally or better qualified.
</p>
<h2 data-mw-anchor="Associated_effects_and_outcomes">Associated effects and outcomes</h2>
<h3 data-mw-anchor="Polarization_of_opinion">Polarization of opinion</h3>

<p>When people with opposing views interpret new information in a biased way, their views can move even further apart. This is called "attitude polarization". The effect was demonstrated by an experiment that involved drawing a series of red and black balls from one of two concealed "bingo baskets". Participants knew that one basket contained 60 percent black and 40 percent red balls; the other, 40 percent black and 60 percent red. The experimenters looked at what happened when balls of alternating color were drawn in turn, a sequence that does not favor either basket. After each ball was drawn, participants in one group were asked to state out loud their judgments of the probability that the balls were being drawn from one or the other basket. These participants tended to grow more confident with each successive draw—whether they initially thought the basket with 60 percent black balls or the one with 60 percent red balls was the more likely source, their estimate of the probability increased. Another group of participants were asked to state probability estimates only at the end of a sequence of drawn balls, rather than after each ball. They did not show the polarization effect, suggesting that it does not necessarily occur when people simply hold opposing positions, but rather when they openly commit to them.
</p><p>A less abstract study was the Stanford biased interpretation experiment, in which participants with strong opinions about the death penalty read about mixed experimental evidence. Twenty-three percent of the participants reported that their views had become more extreme, and this self-reported shift correlated strongly with their initial attitudes. In later experiments, participants also reported their opinions becoming more extreme in response to ambiguous information. However, comparisons of their attitudes before and after the new evidence showed no significant change, suggesting that the self-reported changes might not be real. Based on these experiments, Deanna Kuhn and Joseph Lao concluded that polarization is a real phenomenon but far from inevitable, only happening in a small minority of cases, and it was prompted not only by considering mixed evidence, but by merely thinking about the topic.
</p><p>Charles Taber and Milton Lodge argued that the Stanford team's result had been hard to replicate because the arguments used in later experiments were too abstract or confusing to evoke an emotional response. The Taber and Lodge study used the emotionally charged topics of gun control and affirmative action. They measured the attitudes of their participants towards these issues before and after reading arguments on each side of the debate. Two groups of participants showed attitude polarization: those with strong prior opinions and those who were politically knowledgeable. In part of this study, participants chose which information sources to read, from a list prepared by the experimenters. For example, they could read arguments on gun control from the National Rifle Association of America and the Brady Anti-Handgun Coalition. Even when instructed to be even-handed, participants were more likely to read arguments that supported their existing attitudes than arguments that did not. This biased search for information correlated well with the polarization effect.
</p><p>The <b><span><span id="backfire_effect"></span><span>backfire effect</span></span></b> is a name for the finding that given evidence against their beliefs, people can reject the evidence and believe even more strongly. The phrase was coined by Brendan Nyhan and Jason Reifler in 2010. However, subsequent research has since failed to replicate findings supporting the backfire effect. One study conducted out of the Ohio State University and George Washington University studied 10,100 participants with 52 different issues expected to trigger a backfire effect. While the findings did conclude that individuals are reluctant to embrace facts that contradict their already held ideology, no cases of backfire were detected. The backfire effect has since been noted to be a rare phenomenon rather than a common occurrence (compare the boomerang effect).
</p>
<h3 data-mw-anchor="Persistence_of_discredited_beliefs">Persistence of discredited beliefs</h3>



<p>Confirmation biases provide one plausible explanation for the persistence of beliefs when the initial evidence for them is removed or when they have been sharply contradicted.<sup class="reference nowrap"><span title="Page / location: 187">: 187 </span></sup> This belief perseverance effect has been first demonstrated experimentally by Festinger, Riecken, and Schachter. These psychologists spent time with a cult whose members were convinced that the world would end on 21 December 1954. After the prediction failed, most believers still clung to their faith. Their book describing this research is aptly named <i>When Prophecy Fails</i>.
</p><p>The term <i>belief perseverance</i>, however, was coined in a series of experiments using what is called the "debriefing paradigm": participants read fake evidence for a hypothesis, their attitude change is measured, then the fakery is exposed in detail. Their attitudes are then measured once more to see if their belief returns to its previous level.
</p><p>A common finding is that at least some of the initial belief remains even after a full debriefing. In one experiment, participants had to distinguish between real and fake suicide notes. The feedback was random: some were told they had done well while others were told they had performed badly. Even after being fully debriefed, participants were still influenced by the feedback. They still thought they were better or worse than average at that kind of task, depending on what they had initially been told.
</p><p>In another study, participants read job performance ratings of two firefighters, along with their responses to a risk aversion test. This fictional data was arranged to show either a negative or positive association: some participants were told that a risk-taking firefighter did better, while others were told they did less well than a risk-averse colleague. Even if these two case studies were true, they would have been scientifically poor evidence for a conclusion about firefighters in general. However, the participants found them subjectively persuasive. When the case studies were shown to be fictional, participants' belief in a link diminished, but around half of the original effect remained. Follow-up interviews established that the participants had understood the debriefing and taken it seriously. Participants seemed to trust the debriefing, but regarded the discredited information as irrelevant to their personal belief.
</p><p>The continued influence effect is the tendency for misinformation to continue to influence memory and reasoning about an event, despite the misinformation having been retracted or corrected. This occurs even when the individual believes the correction.
</p>
<h3 data-mw-anchor="Preference_for_early_information">Preference for early information</h3>
<p>Experiments have shown that information is weighted more strongly when it appears early in a series, even when the order is unimportant. For example, people form a more positive impression of someone described as "intelligent, industrious, impulsive, critical, stubborn, envious" than when they are given the same words in reverse order. This <i>irrational primacy effect</i> is independent of the primacy effect in memory in which the earlier items in a series leave a stronger memory trace. Biased interpretation offers an explanation for this effect: seeing the initial evidence, people form a working hypothesis that affects how they interpret the rest of the information.<sup class="reference nowrap"><span title="Page / location: 187">: 187 </span></sup>
</p><p>One demonstration of irrational primacy used colored chips supposedly drawn from two urns. Participants were told the color distributions of the urns, and had to estimate the probability of a chip being drawn from one of them. In fact, the colors appeared in a prearranged order. The first thirty draws favored one urn and the next thirty favored the other.<sup class="reference nowrap"><span title="Page / location: 187">: 187 </span></sup> The series as a whole was neutral, so rationally, the two urns were equally likely. However, after sixty draws, participants favored the urn suggested by the initial thirty.
</p><p>Another experiment involved a slide show of a single object, seen as just a blur at first and in slightly better focus with each succeeding slide. After each slide, participants had to state their best guess of what the object was. Participants whose early guesses were wrong persisted with those guesses, even when the picture was sufficiently in focus that the object was readily recognizable to other people.<sup class="reference nowrap"><span title="Page / location: 187">: 187 </span></sup>
</p>
<h3 data-mw-anchor="Illusory_association_between_events">Illusory association between events</h3>

<p>Illusory correlation is the tendency to see non-existent correlations in a set of data. This tendency was first demonstrated in a series of experiments in the late 1960s. In one experiment, participants read a set of psychiatric case studies, including responses to the Rorschach inkblot test. The participants reported that the homosexual men in the set were more likely to report seeing buttocks, anuses or sexually ambiguous figures in the inkblots. In fact the fictional case studies had been constructed so that the homosexual men were no more likely to report this imagery or, in one version of the experiment, were less likely to report it than heterosexual men. In a survey, a group of experienced psychoanalysts reported the same set of illusory associations with homosexuality.
</p><p>Another study recorded the symptoms experienced by arthritic patients, along with weather conditions over a 15-month period. Nearly all the patients reported that their pains were correlated with weather conditions, although the real correlation was zero.
</p>

<p>This effect is a kind of biased interpretation, in that objectively neutral or unfavorable evidence is interpreted to support existing beliefs. It is also related to biases in hypothesis-testing behavior. In judging whether two events, such as illness and bad weather, are correlated, people rely heavily on the number of <i>positive-positive</i> cases: in this example, instances of both pain and bad weather. They pay relatively little attention to the other kinds of observation (of no pain or good weather). This parallels the reliance on positive tests in hypothesis testing. It may also reflect selective recall, in that people may have a sense that two events are correlated because it is easier to recall times when they happened together.
</p>
<h2 data-mw-anchor="See_also">See also</h2>


<h2 data-mw-anchor="Notes">Notes</h2>

<h2 data-mw-anchor="References">References</h2>
<h3 data-mw-anchor="Citations">Citations</h3>

<h3 data-mw-anchor="Sources">Sources</h3>

<h2 data-mw-anchor="Further_reading">Further reading</h2>
<ul><li><cite id="CITEREFLeavitt2015" class="citation cs2">Leavitt, Fred (2015), <i>Dancing with absurdity: Your most cherished beliefs (and all your others) are probably wrong</i>, Peter Lang Publishers, ISBN <bdi>9781453914908</bdi>, OCLC 908685982</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Dancing+with+absurdity%3A+Your+most+cherished+beliefs+%28and+all+your+others%29+are+probably+wrong&amp;rft.pub=Peter+Lang+Publishers&amp;rft.date=2015&amp;rft_id=info%3Aoclcnum%2F908685982&amp;rft.isbn=9781453914908&amp;rft.aulast=Leavitt&amp;rft.aufirst=Fred&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AConfirmation+bias"></span></li>
<li><cite id="CITEREFStanovich2009" class="citation cs2">Stanovich, Keith (2009), <i>What intelligence tests miss: The psychology of rational thought</i> (Lay), New Haven (CT): Yale University Press, ISBN <bdi>978-0-300-12385-2</bdi></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=What+intelligence+tests+miss%3A+The+psychology+of+rational+thought&amp;rft.place=New+Haven+%28CT%29&amp;rft.pub=Yale+University+Press&amp;rft.date=2009&amp;rft.isbn=978-0-300-12385-2&amp;rft.aulast=Stanovich&amp;rft.aufirst=Keith&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fwhatintelligence00stan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AConfirmation+bias"></span></li>
<li><cite id="CITEREFWesten2007" class="citation cs2">Westen, Drew (2007), <i>The political brain: The role of emotion in deciding the fate of the nation</i>, PublicAffairs, ISBN <bdi>978-1-58648-425-5</bdi>, OCLC 86117725</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+political+brain%3A+The+role+of+emotion+in+deciding+the+fate+of+the+nation&amp;rft.pub=PublicAffairs&amp;rft.date=2007&amp;rft_id=info%3Aoclcnum%2F86117725&amp;rft.isbn=978-1-58648-425-5&amp;rft.aulast=Westen&amp;rft.aufirst=Drew&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fpoliticalbrainro00west&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AConfirmation+bias"></span></li>
<li>Meppelink, Corine S., Edith G. Smit, Marieke L. Fransen, and Nicola Diviani. “‘I Was Right about Vaccination’: Confirmation Bias and Health Literacy in Online Health Information Seeking.” Journal of Health Communication 24, no. 2 (2019): 129–40. https://doi.org/10.1080/10810730.2019.1583701.</li></ul>
<ul><li>Pearson, George David Hooke, and Silvia Knobloch-Westerwick. “Is the Confirmation Bias Bubble Larger Online? Pre-Election Confirmation Bias in Selective Exposure to Online versus Print Political Information.” Mass Communication &amp; Society 22, no. 4 (2019): 466–86. https://doi.org/10.1080/15205436.2019.1599956.</li></ul>
<h2 data-mw-anchor="External_links">External links</h2>

<ul><li>Skeptic's Dictionary: confirmation bias – Robert T. Carroll</li>
<li>Teaching about confirmation bias – class handout and instructor's notes by K.H. Grobman</li>
<li>Confirmation bias at You Are Not So Smart</li>
<li>Confirmation bias learning object – interactive number triples exercise by Rod McFarland for Simon Fraser University</li>
<li>Brief summary of the 1979 Stanford assimilation bias study – Keith Rollag, Babson College</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Confirmation_bias#continued_influence_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Semmelweis reflex</h2>
<a href='https://en.wikipedia.org/wiki/Semmelweis_reflex' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>Semmelweis reflex</b> or "<b>Semmelweis effect</b>" is a metaphor for the reflex-like tendency to reject new evidence or new knowledge because it contradicts established norms, beliefs, or paradigms.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Semmelweis_reflex'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Bias blind spot</h2>
<a href='https://en.wikipedia.org/wiki/Bias_blind_spot' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>bias blind spot</b> is the cognitive bias of recognizing the impact of biases on the judgment of others, while failing to see the impact of biases on one's own judgment. The term was created by Emily Pronin, a social psychologist from Princeton University's Department of Psychology, with colleagues Daniel Lin and Lee Ross. The bias blind spot is named after the visual blind spot. Most people appear to exhibit the bias blind spot. In a sample of more than 600 residents of the United States, more than 85% believed they were less biased than the average American. Only one participant believed that they were more biased than the average American. People do vary with regard to the extent to which they exhibit the bias blind spot. This phenomenon has been successfully replicated and it appears that in general, stronger personal free will beliefs are associated with bias blind spot. It appears to be a stable individual difference that is measurable.
</p><p>The bias blind spot appears to be a true blind spot in that it is unrelated to actual decision making ability. Performance on indices of decision making competence are not related to individual differences in bias blind spot. In other words, most people appear to believe that they are less biased than others, regardless of their actual decision making ability.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Bias_blind_spot'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Naïve cynicism</h2>
<a href='https://en.wikipedia.org/wiki/Naïve_cynicism' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Naïve cynicism</b> is a philosophy of mind, cognitive bias and form of psychological egoism that occurs when people naïvely expect more egocentric bias in others than actually is the case.
</p>

<p>The term was formally proposed by Justin Kruger and Thomas Gilovich and has been studied across a wide range of contexts including: negotiations, group-membership, marriage, economics, government policy and more.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Naïve_cynicism'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Naïve realism</h2>
<a href='https://en.wikipedia.org/wiki/Naïve_realism_(psychology)' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In social psychology, <b>naïve realism</b> is the human tendency to believe that we see the world around us objectively, and that people who disagree with us must be uninformed, irrational, or biased.
</p><p>Naïve realism provides a theoretical basis for several other cognitive biases, which are systematic errors when it comes to thinking and making decisions. These include the false consensus effect, actor–observer bias, bias blind spot, and fundamental attribution error, among others.
</p><p>The term, as it is used in psychology today, was coined by social psychologist Lee Ross and his colleagues in the 1990s. It is related to the philosophical concept of naïve realism, which is the idea that our senses allow us to perceive objects directly and without any intervening processes. Social psychologists in the mid-20th century argued against this stance and proposed instead that perception is inherently subjective.
</p><p>Several prominent social psychologists have studied naïve realism experimentally, including Lee Ross, Andrew Ward, Dale Griffin, Emily Pronin, Thomas Gilovich, Robert Robinson, and Dacher Keltner. In 2010, the <i>Handbook of Social Psychology</i> recognized naïve realism as one of "four hard-won insights about human perception, thinking, motivation and behavior that ... represent important, indeed foundational, contributions of social psychology."
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Naïve_realism_(psychology)'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Confabulation</h2>
<a href='https://en.wikipedia.org/wiki/Confabulation' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Confabulation</b> is a memory error consisting of the production of fabricated, distorted, or misinterpreted memories about oneself or the world. It is generally associated with certain types of brain damage (especially aneurysm in the anterior communicating artery) or a specific subset of dementias. While still an area of ongoing research, the basal forebrain is implicated in the phenomenon of confabulation. People who confabulate present with incorrect memories ranging from subtle inaccuracies to surreal fabrications, and may include confusion or distortion in the temporal framing (timing, sequence or duration) of memories. In general, they are very confident about their recollections, even when challenged with contradictory evidence.
</p><p>Confabulation occurs when individuals mistakenly recall false information, without intending to deceive. Brain damage, dementia, and anticholinergic toxidrome can cause this distortion. Two types of confabulation exist: provoked and spontaneous, with two distinctions: verbal and behavioral. Verbal statements, false information, and the patient's unawareness of the distortion are all associated with this phenomenon. Personality structure also plays a role in confabulation.
</p><p>Numerous theories have been developed to explain confabulation. Neuro­psycho­log­i­cal theories suggest that cognitive dysfunction causes the distortion. Self-identity theories posit that people confabulate to preserve themselves. The temporality theory believes that confabulation occurs when an individual cannot place events properly in time. The monitoring and strategic retrieval account theories argue that confabulation arises when individuals cannot recall memories correctly or monitor them after retrieval. The executive control and fuzzy-trace theories also attempt to explain why confabulation happens.
</p><p>Confabulation can occur with nervous system injuries or illnesses, including Korsakoff's syndrome, Alzheimer's disease, schizophrenia, and traumatic brain injury. It is believed that the right frontal lobe of the brain is damaged, causing false memories. Children are especially susceptible to forced confabulation as they are highly impressionable. Feedback can increase confidence in false memories. In rare cases, confabulation occurs in ordinary individuals.
</p><p>Different memory tests, including recognition tasks and free recall tasks, can be used to study confabulation. Treatment depends on the underlying cause of the distortion. Ongoing research aims to develop a standard test battery to discern between different types of confabulations, distinguish delusions from confabulations, understand the role of unconscious processes, and identify pathological and nonpathological confabulations.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Confabulation'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Clustering illusion</h2>
<a href='https://en.wikipedia.org/wiki/Clustering_illusion' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>clustering illusion</b> is the tendency to erroneously consider the inevitable "streaks" or "clusters" arising in small samples from random distributions to be non-random. The illusion is caused by a human tendency to underpredict the amount of variability likely to appear in a small sample of random or pseudorandom data.
</p>

<p>Thomas Gilovich, an early author on the subject, argued that the effect occurs for different types of random dispersions. Some might perceive patterns in stock market price fluctuations over time, or clusters in two-dimensional data such as the locations of impact of World War II V-1 flying bombs on maps of London. Although Londoners developed specific theories about the pattern of impacts within London, a statistical analysis by R. D. Clarke originally published in 1946 showed that the impacts of V-2 rockets on London were a close fit to a random distribution.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Clustering_illusion'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Insensitivity to sample size</h2>
<a href='https://en.wikipedia.org/wiki/Insensitivity_to_sample_size' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Insensitivity to sample size</b> is a cognitive bias that occurs when people judge the probability of obtaining a sample statistic without respect to the sample size. For example, in one study, subjects assigned the same probability to the likelihood of obtaining a mean height of above six feet [183 cm] in samples of 10, 100, and 1,000 men. In other words, variation is more likely in smaller samples, but people may not expect this.
</p><p>In another example, Amos Tversky and Daniel Kahneman asked subjects
</p>
<blockquote><p>A certain town is served by two hospitals. In the larger hospital about 45 babies are born each day, and in the smaller hospital about 15 babies are born each day. As you know, about 50% of all babies are boys. However, the exact percentage varies from day to day. Sometimes it may be higher than 50%, sometimes lower.
</p><p>For a period of 1 year, each hospital recorded the days on which more than 60% of the babies born were boys. Which hospital do you think recorded more such days?
</p>
<ol><li>The larger hospital</li>
<li>The smaller hospital</li>
<li>About the same (that is, within 5% of each other)</li></ol>
</blockquote>
<p>56% of subjects chose option 3, and 22% of subjects respectively chose options 1 or 2. However, according to sampling theory the larger hospital is much more likely to report a sex ratio close to 50% on a given day than the smaller hospital which requires that the correct answer to the question is the smaller hospital (see the law of large numbers).
</p><p>Relative neglect of sample size were obtained in a different study of statistically sophisticated psychologists.
</p><p>Tversky and Kahneman explained these results as being caused by the representativeness heuristic, according to which people intuitively judge samples as having similar properties to their population without taking other considerations into effect. A related bias is the clustering illusion, in which people under-expect streaks or runs in small samples. Insensitivity to sample size is a subtype of extension neglect.
</p><p>To illustrate this point, Howard Wainer and Harris L. Zwerling demonstrated that kidney cancer rates are lowest in counties that are mostly rural, sparsely populated, and located in traditionally Republican states in the Midwest, the South, and the West, but that they are also <i>highest</i> in counties that are mostly rural, sparsely populated, and located in traditionally Republican states in the Midwest, the South, and the West. While various environmental and economic reasons could be advanced for these facts, Wainer and Zwerlig argue that this is an artifact of sample size.  Because of the small sample size, the incidence of a certain kind of cancer in small rural counties is more likely to be further from the mean, in one direction or another, than the incidence of the same kind of cancer in much more heavily populated urban counties.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Insensitivity_to_sample_size'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Neglect of probability</h2>
<a href='https://en.wikipedia.org/wiki/Neglect_of_probability' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>neglect of probability</b>, a type of cognitive bias, is the tendency to disregard probability when making a decision under uncertainty and is one simple way in which people regularly violate the normative rules for decision making. Small risks are typically either neglected entirely or hugely overrated. The continuum between the extremes is ignored. The term <b>probability neglect</b> was coined by Cass Sunstein.
</p><p>There are many related ways in which people violate the normative rules of decision making with regard to probability including the hindsight bias, the neglect of prior base rates effect, and the gambler's fallacy. However, this bias is different, in that, rather than incorrectly using probability, the actor disregards it.
</p><p>"We have no intuitive grasp of risk and thus distinguish poorly among different threats," Dobelli has written. "The more serious the threat and the more emotional the topic (such as radioactivity), the less reassuring a reduction in risk seems to us."
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Neglect_of_probability'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Anecdotal fallacy</h2>
<a href='https://en.wikipedia.org/wiki/Anecdotal_evidence' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Anecdotal evidence</b> (or <b>anecdata</b>) is evidence based on descriptions and reports of individual, personal experiences, or observations, collected in a non-systematic manner.
</p><p>The term <i>anecdotal</i> encompasses a variety of forms of evidence. This word refers to personal experiences, self-reported claims, or eyewitness accounts of others, including those from fictional sources, making it a broad category that can lead to confusion due to its varied interpretations.
</p><p>Anecdotal evidence can be true or false but is not usually subjected to the methodology of scholarly method, the scientific method, or the rules of legal, historical, academic, or intellectual rigor, meaning that there are little or no safeguards against fabrication or inaccuracy. However, the use of anecdotal reports in advertising or promotion of a product, service, or idea may be considered a testimonial, which is highly regulated in certain jurisdictions.
</p><p>The persuasiveness of anecdotal evidence compared to that of statistical evidence has been a subject of debate; some studies have argued for the presence a generalized tendency to overvalue anecdotal evidence, whereas others have emphasized the types of argument as a prerequisite or rejected the conclusion altogether.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Anecdotal_evidence'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Illusion of validity</h2>
<a href='https://en.wikipedia.org/wiki/Illusion_of_validity' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Illusion of validity</b> is a cognitive bias in which a person overestimates their ability to interpret and predict accurately the outcome when analyzing a set of data, in particular when the data analyzed show a very consistent pattern—that is, when the data "tell" a coherent story.
</p><p>This effect persists even when the person is aware of all the factors that limit the accuracy of their predictions, that is when the data and/or methods used to judge them lead to highly fallible predictions.
</p><p>Daniel Kahneman, Paul Slovic, and Amos Tversky explain the illusion as follows: "people often predict by selecting the output...that is most representative of the input....The confidence they have in their prediction depends primarily on the degree of representativeness...with little or no regard for the factors that limit predictive accuracy. Thus, people express great confidence in the prediction that a person is a librarian when given a description of his personality which matches the stereotype of librarians, even if the description is scanty, unreliable, or outdated. The unwarranted confidence which is produced by a good fit between the predicted outcome and the input information may be called the illusion of validity."
</p><p>Consistent patterns may be observed when input variables are highly redundant or correlated, which may increase subjective confidence. However, a number of highly correlated inputs should not increase confidence much more than only one of the inputs; instead higher confidence should be merited when a number of highly <i>independent</i> inputs show a consistent pattern.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Illusion_of_validity'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Masked–man fallacy</h2>
<a href='https://en.wikipedia.org/wiki/Masked-man_fallacy' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In philosophical logic, the <b>masked-man fallacy</b> (also known as the <b>intensional fallacy</b> or <b>epistemic fallacy</b>) is committed when one makes an illicit use of Leibniz's law in an argument. Leibniz's law states that if A and B are the same object, then A and B are indiscernible (that is, they have all the same properties). By <i>modus tollens</i>, this means that if one object has a certain property, while another object does not have the same property, the two objects cannot be identical. The fallacy is "epistemic" because it posits an immediate identity between a subject's knowledge of an object with the object itself, failing to recognize that Leibniz's Law is not capable of accounting for intensional contexts.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Masked-man_fallacy'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Recency illusion</h2>
<a href='https://en.wikipedia.org/wiki/Recency_illusion' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>recency illusion</b> is the belief or impression, on the part of someone who has only recently become aware of a long-established phenomenon, that the phenomenon itself must be of recent origin. The term was coined by Arnold Zwicky, a linguist at Stanford University who is primarily interested in examples involving words, meanings, phrases, and grammatical constructions. However, use of the term is not restricted to linguistic phenomena: Zwicky has defined it simply as, "the belief that things <i>you</i> have noticed only recently are in fact recent".
</p><p>According to Zwicky, the illusion is caused by selective attention.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Recency_illusion'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Gambler's fallacy</h2>
<a href='https://en.wikipedia.org/wiki/Gambler's_fallacy' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>gambler's fallacy</b>, also known as the <b>Monte Carlo fallacy</b> or the <b>fallacy of the maturity of chances</b>, is the belief that, if an event (whose occurrences are independent and identically distributed) has occurred less frequently than expected, it is more likely to happen again in the future (or vice versa). The fallacy is commonly associated with gambling, where it may be believed, for example, that the next dice roll is more likely to be six than is usually the case because there have recently been fewer than the expected number of sixes.
</p><p>The term  "Monte Carlo fallacy" originates from an example of the phenomenon, in which the roulette wheel spun black 26 times in succession at the Monte Carlo Casino in 1913.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Gambler's_fallacy'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Hot–hand fallacy</h2>
<a href='https://en.wikipedia.org/wiki/Hot-hand_fallacy' target='_blank'>Wikipedia Link</a>
<div class='content'></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Hot-hand_fallacy'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Illusory correlation</h2>
<a href='https://en.wikipedia.org/wiki/Illusory_correlation' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In psychology, <b>illusory correlation</b> is the phenomenon of perceiving a relationship between variables (typically people, events, or behaviors) even when no such relationship exists. A false association may be formed because rare or novel occurrences are more salient and therefore tend to capture one's attention. This phenomenon is one way stereotypes form and endure. Hamilton &amp; Rose (1980) found that stereotypes can lead people to expect certain groups and traits to fit together, and then to overestimate the frequency with which these correlations actually occur. These stereotypes can be learned and perpetuated without any actual contact occurring between the holder of the stereotype and the group it is about.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Illusory_correlation'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Pareidolia</h2>
<a href='https://en.wikipedia.org/wiki/Pareidolia' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>
<p><b>Pareidolia</b> (<span></span>; <span><span>also US: </span></span>) is the tendency for perception to impose a meaningful interpretation on a nebulous stimulus, usually visual, so that one detects an object, pattern, or meaning where there is none. Pareidolia is a specific but common type of apophenia (the tendency to perceive meaningful connections between unrelated things or ideas).
</p><p>Common examples include perceived images of animals, faces, or objects in cloud formations; seeing faces in inanimate objects; or lunar pareidolia like the Man in the Moon or the Moon rabbit. The concept of pareidolia may extend to include hidden messages in recorded music played in reverse or at higher- or lower-than-normal speeds, and hearing voices (mainly indistinct) or music in random noise, such as that produced by air conditioners or by fans. Face pareidolia has also been demonstrated in rhesus macaques.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Pareidolia'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Anthropomorphism</h2>
<a href='https://en.wikipedia.org/wiki/Anthropomorphism#Psychology' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">


</p>


<p><b>Anthropomorphism</b> is the attribution of human traits, emotions, or intentions to non-human entities. It is considered to be an innate tendency of human psychology. Personification is the related attribution of human form and characteristics to abstract concepts such as nations, emotions, and natural forces, such as seasons and weather. Both have ancient roots as storytelling and artistic devices, and most cultures have traditional fables with anthropomorphized animals as characters. People have also routinely attributed human emotions and behavioral traits to wild as well as domesticated animals.
</p>

<h2 data-mw-anchor="Etymology">Etymology</h2>
<p>Anthropomorphism and <b>anthropomorphization</b> derive from the verb form <i>anthropomorphize</i>, itself derived from the Greek <i>ánthrōpos</i> (<span title="Ancient Greek (to 1453)-language text"><span lang="grc">ἄνθρωπος</span></span>, <small><abbr title="literally">lit.</abbr></small> "human") and <i>morphē</i> (<span title="Ancient Greek (to 1453)-language text"><span lang="grc">μορφή</span></span>, "form"). It is first attested in 1753, originally in reference to the heresy of applying a human form to the Christian God.
</p>
<h2 data-mw-anchor="Examples_in_prehistory">Examples in prehistory</h2>


<p>From the beginnings of human behavioral modernity in the Upper Paleolithic, about 40,000 years ago, examples of zoomorphic (animal-shaped) works of art occur that may represent the earliest known evidence of anthropomorphism. One of the oldest known is an ivory sculpture, the Löwenmensch figurine, Germany, a human-shaped figurine with the head of a lioness or lion, determined to be about 32,000 years old.
</p><p>It is not possible to say what these prehistoric artworks represent. A more recent example is The Sorcerer, an enigmatic cave painting from the Trois-Frères Cave, Ariège, France: the figure's significance is unknown, but it is usually interpreted as some kind of great spirit or master of the animals. In either case there is an element of anthropomorphism.
</p><p>This anthropomorphic art has been linked by archaeologist Steven Mithen with the emergence of more systematic hunting practices in the Upper Palaeolithic. He proposes that these are the product of a change in the architecture of the human mind, <span>an increasing fluidity between the natural history and social intelligences</span>, where anthropomorphism allowed hunters to identify empathetically with hunted animals and better predict their movements.
</p>
<h2 data-mw-anchor="In_religion_and_mythology">In religion and mythology</h2>

<p>In religion and mythology, anthropomorphism is the perception of a divine being or beings in human form, or the recognition of human qualities in these beings.
</p><p>Ancient mythologies frequently represented the divine as deities with human forms and qualities. They resemble human beings not only in appearance and personality; they exhibited many human behaviors that were used to explain natural phenomena, creation, and historical events. The deities fell in love, married, had children, fought battles, wielded weapons, and rode horses and chariots. They feasted on special foods, and sometimes required sacrifices of food, beverage, and sacred objects to be made by human beings. Some anthropomorphic deities represented specific human concepts, such as love, war, fertility, beauty, or the seasons. Anthropomorphic deities exhibited human qualities such as beauty, wisdom, and power, and sometimes human weaknesses such as greed, hatred, jealousy, and uncontrollable anger. Greek deities such as Zeus and Apollo often were depicted in human form exhibiting both commendable and despicable human traits. Anthropomorphism in this case is, more specifically, anthropotheism.
</p><p>From the perspective of adherents to religions in which humans were created in the form of the divine, the phenomenon may be considered theomorphism, or the giving of divine qualities to humans.
</p><p>Anthropomorphism has cropped up as a Christian heresy, particularly prominently with Audianism in third-century Syria, but also fourth-century Egypt and tenth-century Italy.  This often was based on a literal interpretation of the Genesis creation myth: "So God created humankind in his image, in the image of God he created them; male and female he created them".
</p><p>Hindus do not reject the concept of a deity in the abstract unmanifested, but note practical problems. The <i>Bhagavad Gita</i>, Chapter 12, Verse 5, states that it is much more difficult for people to focus on a deity that is unmanifested than one with form, remarking on the usage of anthropomorphic icons (murtis) that adherents can perceive with their senses.
</p>
<h3 data-mw-anchor="Criticism">Criticism</h3>
<p>Some religions, scholars, and philosophers objected to anthropomorphic deities. The earliest known criticism was that of the Greek philosopher Xenophanes (570–480 BCE) who observed that people model their gods after themselves. He argued against the conception of deities as fundamentally anthropomorphic:
</p>
<blockquote class="templatequote"><p>But if cattle and horses and lions had hands<br>or could paint with their hands and create works such as men do,<br>horses like horses and cattle like cattle<br>also would depict the gods' shapes and make their bodies<br>of such a sort as the form they themselves have.<br>...<br>Ethiopians say that their gods are snub–nosed [<span title="Ancient Greek (to 1453)-language text"><span lang="grc">σιμούς</span></span>] and black<br>Thracians that they are pale and red-haired.</p></blockquote><p> Xenophanes said that "the greatest god" resembles man "neither in form nor in mind".
</p><p>Both Judaism and Islam reject an anthropomorphic deity, believing that God is beyond human comprehension. Judaism's rejection of an anthropomorphic deity began with the prophets, who explicitly rejected any likeness of God to humans. Their rejection grew further after the Islamic Golden Age in the tenth century, which Maimonides codified in the twelfth century, in his thirteen principles of Jewish faith.
</p><p>In the Ismaili interpretation of Islam, assigning attributes to God as well as negating any attributes from God (<i>via negativa</i>) both qualify as anthropomorphism and are rejected, as God cannot be understood by either assigning attributes to Him or taking them away. The 10th-century Ismaili philosopher Abu Yaqub al-Sijistani suggested the method of double negation; for example: "God is not existent" followed by "God is not non-existent". This glorifies God from any understanding or human comprehension.
</p><p>In secular thought, one of the most notable criticisms began in 1600 with Francis Bacon, who argued against Aristotle's teleology, which declared that everything behaves as it does in order to achieve some end, in order to fulfill itself. Bacon pointed out that achieving ends is a human activity and to attribute it to nature misconstrues it as humanlike. Modern criticisms followed Bacon's ideas such as critiques of Baruch Spinoza and David Hume. The latter, for instance, embedded his arguments in his wider criticism of human religions and specifically demonstrated in what he cited as their "inconsistence" where, on one hand, the Deity is painted in the most sublime colors but, on the other, is degraded to nearly human levels by giving him human infirmities, passions, and prejudices. In <i>Faces in the Clouds</i>, anthropologist Stewart Guthrie proposes that all religions are anthropomorphisms that originate in the brain's tendency to detect the presence or vestiges of other humans in natural phenomena.
</p><p>Some scholars argue that anthropomorphism overestimates the similarity of humans and nonhumans and therefore could not yield accurate accounts.
</p>
<h2 data-mw-anchor="In_literature">In literature</h2>
<h3 data-mw-anchor="Religious_texts">Religious texts</h3>
<p>There are various examples of personification in both the Hebrew Bible and Christian New Testaments, as well as in the texts of some other religions.
</p>
<h3 data-mw-anchor="Fables">Fables</h3>

<p>Anthropomorphism, also referred to as personification, is a well-established literary device from ancient times. The story of "The Hawk and the Nightingale" in Hesiod's <i>Works and Days</i> preceded Aesop's fables by centuries. Collections of linked fables from India, the <i>Jataka Tales</i> and <i>Panchatantra</i>, also employ anthropomorphized animals to illustrate principles of life. Many of the stereotypes of animals that are recognized today, such as the wily fox and the proud lion, can be found in these collections. Aesop's anthropomorphisms were so familiar by the first century CE that they colored the thinking of at least one philosopher:
</p>
<blockquote class="templatequote"><p>And there is another charm about him, namely, that he puts animals in a pleasing light and makes them interesting to mankind. For after being brought up from childhood with these stories, and after being as it were nursed by them from babyhood, we acquire certain opinions of the several animals and think of some of them as royal animals, of others as silly, of others as witty, and others as innocent.</p></blockquote>
<p>Apollonius noted that the fable was created to teach wisdom through fictions that are meant to be taken as fictions, contrasting them favorably with the poets' stories of the deities that are sometimes taken literally. Aesop, "by announcing a story which everyone knows not to be true, told the truth by the very fact that he did not claim to be relating real events". The same consciousness of the fable as fiction is to be found in other examples across the world, one example being a traditional Ashanti way of beginning tales of the anthropomorphic trickster-spider Anansi: "We do not really mean, we do not really mean that what we are about to say is true. A story, a story; let it come, let it go."
</p>
<h3 data-mw-anchor="Fairy_tales">Fairy tales</h3>
<p>Anthropomorphic motifs have been common in fairy tales from the earliest ancient examples set in a mythological context to the great collections of the Brothers Grimm and Perrault. The <i>Tale of Two Brothers</i> (Egypt, 13th century BCE) features several talking cows and in <i>Cupid and Psyche</i> (Rome, 2nd century CE) Zephyrus, the west wind, carries Psyche away. Later an ant feels sorry for her and helps her in her quest.
</p>
<h3 data-mw-anchor="Modern_literature">Modern literature</h3>


<p>Building on the popularity of fables and fairy tales, <i>children's</i> literature began to emerge in the nineteenth century with works such as <i>Alice's Adventures in Wonderland</i> (1865) by Lewis Carroll, <i>The Adventures of Pinocchio</i> (1883) by Carlo Collodi and <i>The Jungle Book</i> (1894) by Rudyard Kipling, all employing anthropomorphic elements. This continued in the twentieth century with many of the most popular titles having anthropomorphic characters, examples being <i>The Tale of Peter Rabbit</i> (1901) and later books by Beatrix Potter; <i>The Wind in the Willows</i> by Kenneth Grahame (1908); <i>Winnie-the-Pooh</i> (1926) and <i>The House at Pooh Corner</i> (1928) by A. A. Milne; and <i>The Lion, the Witch, and the Wardrobe</i> (1950) and the subsequent books in <i>The Chronicles of Narnia</i> series by C. S. Lewis.
</p><p>In many of these stories the animals can be seen as representing facets of human personality and character. As John Rowe Townsend remarks, discussing <i>The Jungle Book</i> in which the boy Mowgli must rely on his new friends the bear Baloo and the black panther Bagheera, "The world of the jungle is in fact both itself and our world as well". A notable work aimed at an adult audience is George Orwell's <i>Animal Farm</i>, in which all the main characters are anthropomorphic animals. Non-animal examples include Rev. W. Awdry's <i>Railway Series</i> stories featuring Thomas the Tank Engine and other anthropomorphic locomotives.
</p><p>The fantasy genre developed from mythological, fairy tale, and Romance motifs sometimes have anthropomorphic animals as characters. The best-selling examples of the genre are <i>The Hobbit</i> (1937) and <i>The Lord of the Rings</i> (1954–1955), both by J. R. R. Tolkien, books peopled with talking creatures such as ravens, spiders, and the dragon Smaug and a multitude of anthropomorphic goblins and elves. John D. Rateliff calls this the "Doctor Dolittle Theme" in his book <i>The History of the Hobbit</i> and Tolkien saw this anthropomorphism as closely linked to the emergence of human language and myth: "...The first men to talk of 'trees and stars' saw things very differently. To them, the world was alive with mythological beings... To them the whole of creation was 'myth-woven and elf-patterned'."
</p><p>Richard Adams developed a distinctive take on anthropomorphic writing in the 1970s: his debut novel, <i>Watership Down</i> (1972), featured rabbits that could talk—with their own distinctive language (Lapine) and mythology—and included a police-state warren, Efrafa. Despite this, Adams attempted to ensure his characters' behavior mirrored that of wild rabbits, engaging in fighting, copulating and defecating, drawing on Ronald Lockley's study <i>The Private Life of the Rabbit</i> as research. Adams returned to anthropomorphic storytelling in his later novels <i>The Plague Dogs</i> (1977) and <i>Traveller</i> (1988).
</p><p>By the 21st century, the children's picture book market had expanded massively. Perhaps a majority of picture books have some kind of anthropomorphism, with popular examples being <i>The Very Hungry Caterpillar</i> (1969) by Eric Carle and <i>The Gruffalo</i> (1999) by Julia Donaldson.
</p><p>Anthropomorphism in literature and other media led to a sub-culture known as furry fandom, which promotes and creates stories and artwork involving anthropomorphic animals, and the examination and interpretation of humanity through anthropomorphism. This can often be shortened in searches as "anthro", used by some as an alternative term to "furry".
</p><p>Anthropomorphic characters have also been a staple of the comic book genre. The most prominent one was Neil Gaiman's the <i>Sandman</i> which had a huge impact on how characters that are physical embodiments are written in the fantasy genre. Other examples also include the mature <i>Hellblazer</i> (personified political and moral ideas), <i>Fables</i> and its spin-off series <i>Jack of Fables</i>, which was unique for having anthropomorphic representation of literary techniques and genres. Various Japanese manga and anime have used anthropomorphism as the basis of their story. Examples include <i>Squid Girl</i> (anthropomorphized squid), <i>Hetalia: Axis Powers</i> (personified countries), <i>Upotte!!</i> (personified guns), <i>Arpeggio of Blue Steel</i> and <i>Kancolle</i> (personified ships).
</p>
<h2 data-mw-anchor="In_film">In film</h2>

<p>Some of the most notable examples are the Walt Disney characters Mickey Mouse, Donald Duck, Goofy, and Oswald the Lucky Rabbit; the Looney Tunes characters Bugs Bunny, Daffy Duck, and Porky Pig; and an array of others from the 1920s to the present day.
</p><p>In the Disney/Pixar franchises <i>Cars</i> and <i>Planes</i>, all the characters are anthropomorphic vehicles, while in <i>Toy Story</i>, they are anthropomorphic toys. Other Pixar franchises like <i>Monsters, Inc</i> features anthropomorphic monsters and <i>Finding Nemo</i> features anthropomorphic sea animals (like fish, sharks, and whales). Discussing anthropomorphic animals from DreamWorks franchise <i>Madagascar</i>, Timothy Laurie suggests that "<span>social differences based on conflict and contradiction are naturalized and made less 'contestable' through the classificatory matrix of human and nonhuman relations</span>". Other DreamWorks franchises like <i>Shrek</i> features fairy tale characters, and Blue Sky Studios of 20th Century Fox franchises like <i>Ice Age</i> features anthropomorphic extinct animals. Other characters in <i>SpongeBob SquarePants</i> features anthropomorphic sea animals as well (like sea sponges, starfish, octopus, crabs, whales, puffer fish, lobsters, and zooplankton).
</p><p>All of the characters in Walt Disney Animation Studios' <i>Zootopia</i> (2016) are anthropomorphic animals, that is an entirely nonhuman civilization.
</p><p>The live-action/animated franchise <i>Alvin and the Chipmunks</i> by 20th Century Fox centers around anthropomorphic talkative and singing chipmunks. The female singing chipmunks called The Chipettes are also centered in some of the franchise's films.
</p>
<h2 data-mw-anchor="In_television">In television</h2>

<p>Since the 1960s, anthropomorphism has also been represented in various animated television shows such as <i>Biker Mice From Mars</i> (1993–1996) and <i>SWAT Kats: The Radical Squadron</i> (1993–1995).  <i>Teenage Mutant Ninja Turtles</i>, first aired in 1987, features four pizza-loving anthropomorphic turtles with a great knowledge of ninjutsu, led by their anthropomorphic rat sensei, Master Splinter. Nickelodeon's longest running animated TV series <i>SpongeBob SquarePants</i> (1999–present), revolves around SpongeBob, a yellow sea sponge, living in the underwater town of Bikini Bottom with his anthropomorphic marine life friends. Cartoon Network's animated series <i>The Amazing World of Gumball</i> (2011–2019) are about anthropomorphic animals and inanimate objects. All of the characters in Hasbro Studios' TV series <i>My Little Pony: Friendship Is Magic</i> (2010–2019) are anthropomorphic fantasy creatures, with most of them being ponies living in the pony-inhabited land of Equestria. The Netflix original series Centaurworld focuses on a warhorse who gets transported to a Dr. Seuss-like world full of centaurs who possess the bottom half of any animal, as opposed to the traditional horse.
</p><p>In the American animated TV series <i>Family Guy</i>, one of the show's main characters, Brian, is a dog. Brian shows many human characteristics – he walks upright, talks, smokes, and drinks Martinis – but also acts like a normal dog in other ways; for example, he cannot resist chasing a ball and barks at the mailman, believing him to be a threat. In a similar case, <i>BoJack Horseman</i>, an American Netflix adult animated black comedy series, takes place in an alternate world where humans and anthropomorphic animals live side by side, and centers around the life of BoJack Horseman; a humanoid horse who was a one hit wonder on a popular 1990s sitcom <i>Horsin' Around</i>, living off the show's residuals in present time. Multiple main characters of the series are other animals who possess human body form and other human-like traits and identity as well; Mr. Peanutbutter, a humanoid dog lives a mostly human life—he speaks American English, walks upright, owns a house, drives a car, is in a romantic relationship with a human woman (in this series, as animals and humans are seen as equal, relationships like this are not seen as bestiality but seen as regular human sexuality), Diane, and has a successful career in television—however also exhibits dog traits—he sleeps in a human-size dog bed, gets arrested for having a drag race with the mailman and is once forced to wear a dog cone after he gets stitches in his arm.
</p><p>The PBS Kids animated series <i>Let's Go Luna!</i> centers on an anthropomorphic female Moon who speaks, sings, and dances. She comes down out of the sky to serve as a tutor of international culture to the three main characters: a boy frog and wombat and a girl butterfly, who are supposed to be preschool children traveling a world populated by anthropomorphic animals with a circus run by their parents.
</p><p>The French-Belgian animated series <i>Mush-Mush &amp; the Mushables</i> takes place in a world inhabited by Mushables, which are anthropomorphic fungi, along with other critters such as beetles, snails, and frogs.
</p>
<h2 data-mw-anchor="In_video_games">In video games</h2>


<p><i>Sonic the Hedgehog</i>, a video game franchise debuting in 1991, features a speedy blue hedgehog as the main protagonist. This series' characters are almost all anthropomorphic animals such as foxes, cats, and other hedgehogs who are able to speak and walk on their hind legs like normal humans. As with most anthropomorphisms of animals, clothing is of little or no importance, where some characters may be fully clothed while some wear only shoes and gloves.
</p><p>Another popular example in video games is the <i>Super Mario</i> series, debuting in 1985 with <i>Super Mario Bros.</i>, of which main antagonist includes a fictional species of anthropomorphic turtle-like creatures known as Koopas. Other games in the series, as well as of other of its greater <i>Mario</i> franchise, spawned similar characters such as Yoshi, Donkey Kong and many others.
</p>
<h2 data-mw-anchor="Art_history">Art history</h2>

<h3 data-mw-anchor="Claes_Oldenburg">Claes Oldenburg</h3>
<p>Claes Oldenburg's soft sculptures are commonly described as anthropomorphic. Depicting common household objects, Oldenburg's sculptures were considered Pop Art. Reproducing these objects, often at a greater size than the original, Oldenburg created his sculptures out of soft materials. The anthropomorphic qualities of the sculptures were mainly in their sagging and malleable exterior which mirrored the not-so-idealistic forms of the human body. In "Soft Light Switches" Oldenburg creates a household light switch out of vinyl. The two identical switches, in a dulled orange, insinuate nipples. The soft vinyl references the aging process as the sculpture wrinkles and sinks with time.
</p>
<h3 data-mw-anchor="Minimalism">Minimalism</h3>
<p>In the essay "Art and Objecthood", Michael Fried makes the case that "literalist art" (minimalism) becomes theatrical by means of anthropomorphism. The viewer engages the minimalist work, not as an autonomous art object, but as a theatrical interaction. Fried references a conversation in which Tony Smith answers questions about his six-foot cube, "Die".
</p>
<blockquote class="templatequote"><p>Q: Why didn't you make it larger so that it would loom over the observer?
</p><p>A: I was not making a monument.
</p><p>Q: Then why didn't you make it smaller so that the observer could see over the top?
</p><p>
A: I was not making an object.</p></blockquote>
<p>Fried implies an anthropomorphic connection by means of "a surrogate person – that is, a kind of statue."
</p><p>The minimalist decision of "hollowness" in much of their work was also considered by Fried to be "blatantly anthropomorphic". This "hollowness" contributes to the idea of a separate inside; an idea mirrored in the human form. Fried considers the Literalist art's "hollowness" to be "biomorphic" as it references a living organism.
</p>
<h3 data-mw-anchor="Post-minimalism">Post-minimalism</h3>
<p>Curator Lucy Lippard's Eccentric Abstraction show, in 1966, sets up Briony Fer's writing of a post-minimalist anthropomorphism. Reacting to Fried's interpretation of minimalist art's "looming presence of objects which appear as actors might on a stage", Fer interprets the artists in Eccentric Abstraction to a new form of anthropomorphism. She puts forth the thoughts of Surrealist writer Roger Caillois, who speaks of the "spacial lure of the subject, the way in which the subject could inhabit their surroundings."  Caillous uses the example of an insect who "through camouflage does so in order to become invisible... and loses its distinctness." For Fer, the anthropomorphic qualities of imitation found in the erotic, organic sculptures of artists Eva Hesse and Louise Bourgeois, are not necessarily for strictly "mimetic" purposes. Instead, like the insect, the work must come into being in the "scopic field... which we cannot view from outside."
</p>
<h2 data-mw-anchor="Mascots">Mascots</h2>


<p>For branding, merchandising, and representation, figures known as mascots are now often employed to personify sports teams, corporations, and major events such as the World's Fair and the Olympics. These personifications may be simple human or animal figures, such as Ronald McDonald or the donkey that represents the United States's Democratic Party. Other times, they are anthropomorphic items, such as "Clippy" or the "Michelin Man". Most often, they are anthropomorphic animals such as the Energizer Bunny or the San Diego Chicken.
</p><p>The practice is particularly widespread in Japan, where cities, regions, and companies all have mascots, collectively known as <i>yuru-chara</i>. Two of the most popular are Kumamon (a bear who represents Kumamoto Prefecture) and Funassyi (a pear who represents Funabashi, a suburb of Tokyo).
</p>
<h2 data-mw-anchor="Animals">Animals</h2>


<p>Other examples of anthropomorphism include the attribution of human traits to animals, especially domesticated pets such as dogs and cats. Examples of this include thinking a dog is smiling simply because it is showing his teeth, or a cat mourns for a dead owner. Anthropomorphism may be beneficial to the welfare of animals. A 2012 study by Butterfield <i>et al.</i> found that utilizing anthropomorphic language when describing dogs created a greater willingness to help them in situations of distress. Previous studies have shown that individuals who attribute human characteristics to animals are less willing to eat them, and that the degree to which individuals perceive minds in other animals predicts the moral concern afforded to them. It is possible that anthropomorphism leads humans to like non-humans more when they have apparent human qualities, since perceived similarity has been shown to increase prosocial behavior toward other humans. A study of how animal behaviors were discussed on the television series <i>Life</i> found that the script very often used anthropomorphisms.
</p>
<h2 data-mw-anchor="In_science">In science</h2>
<p>In science, the use of anthropomorphic language that suggests animals have intentions and emotions has traditionally been deprecated as indicating a lack of objectivity. Biologists have been warned to avoid assumptions that animals share any of the same mental, social, and emotional capacities of humans, and to rely instead on strictly observable evidence.  In 1927 Ivan Pavlov wrote that animals should be considered "without any need to resort to fantastic speculations as to the existence of any possible subjective states". More recently, <i>The Oxford companion to animal behaviour</i> (1987) advised that "one is well advised to study the behaviour rather than attempting to get at any underlying emotion". Some scientists, like William M Wheeler (writing apologetically of his use of anthropomorphism in 1911), have used anthropomorphic language in metaphor to make subjects more humanly comprehensible or memorable.
</p><p>Despite the impact of Charles Darwin's ideas in <i>The Expression of the Emotions in Man and Animals</i> (Konrad Lorenz in 1965 called him a "patron saint" of ethology) ethology has generally focused on behavior, not on emotion in animals.
</p>
<blockquote class="templatequote"><p>Even insects play together, as has been described by that excellent observer, P. Huber, who saw ants chasing and pretending to bite each other, like so many puppies.</p></blockquote>
<p>The study of great apes in their own environment and in captivity has changed attitudes to anthropomorphism. In the 1960s the three so-called "Leakey's Angels", Jane Goodall studying chimpanzees, Dian Fossey studying gorillas and Biruté Galdikas studying orangutans, were all accused of "that worst of ethological sins – anthropomorphism".  The charge was brought about by their descriptions of the great apes in the field; it is now more widely accepted that empathy has an important part to play in research.
</p><p>De Waal has written: "To endow animals with human emotions has long been a scientific taboo.  But if we do not, we risk missing something fundamental, about both animals and us." Alongside this has come increasing awareness of the linguistic abilities of the great apes and the recognition that they are tool-makers and have individuality and culture.
</p><p>Writing of cats in 1992, veterinarian Bruce Fogle points to the fact that "both humans and cats have identical neurochemicals and regions in the brain responsible for emotion" as evidence that "it is not anthropomorphic to credit cats with emotions such as jealousy".
</p>
<h2 data-mw-anchor="In_computing">In computing</h2>
<p><span id="In_computing"></span>
</p><p>In science fiction, an artificially intelligent computer or robot, even though it has not been programmed with human emotions, often spontaneously experiences those emotions anyway: for example, Agent Smith in <i>The Matrix</i> was influenced by a "disgust" toward humanity. This is an example of anthropomorphism: in reality, while an artificial intelligence could perhaps be deliberately programmed with human emotions or could develop something similar to an emotion as a means to an ultimate goal <i>if</i> it is useful to do so, it would not spontaneously develop human emotions for no purpose whatsoever, as portrayed in fiction.
</p><p>One example of anthropomorphism would be to believe that one's computer is angry at them because they insulted it; another would be to believe that an intelligent robot would naturally find a woman attractive and be driven to mate with her. Scholars sometimes disagree with each other about whether a particular prediction about an artificial intelligence's behavior is logical, or whether the prediction constitutes illogical anthropomorphism. An example that might initially be considered anthropomorphism, but is in fact a logical statement about an artificial intelligence's behavior, would be the Dario Floreano experiments where certain robots spontaneously evolved a crude capacity for "deception", and tricked other robots into eating "poison" and dying: here, a trait, "deception", ordinarily associated with people rather than with machines, spontaneously evolves in a type of convergent evolution.
</p><p>The conscious use of anthropomorphic metaphor is not intrinsically unwise; ascribing mental processes to the computer, under the proper circumstances, may serve the same purpose as it does when humans do it to other people: it may help persons to understand what the computer will do, how their actions will affect the computer, how to compare computers with humans, and conceivably how to design computer programs. However, inappropriate use of anthropomorphic metaphors can result in false beliefs about the behavior of computers, for example by causing people to overestimate how "flexible" computers are. According to Paul R. Cohen and Edward Feigenbaum, in order to differentiate between anthropomorphization and logical prediction of AI behavior, "the trick is to know enough about how humans and computers think to say <i>exactly</i> what they have in common, and, when we lack this knowledge, to use the comparison to <i>suggest</i> theories of human thinking or computer thinking."
</p><p>Computers overturn the childhood hierarchical taxonomy of "stones (non-living) → plants (living) → animals (conscious) → humans (rational)", by introducing a non-human "actor" that appears to regularly behave rationally. Much of computing terminology derives from anthropomorphic metaphors: computers can "read", "write", or "catch a virus". Information technology presents no clear correspondence with any other entities in the world besides humans; the options are either to leverage an emotional, imprecise human metaphor, or to reject imprecise metaphor and make use of more precise, domain-specific technical terms.
</p><p>People often grant an unnecessary social role to computers during interactions. The underlying causes are debated; Youngme Moon and Clifford Nass propose that humans are emotionally, intellectually and physiologically biased toward social activity, and so when presented with even tiny social cues, deeply infused social responses are triggered automatically. This may allow incorporation of anthropomorphic features into computers/robots to enable more familiar "social" interactions, making them easier to use.
</p><p>Alleged examples of anthropomorphism toward AI have included: Google engineer Blake Lemoine's widely derided 2022 claim that the Google LaMDA chatbot was sentient; the 2017 granting of honorary Saudi Arabian citizenship to the robot Sophia; and the reactions to the chatbot ELIZA in the 1960s.
</p>
<h2 data-mw-anchor="Psychology">Psychology</h2>
<h3 data-mw-anchor="Foundational_research">Foundational research</h3>
<p>In psychology, the first empirical study of anthropomorphism was conducted in 1944 by Fritz Heider and Marianne Simmel. In the first part of this experiment, the researchers showed a 2-and-a-half-minute long animation of several shapes moving around on the screen in varying directions at various speeds. When subjects were asked to describe what they saw, they gave detailed accounts of the intentions and personalities of the shapes. For instance, the large triangle was characterized as a bully, chasing the other two shapes until they could trick the large triangle and escape. The researchers concluded that when people see objects making motions for which there is no obvious cause, they view these objects as intentional agents (individuals that deliberately make choices to achieve goals).
</p><p>Modern psychologists generally characterize anthropomorphism as a cognitive bias. That is, anthropomorphism is a cognitive process by which people use their schemas about other humans as a basis for inferring the properties of non-human entities in order to make efficient judgements about the environment, even if those inferences are not always accurate. Schemas about humans are used as the basis because this knowledge is acquired early in life, is more detailed than knowledge about non-human entities, and is more readily accessible in memory. Anthropomorphism can also function as a strategy to cope with loneliness when other human connections are not available.
</p>
<h3 data-mw-anchor="Three-factor_theory">Three-factor theory</h3>
<p>Since making inferences requires cognitive effort, anthropomorphism is likely to be triggered only when certain aspects about a person and their environment are true. Psychologist Adam Waytz and his colleagues created a three-factor theory of anthropomorphism to describe these aspects and predict when people are most likely to anthropomorphize. The three factors are:
</p>
<ul><li><i>Elicited agent knowledge</i>, or the amount of prior knowledge held about an object and the extent to which that knowledge is called to mind.</li>
<li><i>Effectance</i>, or the drive to interact with and understand one's environment.</li>
<li><i>Sociality</i>, the need to establish social connections.</li></ul>
<p>When elicited agent knowledge is low and effectance and sociality are high, people are more likely to anthropomorphize. Various dispositional, situational, developmental, and cultural variables can affect these three factors, such as need for cognition, social disconnection, cultural ideologies, uncertainty avoidance, etc.
</p>
<h3 data-mw-anchor="Developmental_perspective">Developmental perspective</h3>
<p>Children appear to anthropomorphize and use egocentric reasoning from an early age and use it more frequently than adults. Examples of this are describing a storm cloud as "angry" or drawing flowers with faces. This penchant for anthropomorphism is likely because children have acquired vast amounts of socialization, but not as much experience with specific non-human entities, so thus they have less developed alternative schemas for their environment. In contrast, autistic children may tend to describe anthropomorphized objects in purely mechanical terms (that is, in terms of what they do) because they have difficulties with theory of mind (ToM) according to past research. A 2018 study has shown that autistic people are more prone to object personification, suggesting that autistic empathy and ToM may be not only more complex but also more all-encompassing. The double empathy problem challenges the notion that autistic people have difficulties with ToM.
</p>
<h3 data-mw-anchor="Effect_on_learning">Effect on learning</h3>
<p>Anthropomorphism can be used to assist learning. Specifically, anthropomorphized words and describing scientific concepts with intentionality can improve later recall of these concepts.
</p>
<h3 data-mw-anchor="In_mental_health">In mental health</h3>
<p>In people with depression, social anxiety, or other mental illnesses, emotional support animals are a useful component of treatment partially because anthropomorphism of these animals can satisfy the patients' need for social connection.
</p>
<h3 data-mw-anchor="In_marketing">In marketing</h3>
<p>Anthropomorphism of inanimate objects can affect product buying behavior. When products seem to resemble a human schema, such as the front of a car resembling a face, potential buyers evaluate that product more positively than if they do not anthropomorphize the object.
</p><p>People also tend to trust robots to do more complex tasks such as driving a car or childcare if the robot resembles humans in ways such as having a face, voice, and name; mimicking human motions; expressing emotion; and displaying some variability in behavior.
</p>
<h2 data-mw-anchor="Image_gallery">Image gallery</h2>
<ul class="gallery mw-gallery-traditional">
		<li class="gallerybox" style="width: 155px">
			
			
		</li>
		<li class="gallerybox" style="width: 155px">
			
			
		</li>
		<li class="gallerybox" style="width: 155px">
			
			
		</li>
		<li class="gallerybox" style="width: 155px">
			
			
		</li>
</ul>
<h2 data-mw-anchor="See_also">See also</h2>


<h2 data-mw-anchor="Notes">Notes</h2>

<h2 data-mw-anchor="References">References</h2>

<h2 data-mw-anchor="Sources">Sources</h2>
<ul><li><cite id="CITEREFMassonMcCarthy1996" class="citation book cs1">Masson, Jeffrey Moussaieff; McCarthy, Susan (1996). <i>When Elephants Weep: Emotional Lives of Animals</i>. Vintage. p. 272. ISBN <bdi>978-0-09-947891-1</bdi>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=When+Elephants+Weep%3A+Emotional+Lives+of+Animals&amp;rft.pages=272&amp;rft.pub=Vintage&amp;rft.date=1996&amp;rft.isbn=978-0-09-947891-1&amp;rft.aulast=Masson&amp;rft.aufirst=Jeffrey+Moussaieff&amp;rft.au=McCarthy%2C+Susan&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DUcbYqb8D4IEC%26q%3DJane%2520Goodall%2520controversy%26pg%3DPR19&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAnthropomorphism"></span></li></ul>
<h2 data-mw-anchor="Further_reading">Further reading</h2>
<ul><li><cite id="CITEREFBaynes1878" class="citation encyclopaedia cs1">Baynes, T. S., ed. (1878). <span title="s:Encyclopædia Britannica, Ninth Edition/Anthropomorphism">"Anthropomorphism" </span>. <i>Encyclopædia Britannica</i>. Vol. 2 (9th ed.). New York: Charles Scribner's Sons. pp. <span>123–</span>124.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Anthropomorphism&amp;rft.btitle=Encyclop%C3%A6dia+Britannica&amp;rft.place=New+York&amp;rft.pages=123-124&amp;rft.edition=9th&amp;rft.pub=Charles+Scribner%27s+Sons&amp;rft.date=1878&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAnthropomorphism"></span></li>
<li><cite id="CITEREFMackintosh1911" class="citation encyclopaedia cs1">Mackintosh, Robert (1911). <span title="s:1911 Encyclopædia Britannica/Anthropomorphism">"Anthropomorphism" </span>. In Chisholm, Hugh (ed.). <i>Encyclopædia Britannica</i>. Vol. 2 (11th ed.). Cambridge University Press. p. 120.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Anthropomorphism&amp;rft.btitle=Encyclop%C3%A6dia+Britannica&amp;rft.pages=120&amp;rft.edition=11th&amp;rft.pub=Cambridge+University+Press&amp;rft.date=1911&amp;rft.aulast=Mackintosh&amp;rft.aufirst=Robert&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAnthropomorphism"></span></li>
<li><cite id="CITEREFKennedy1992" class="citation book cs1">Kennedy, John S. (1992). <i>The New Anthropomorphism</i>. Cambridge University Press. ISBN <bdi>978-0-521-42267-3</bdi>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+New+Anthropomorphism&amp;rft.pub=Cambridge+University+Press&amp;rft.date=1992&amp;rft.isbn=978-0-521-42267-3&amp;rft.aulast=Kennedy&amp;rft.aufirst=John+S.&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3D5RjoDMW8pSIC&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAnthropomorphism"></span></li>
<li><cite id="CITEREFMithen1998" class="citation book cs1">Mithen, Steven (1998). <i>The Prehistory Of The Mind: A Search for the Origins of Art, Religion and Science</i>. Phoenix. p. 480. Bibcode:1996pmso.book.....M. ISBN <bdi>978-0-7538-0204-5</bdi>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Prehistory+Of+The+Mind%3A+A+Search+for+the+Origins+of+Art%2C+Religion+and+Science&amp;rft.pages=480&amp;rft.pub=Phoenix&amp;rft.date=1998&amp;rft_id=info%3Abibcode%2F1996pmso.book.....M&amp;rft.isbn=978-0-7538-0204-5&amp;rft.aulast=Mithen&amp;rft.aufirst=Steven&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAnthropomorphism"></span></li></ul>
<h2 data-mw-anchor="External_links">External links</h2>

<ul><li>"Anthropomorphism" entry in the <i>Encyclopedia of Human-Animal Relationships</i> (Horowitz A., 2007)</li>
<li>"Anthropomorphism" entry in the Encyclopedia of Astrobiology, Astronomy, and Spaceflight</li>
<li>"Anthropomorphism" in mid-century American print advertising. Archived 1 December 2021 at the Wayback Machine Collection at The Gallery of Graphic Design.</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Anthropomorphism#Psychology'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Group attribution error</h2>
<a href='https://en.wikipedia.org/wiki/Group_attribution_error' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>group attribution error</b> refers to people's tendency to believe either
</p>
<ol><li>the characteristics of an individual group member are reflective of the group as a whole, or</li>
<li>a group's decision outcome must reflect the preferences of individual group members, even when external information is available suggesting otherwise.</li></ol>
<p>The group attribution error shares an attribution bias analogous to the fundamental attribution error. Rather than focusing on individual's behavior, it relies on group outcomes and attitudes as its main basis for conclusions.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Group_attribution_error'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Ultimate attribution error</h2>
<a href='https://en.wikipedia.org/wiki/Ultimate_attribution_error' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>ultimate attribution error</b> is an attribution error made when making in-group and out-group attributions. The error occurs when attributions of outgroup behavior are more negative and attributions of ingroup behavior are more positive. As a cognitive bias, the error results in negative outgroup behavior being more likely to be attributed to factors internal and specific to the actor, such as personality, and to attribute positive behaviors to external factors, such as the context the behavior is exhibited in. The opposite effect is seen for in-group members as they are more likely to attribute their positive acts to dispositional factors, and their negative acts to situational factors. Also, in-group members will 'explain away' out-group success to external factors such as luck or circumstance. The bias reinforces negative stereotypes and prejudice about the out-group and favouritism of the ingroup through positive stereotypes. The Ultimate attribution error is an example of a cognitive bias that shows cross cultural differences, showing up more strongly for individuals in Western cultures than Eastern Cultures.
</p><p>Emotion is also known to influence the ultimate attribution error, shaping the way individuals attribute behavior to group members. For instance, emotions such as fear and anger can intensify negative attributions toward out-group members by increasing the likelihood of bad out-group behavior to dispositional factors, and good behavior to situational factors. This suggests that emotional states play a role in reinforcing the bias, especially in emotionally charged contexts like politics. Negative emotions may lead individuals to make harsher judgements of out-group members, further solidifying stereotypes and prejudiced beliefs.
</p><p>Four categories have been identified that describe the negative attribution of positive outgroup behaviour. First, that the outgroup member is an exception to a general rule; second, that the member was lucky or had specific advantages; third, that the member was highly motivated; and lastly that the behaviour as attributable to situational causes. 
</p><p>The concept and term originates in an article by Thomas F. Pettigrew in 1979 as an extension of the fundamental attribution error which was identified in 1958. Since its publication, which at the time lacked a strong empirical basis, there has been some support for the theory. The specific categorisation originally proposed had only some empirical support for broader categories of motivational and cognitive attribution.  The bias is related to intergroup attribution bias. The attribution bias can be explained by group schemas. The grouping schema assumes that one will like and trust members of their in-group and dislike and hate are expected reactions to the out-group.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Ultimate_attribution_error'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Stereotyping</h2>
<a href='https://en.wikipedia.org/wiki/Stereotype' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>




<p>In social psychology, a <b>stereotype</b> is a generalized belief about a particular category of people. It is an expectation that people might have about every person of a particular group. The type of expectation can vary; it can be, for example, an expectation about the group's personality, preferences, appearance or ability.  Stereotypes are often overgeneralized, inaccurate, and resistant to new information. A stereotype does not necessarily need to be a negative assumption. They may be positive, neutral, or negative.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Stereotype'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Essentialism</h2>
<a href='https://en.wikipedia.org/wiki/Essentialism' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p><p><b>Essentialism</b> is the view that objects have a set of attributes that are necessary to their identity. In early Western thought, Platonic idealism held that all things have such an "essence"—an "idea" or "form". In <i>Categories</i>, Aristotle similarly proposed that all objects have a substance that, as George Lakoff put it, "make the thing what it is, and without which it would be not <i>that</i> kind of thing". The contrary view—non-essentialism—denies the need to posit such an "essence". Essentialism has been controversial from its beginning. In the <i>Parmenides</i> dialogue, Plato depicts Socrates questioning the notion, suggesting that if we accept the idea that every beautiful thing or just action partakes of an essence to be beautiful or just, we must also accept the "existence of separate essences for hair, mud, and dirt".
</p><p>Older social theories were often conceptually essentialist. In biology and other natural sciences, essentialism provided the rationale for taxonomy at least until the time of Charles Darwin. The role and importance of essentialism in modern biology is still a matter of debate. Beliefs which posit that social identities such as race, ethnicity, nationality, or gender are essential characteristics have been central to many discriminatory or extremist ideologies. For instance, psychological essentialism is correlated with racial prejudice. Essentialist views about race have also been shown to diminish empathy when dealing with members of another racial group. In medical sciences, essentialism can lead to a reified view of identities, leading to fallacious conclusions and potentially unequal treatment.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Essentialism'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Functional fixedness</h2>
<a href='https://en.wikipedia.org/wiki/Functional_fixedness' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Functional fixedness</b> is a cognitive bias that limits a person to use an object only in the way it is traditionally used. The concept of functional fixedness originated in Gestalt psychology, a movement in psychology that emphasizes holistic processing. Karl Duncker defined functional fixedness as being a mental block against using an object in a new way that is required to solve a problem. This "block" limits the ability of an individual to use components given to them to complete a task, as they cannot move past the original purpose of those components. For example, if someone needs a paperweight, but they only have a hammer, they may not see how the hammer can be used as a paperweight. Functional fixedness is this inability to see a hammer's use as anything other than for pounding nails; the person couldn't think to use the hammer in a way other than in its conventional function.
</p><p>When tested, 5-year-old children show no signs of functional fixedness. It has been argued that this is because at age 5, any goal to be achieved with an object is equivalent to any other goal. However, by age 7, children have acquired the tendency to treat the originally intended purpose of an object as special.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Functional_fixedness'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Moral credential effect</h2>
<a href='https://en.wikipedia.org/wiki/Self-licensing' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Self-licensing</b> (also <b>moral self-licensing</b>, <b>moral licensing</b>, or <b>licensing effect</b>) is a term used in social psychology and marketing to describe the subconscious phenomenon whereby increased confidence and security in one's self-image or self-concept tends to make that individual worry less about the consequences of subsequent immoral behavior and, therefore, more likely to make immoral choices and act immorally. In simple terms, self-licensing occurs when people allow themselves to indulge after doing something positive first; for example, drinking a diet soda with a greasy hamburger and fries can lead one to subconsciously discount the negative attributes of the meal's high caloric and cholesterol content.
</p><p>A large subset of this effect, the <b>moral credential effect</b>, is a bias that occurs when a person's track record as a good egalitarian establishes in them an unconscious ethical certification, endorsement, or license that increases the likelihood of less egalitarian decisions later. This effect occurs even when the audience or moral peer group is unaware of the affected person's previously established moral credential. For example, individuals who had the opportunity to recruit a woman or Black person in one setting were more likely to say later, in a different setting, that a job would be better suited for a man or a white person. Similar effects also appear to occur when a person observes another person from a group they identify with making an egalitarian decision.
</p><p>Self-licensing can have negative societal consequences since it has a permissive effect on behaviors such as racial prejudice and discrimination, selfishness, poor dietary and health habits, and excessive energy consumption.
</p><p>But recent scholarship has failed to replicate seminal studies of the licensing effect, and meta-analysis found it to be exaggerated by publication bias. Furthermore, where licensing typically assumes that a good deed is the cause that makes subsequent transgressions more likely, an alternative (or additional) account is that people are faced with a temptation to do something morally dubious, and use a prior good deed as an excuse or reason why it is allowed for them to indulge.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Self-licensing'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Just–world hypothesis</h2>
<a href='https://en.wikipedia.org/wiki/Just-world_hypothesis' target='_blank'>Wikipedia Link</a>
<div class='content'></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Just-world_hypothesis'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Argument from fallacy</h2>
<a href='https://en.wikipedia.org/wiki/Argument_from_fallacy' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Argument from fallacy</b> is the formal fallacy of analyzing an argument and inferring that, since it contains a fallacy, its <i>conclusion</i> must be false. It is also called <b>argument to logic</b>  (<i><b>argumentum ad logicam</b></i>), the <b>fallacy fallacy</b>, the <b>fallacist's fallacy</b>, and the <b>bad reasons fallacy</b>.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Argument_from_fallacy'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Authority bias</h2>
<a href='https://en.wikipedia.org/wiki/Authority_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Authority bias</b> is the tendency to attribute greater accuracy to the opinion of an authority figure (unrelated to its content) and be more influenced by that opinion. An individual is more influenced by the opinion of this authority figure, believing their views to be more credible, and hence place greater emphasis on the authority figure's viewpoint and are more likely to obey them. This concept is considered one of the social cognitive biases or collective cognitive biases.
</p><p>Humans generally have a deep-seated duty to authority and tend to comply when requested by an authority figure. Some scholars explain that individuals are motivated to view authority as deserving of their position and this legitimacy leads people to accept and obey the decisions that it makes. System justification theory articulates this phenomenon, particularly within its position that there is a psychological motivation for believing in the steadiness, stability and justness of the current social system.
</p><p>Authority bias can be measured concerning respect for authority, where higher respect for authority positively correlates with the increased likelihood of exhibiting authority bias. 
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Authority_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Automation bias</h2>
<a href='https://en.wikipedia.org/wiki/Automation_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Automation bias</b> is the propensity for humans to favor suggestions from automated decision-making systems and to ignore contradictory information made without automation, even if it is correct. Automation bias stems from the social psychology literature that found a bias in human-human interaction that showed that people assign more positive evaluations to decisions made by humans than to a neutral object. The same type of positivity bias has been found for human-automation interaction, where the automated decisions are rated more positively than neutral. This has become a growing problem for decision making as intensive care units, nuclear power plants, and aircraft cockpits have increasingly integrated computerized system monitors and decision aids to mostly factor out possible human error. Errors of automation bias tend to occur when decision-making is dependent on computers or other automated aids and the human is in an observatory role but able to make decisions. Examples of automation bias range from urgent matters like flying a plane on automatic pilot to such mundane matters as the use of spell-checking programs.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Automation_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Bandwagon effect</h2>
<a href='https://en.wikipedia.org/wiki/Bandwagon_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>bandwagon effect</b> is a psychological phenomenon where people  adopt certain behaviors, styles, or attitudes simply because others are doing so. More specifically, it is a cognitive bias by which public opinion or behaviours can alter due to particular actions and beliefs rallying amongst the public. It is a psychological phenomenon whereby the rate of uptake of beliefs, ideas, fads and trends increases with respect to the proportion of others who have already done so. As more people come to believe in something, others also "hop on the bandwagon" regardless of the underlying evidence.
</p><p>Following others' actions or beliefs can occur because of conformism or deriving information from others. Much of the influence of the bandwagon effect comes from the desire to 'fit in' with peers; by making similar selections as other people, this is seen as a way to gain access to a particular social group. An example of this is fashion trends wherein the increasing popularity of a certain garment or style encourages more acceptance. When individuals make rational choices based on the information they receive from others, economists have proposed that information cascades can quickly form in which people ignore their personal information signals and follow the behaviour of others. Cascades explain why behaviour is fragile as people understand that their behaviour is based on a very limited amount of information. As a result, fads form easily but are also easily dislodged. The phenomenon is observed in various fields, such as economics, political science, medicine, and psychology. In social psychology, people's tendency to align their beliefs and behaviors with a group is known as 'herd mentality' or 'groupthink'. The <b>reverse bandwagon effect</b> (also known as the snob effect in certain contexts) is a cognitive bias that causes people to avoid doing something, because they believe that other people are doing it.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Bandwagon_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Placebo effect</h2>
<a href='https://en.wikipedia.org/wiki/Placebo' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>


<p>A <b>placebo</b> (<span></span> <i title="English pronunciation respelling">plə-<span>SEE</span>-boh</i>) can be roughly defined as a sham medical treatment. Common placebos include inert tablets (like sugar pills), inert injections (like saline), sham surgery, and other procedures.
</p><p>Placebos are used in randomized clinical trials to test the efficacy of medical treatments. In a placebo-controlled clinical trial, any change in the control group is known as the <i>placebo response</i>, and the difference between this and the result of no treatment is the <i>placebo effect</i>. Placebos in clinical trials should ideally be indistinguishable from so-called verum treatments under investigation, except for the latter's particular hypothesized medicinal effect. This is to shield test participants (with their consent) from knowing who is getting the placebo and who is getting the treatment under test, as patients' and clinicians' expectations of efficacy can influence results.
</p><p>The idea of a placebo effect was discussed in 18th century psychology, but became more prominent in the 20th century. Modern studies find that placebos can affect some outcomes such as pain and nausea, but otherwise do not generally have important clinical effects. Improvements that patients experience after being treated with a placebo can also be due to unrelated factors, such as regression to the mean (a statistical effect where an unusually high or low measurement is likely to be followed by a less extreme one). The use of placebos in clinical medicine raises ethical concerns, especially if they are disguised as an active treatment, as this introduces dishonesty into the doctor–patient relationship and bypasses informed consent.
</p><p>Placebos are also popular because they can sometimes produce relief through psychological mechanisms (a phenomenon known as the "placebo effect"). They can affect how patients perceive their condition and encourage the body's chemical processes for relieving pain and a few other symptoms, but have no impact on the disease itself.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Placebo'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Out–group homogeneity bias</h2>
<a href='https://en.wikipedia.org/wiki/Out-group_homogeneity' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>out-group homogeneity effect</b> is the perception of out-group members as more similar to one another than are in-group members, e.g. "they are alike; we are diverse". Perceivers tend to have impressions about the diversity or variability of group members around those central tendencies or typical attributes of those group members. Thus, outgroup stereotypicality judgments are overestimated, supporting the view that out-group stereotypes are overgeneralizations. The term "outgroup homogeneity effect", "outgroup homogeneity bias" or "relative outgroup homogeneity" have been explicitly contrasted with "outgroup homogeneity" in general, the latter referring to perceived outgroup variability unrelated to perceptions of the ingroup.
</p><p>The outgroup homogeneity effect is sometimes referred to as "outgroup homogeneity bias". Such nomenclature hints at a broader meta-theoretical debate that is present in the field of social psychology. This debate centres on the validity of heightened perceptions of ingroup and outgroup homogeneity, where some researchers view the homogeneity effect as an example of cognitive bias and error, while other researchers view the effect as an example of normal and often adaptive social perception. The out-group homogeneity effect has been found using a wide variety of different social groups, from political and racial groups to age and gender groups.
</p><p>The out-group homogeneity effect is part of a broader field of research that examines perceived group variability. This area includes in-group homogeneity effects as well as out-group homogeneity effects, and it also deals with perceived group variability effects that are not linked to in-group/out-group membership, such as effects that are related to the power, status, and size of groups. The out-group homogeneity effect has been found using a wide variety of different social groups, from political and racial groups to age and gender groups. The implications of this effect on stereotyping have been noted.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Out-group_homogeneity'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Cross–race effect</h2>
<a href='https://en.wikipedia.org/wiki/Cross-race_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>cross-race effect</b> (sometimes called <b>cross-race bias</b>, <b>other-race bias</b>, <b>own-race bias</b> or <b>other-race effect</b>) is the tendency to more easily recognize faces that belong to one's own racial group, or racial groups that one has been in contact with. In social psychology, the cross-race effect is described as the "ingroup advantage," whereas in other fields, the effect can be seen as a specific form of the "ingroup advantage" since it is only applied in interracial or inter-ethnic situations. The cross-race effect is thought to contribute to difficulties in cross-race identification, as well as implicit racial bias.
</p><p>A number of theories as to why the cross-race effect exists have been conceived, including social cognition and perceptual expertise. However, no model has been able to fully account for the full body of evidence.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Cross-race_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>In–group favoritism</h2>
<a href='https://en.wikipedia.org/wiki/In-group_favoritism' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>


<p><b>In-group favoritism</b>, sometimes known as <b>in-group–out-group bias</b>, <b>in-group bias</b>, <b>intergroup bias</b>, or <b>in-group preference</b>, is a pattern of favoring members of one's in-group over out-group members. This can be expressed in evaluation of others, in allocation of resources, and in many other ways.
</p><p>This effect has been researched by many psychologists and linked to many theories related to group conflict and prejudice. The phenomenon is primarily viewed from a social psychology standpoint. Studies have shown that in-group favoritism arises as a result of the formation of cultural groups. These cultural groups can be divided based on seemingly trivial observable traits, but with time, populations grow to associate certain traits with certain behavior, increasing covariation. This then incentivizes in-group bias.
</p><p>Two prominent theoretical approaches to the phenomenon of in-group favoritism are realistic conflict theory and social identity theory. Realistic conflict theory proposes that intergroup competition, and sometimes intergroup conflict, arises when two groups have opposing claims to scarce resources. In contrast, social identity theory posits a psychological drive for positively distinct social identities as the general root cause of in-group favoring behavior.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/In-group_favoritism'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Halo effect</h2>
<a href='https://en.wikipedia.org/wiki/Halo_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>halo effect</b> (sometimes called the <b>halo error</b>) is the tendency for positive impressions of a person, company, country, brand, or product in one area to positively influence one's opinion or feelings. The halo effect is "the name given to the phenomenon whereby evaluators tend to be influenced by their previous judgments of performance or personality." The halo effect is a cognitive bias which can prevent someone from forming an image of a person, a product or a brand based on the sum of all objective circumstances at hand.
</p><p>The term was coined by Edward Thorndike. A simplified example of the halo effect is when a person, after noticing that an individual in a photograph is attractive, well groomed, and properly attired, then assumes, using a mental heuristic, that the person in the photograph is a good person based upon the rules of their own social concept. This constant error in judgment is reflective of the individual's preferences, prejudices, ideology, aspirations, and social perception.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Halo_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Cheerleader effect</h2>
<a href='https://en.wikipedia.org/wiki/Cheerleader_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>cheerleader effect</b>, also known as the <b>group attractiveness effect</b> or the <b>friend effect</b>, is a proposed cognitive bias which causes people to perceive individuals as 1.5–2.0% more attractive in a group than when seen alone. The first paper to report this effect was written by Drew Walker and Edward Vul, in 2013.
</p><p>Physical attractiveness implies individuals' preferences in a sexual selection based on the evolutionary psychology. In 1979, Donald Symons first proposed this evolutionary explanation, suggesting that the evolving physical attractiveness results from mate assessment favoring partners who exhibited signs of good health and fertility, including face averageness. This preference was proved to be shared across cultures. Two parts constitute physical attractiveness, and most former studies investigated underlying mechanisms leading to cheerleader effect specifically in its subset, facial attractiveness. Nevertheless, a study has recognized this effect in another physical appearance indicator, human body perceptions.
</p><p>The effect size of the cheerleader effect is not modulated by the presentation time, the number of individuals surrounding the target, spatial arrangement of the faces in the group. However, another study argued that the arrangement of faces in the group might influence this effect since people's central viewing tendency might affect observers to focus more on the perceived attractiveness of the middle face in the group.
</p><p>Findings of this effect are interdisciplinary in applications. Based on them, mate choice, marketing, and social media tactics are designed to increase the attractiveness of a target individual or item via the help of the group.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Cheerleader_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Positivity effect</h2>
<a href='https://en.wikipedia.org/wiki/Positivity_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>positivity effect</b> is the ability to constructively analyze a situation where the desired results are not achieved, but still obtain positive feedback that assists one's future progression.
</p><p>Empirical research findings suggest that the positivity effect can be influenced by internal positive speech, where engaging in constructive self-dialogue can significantly improve one’s ability to perceive and react to challenging situations more optimistically.
</p><p>The findings of a study show that the optimism bias in future-oriented thinking fulfils a self-improvement purpose while also suggesting this bias probably reflects a common underpinning motivational process across various future-thinking domains, either episodic or semantic.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Positivity_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Not invented here</h2>
<a href='https://en.wikipedia.org/wiki/Not_invented_here' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Not invented here</b> (<b>NIH</b>) is the tendency to avoid using or buying products, research, standards, or knowledge from external origins. It is usually adopted by social, corporate, or institutional cultures. Research illustrates a strong bias against ideas from the outside.
</p><p>The reasons for not wanting to use the work of others are varied, but can include a desire to support a local economy instead of paying royalties to a foreign license-holder, fear of patent infringement, lack of understanding of the foreign work, an unwillingness to acknowledge or value the work of others, jealousy, belief perseverance, or forming part of a wider turf war. As a social phenomenon, this tendency can manifest itself as an unwillingness to adopt an idea or product because it originates from another culture, a form of tribalism and/or an inadequate effort in choosing the right approach for the business.
</p><p>The term is typically used in a pejorative sense. The opposite predisposition is sometimes called "proudly found elsewhere" (PFE) or "invented elsewhere".
</p>
</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Not_invented_here'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Reactive devaluation</h2>
<a href='https://en.wikipedia.org/wiki/Reactive_devaluation' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Reactive devaluation</b> is a cognitive bias that occurs when a proposal is devalued if it appears to originate from an antagonist. The bias was proposed by Lee Ross and Constance Stillinger (1988).
</p><p>Reactive devaluation could be caused by loss aversion or attitude polarization, or naïve realism.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Reactive_devaluation'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Well–traveled road effect</h2>
<a href='https://en.wikipedia.org/wiki/Well_travelled_road_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>well travelled road effect</b> is a cognitive bias in which travellers will estimate the time taken to traverse routes differently depending on their familiarity with the route. Frequently travelled routes are assessed as taking a shorter time than unfamiliar routes. This effect creates errors when estimating the most efficient route to an unfamiliar destination, when one candidate route includes a familiar route, whilst the other candidate route includes no familiar routes. The effect is most salient when subjects are driving, but is still detectable for pedestrians and users of public transport. The effect has been observed for centuries but was first studied scientifically in the 1980s and 1990s following from earlier "heuristics and biases" work undertaken by Daniel Kahneman and Amos Tversky.
</p><p>Much like the Stroop task, it is hypothesised that drivers use less cognitive effort when traversing familiar routes and therefore underestimate the time taken to traverse the familiar route.  The well travelled road effect has been hypothesised as a reason that self-reported experience curve effects are overestimated.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Well_travelled_road_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Mental accounting</h2>
<a href='https://en.wikipedia.org/wiki/Mental_accounting' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Mental accounting</b> (or <b>psychological accounting</b>) is a model of consumer behaviour developed by Richard Thaler that attempts to describe the process whereby people code, categorize and evaluate economic outcomes. Mental accounting incorporates the economic concepts of prospect theory and transactional utility theory to evaluate how people create distinctions between their financial resources in the form of mental accounts, which in turn impacts the buyer decision process and reaction to economic outcomes.  People are presumed to make mental accounts as a self control strategy to manage and keep track of their spending and resources. People budget money into mental accounts for savings (e.g., saving for a home) or expense categories (e.g., gas money, clothing, utilities). People also are assumed to make mental accounts to facilitate savings for larger purposes (e.g., a home or college tuition). Mental accounting can result in people demonstrating greater loss aversion for certain mental accounts, resulting in cognitive bias that incentivizes systematic departures from consumer rationality. Through an increased understanding of mental accounting differences in decision making based on different resources, and different reactions based on similar outcomes can be greater understood. 
</p><p>As Thaler puts it, "All organizations, from General Motors down to single person households, have explicit and/or implicit accounting systems. The accounting system often influences decisions in unexpected ways". Particularly, individual expenses will usually not be considered in conjunction with the present value of one's total wealth; they will be instead considered in the context of two accounts: the current budgetary period (this could be a monthly process due to bills, or yearly due to an annual income), and the category of expense.  People can even have multiple mental accounts for the same kind of resource. A person may use different monthly budgets for grocery shopping and eating out at restaurants, for example, and constrain one kind of purchase when its budget has run out while not constraining the other kind of purchase, even though both expenditures draw on the same fungible resource (income).
</p><p>One detailed application of mental accounting, the Behavioral Life Cycle Hypothesis posits that people mentally frame assets as belonging to either current income, current wealth or future income and this has implications for their behavior as the accounts are largely non-fungible and marginal propensity to consume out of each account is different. 
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Mental_accounting'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Appeal to probability fallacy</h2>
<a href='https://en.wikipedia.org/wiki/Appeal_to_probability' target='_blank'>Wikipedia Link</a>
<div class='content'><p>An <b>appeal to probability</b> (or <b>appeal to possibility</b>, also known as <i>possibiliter ergo probabiliter</i>, "possibly, therefore probably") is the logical fallacy of taking something for granted because it is possibly the case.  The fact that an event is possible does not imply that the event is probable, nor that the event was realized. 
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Appeal_to_probability'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Normalcy bias</h2>
<a href='https://en.wikipedia.org/wiki/Normalcy_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Normalcy bias</b>, or <b>normality bias</b>, is a cognitive bias which leads people to disbelieve or minimize threat warnings. Consequently, individuals underestimate the likelihood of a disaster, when it might affect them, and its potential adverse effects. The normalcy bias causes many people to prepare inadequately for natural disasters, market crashes, and calamities caused by human error. About 80% of people reportedly display normalcy bias during a disaster.
</p><p>The normalcy bias can manifest in response to warnings about disasters and actual catastrophes. Such events can range in scale from incidents such as traffic collisions to global catastrophic risk. The event may involve social constructionism phenomena such as loss of money in market crashes, or direct threats to continuity of life: as in natural disasters like a tsunami or violence in war.
</p><p>Normalcy bias has also been called <i>analysis paralysis</i>, <i>the ostrich effect</i>, and by first responders, <i>the negative panic</i>. The opposite of normalcy bias is overreaction, or worst-case scenario bias, in which small deviations from normality are dealt with as signals of an impending catastrophe.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Normalcy_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Murphy's Law</h2>
<a href='https://en.wikipedia.org/wiki/Murphy's_law' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Murphy's law</b> is an adage or epigram that is typically stated as: "Anything that can go wrong will go wrong."
</p><p>Though similar statements and concepts have been made over the course of history, the law itself was coined by, and  named after, American aerospace engineer Edward A. Murphy Jr.; its exact origins are debated, but it is generally agreed it originated from Murphy and his team following a mishap during rocket sled tests some time between 1948 and 1949, and was finalized and first popularized by testing project head John Stapp during a later press conference. Murphy's original quote was the precautionary design advice that "If there are two or more ways to do something and one of those results in a catastrophe, then someone will do it that way."
</p><p>The law entered wider public knowledge in the late 1970s with the publication of Arthur Bloch's 1977 book <i>Murphy's Law, and Other Reasons Why Things Go WRONG</i>, which included other variations and corollaries of the law. Since then, Murphy's law has remained a popular (and occasionally misused) adage, though its accuracy has been disputed by academics. 
</p><p>Similar "laws" include Sod's law, Finagle's law, and Yhprum's law, among others.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Murphy's_law'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Zero sum bias</h2>
<a href='https://en.wikipedia.org/wiki/Zero-sum_thinking' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Zero-sum thinking</b> perceives situations as zero-sum games, where one person's gain would be another's loss. The term is derived from game theory. However, unlike the game theory concept, zero-sum thinking refers to a psychological construct—a person's subjective interpretation of a situation. Zero-sum thinking is captured by the saying "your gain is my loss" (or conversely, "your loss is my gain"). Rozycka-Tran et al. (2015) defined zero-sum thinking as:
</p>
<blockquote><p>A general belief system about the antagonistic nature of social relations, shared by people in a society or culture and based on the implicit assumption that a finite amount of goods exists in the world, in which one person's winning makes others the losers, and vice versa ... a relatively permanent and general conviction that social relations are like a zero-sum game. People who share this conviction believe that success, especially economic success, is possible only at the expense of other people's failures.</p></blockquote>
<p><b>Zero-sum bias</b> is a cognitive bias towards zero-sum thinking; it is people's tendency to intuitively judge that a situation is zero-sum, even when this is not the case. This bias promotes <b>zero-sum fallacies</b>, false beliefs that situations are zero-sum. Such fallacies can cause other false judgements and poor decisions. In economics, "zero-sum fallacy" generally refers to the fixed-pie fallacy.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Zero-sum_thinking'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Survivorship bias</h2>
<a href='https://en.wikipedia.org/wiki/Survivorship_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>

<p><b>Survivorship bias</b> or <b>survival bias</b> is the logical error of concentrating on entities that passed a selection process while overlooking those that did not. This can lead to incorrect conclusions because of incomplete data.  
</p><p>Survivorship bias is a form of sampling bias that can lead to overly optimistic beliefs because multiple failures are overlooked, such as when companies that no longer exist are excluded from analyses of financial performance. It can also lead to the false belief that the successes in a group have some special property, rather than just coincidence as in correlation "proves" causality.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Survivorship_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Subadditivity effect</h2>
<a href='https://en.wikipedia.org/wiki/Subadditivity_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>subadditivity effect</b> is the tendency to judge probability of the whole to be less than the probabilities of the parts.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Subadditivity_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Denomination effect</h2>
<a href='https://en.wikipedia.org/wiki/Denomination_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>

<p>The <b>denomination effect</b> is a form of cognitive bias relating to currency, suggesting people may be less likely to spend larger currency denominations than their equivalent value in smaller denominations. It was proposed by Priya Raghubir, professor at the New York University Stern School of Business, and Joydeep Srivastava, professor at University of Maryland, in their 2009 paper "Denomination Effect".
</p><p>Raghubir and Srivastava conducted three studies in their research on the denomination effect; their findings suggested people may be more likely to spend money represented by smaller denominations and that consumers may prefer to receive money in a large denomination when there is a need to control spending. The denomination effect can occur when large denominations are perceived as less exchangeable than smaller denominations.
</p><p>The effect's influence on spending decisions has implications throughout various sectors in society, including consumer welfare, monetary policy and the finance industry. For example, during the Great Recession, one businessman observed employees using more coins rather than banknotes in an office vending machine, perceiving the customers used coins to feel thriftier. Raghubir and Srivastava also suggested the effect may involve incentives to alter future behavior and that a large denomination can serve as a mechanism to prevent the urge to spend.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Denomination_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>The magical number 7 ± 2</h2>
<a href='https://en.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">

</p><p>"<b>The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information</b>" is one of the most highly cited papers in psychology. It was written by the cognitive psychologist George A. Miller of Harvard University's Department of Psychology and published in 1956 in <i>Psychological Review</i>. It is often interpreted to argue that the number of objects an average human can hold in short-term memory is 7 ± 2. This has occasionally been referred to as <i>Miller's law</i>.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Illusion of transparency</h2>
<a href='https://en.wikipedia.org/wiki/Illusion_of_transparency' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>illusion of transparency</b> is a tendency for people to overestimate the degree to which their personal mental state is known by others. Another manifestation of the illusion of transparency (sometimes called the observer's illusion of transparency) is a tendency for people to overestimate how well they understand others' personal mental states. This cognitive bias is similar to the illusion of asymmetric insight.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Illusion_of_transparency'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Curse of knowledge</h2>
<a href='https://en.wikipedia.org/wiki/Curse_of_knowledge' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>curse of knowledge</b>, also called the <b>curse of expertise</b> or <b>expert's curse</b>, is a cognitive bias that occurs when a person who has specialized knowledge assumes that others share in that knowledge.
</p><p>For example, in a classroom setting, teachers may have difficulty if they cannot put themselves in the position of the student. A knowledgeable professor might no longer remember the difficulties that a young student encounters when learning a new subject for the first time. This curse of knowledge also explains the danger behind thinking about student learning based on what appears best to faculty members, as opposed to what has been verified with students.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Curse_of_knowledge'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Spotlight effect</h2>
<a href='https://en.wikipedia.org/wiki/Spotlight_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>spotlight effect</b> is the psychological phenomenon by which people tend to believe they are being noticed more than they really are. Being that one is constantly in the center of one's own world, an <i>accurate</i> evaluation of how much one is noticed by others is uncommon. The reason for the spotlight effect is the innate tendency to forget that although one is the center of one's own world, one is not the center of everyone else's. This tendency is especially prominent when one does something atypical.
</p><p>Research has empirically shown that such drastic over-estimation of one's effect on others is widely common. Many professionals in social psychology encourage people to be conscious of the spotlight effect and to allow this phenomenon to moderate the extent to which one believes one is in a social spotlight.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Spotlight_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Extrinsic incentive error</h2>
<a href='https://en.wikipedia.org/wiki/Extrinsic_incentives_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>extrinsic incentives bias</b> is an attributional bias according to which people attribute relatively more to "extrinsic incentives" (such as monetary reward) than to "intrinsic incentives" (such as learning a new skill) when weighing the motives of others rather than themselves.
</p><p>It is a counter-example to the fundamental attribution error as according to the extrinsic bias others are presumed to have <i>situational</i> motivations while oneself is seen as having <i>dispositional</i> motivations. This is the opposite of what the fundamental attribution error would predict. It also might help to explain some of the backfiring effects that can occur when extrinsic incentives are attached to activities that people are intrinsically motivated to do. The term was first proposed by Chip Heath, citing earlier research by others in management science. 
</p>
</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Extrinsic_incentives_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Illusion of external agency</h2>
<a href='https://en.wikipedia.org/wiki/Illusion_of_external_agency' target='_blank'>Wikipedia Link</a>
<div class='content'></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Illusion_of_external_agency'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Illusion of asymmetric insight</h2>
<a href='https://en.wikipedia.org/wiki/Illusion_of_asymmetric_insight' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>illusion of asymmetric insight</b> is a cognitive bias whereby people perceive their knowledge of others to surpass other people's knowledge of them. This bias "has been traced to people's tendency to view their own spontaneous or off-the-cuff responses to others' questions as relatively unrevealing even though they view others' similar responses as meaningful".
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Illusion_of_asymmetric_insight'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Telescoping effect</h2>
<a href='https://en.wikipedia.org/wiki/Telescoping_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In cognitive psychology, the <b>telescoping effect</b> (or <b>telescoping bias</b>) refers to the temporal displacement of an event whereby people perceive recent events as being more remote than they are and distant events as being more recent than they are. The former is known as <b>backward telescoping</b> or <b>time expansion</b>, and the latter as is known as <b>forward telescoping</b>.
</p><p>The approximate time frame in which events switch from being displaced backward in time to forward in time is three years, with events occurring three years in the past being equally likely to be reported with forward telescoping bias as with backward telescoping bias. Although telescoping occurs in both the forward and backward directions, in general the effect is to increase the number of events reported too recently. This net effect in the forward direction is because forces that impair memory, such as lack of salience, also impair time perception.
</p><p>Telescoping leads to an over-reporting of the frequency of events. This over-reporting is because participants include events beyond the period, either events that are too recent for the target time period (backward telescoping) or events that are too old for the target time period (forward telescoping).
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Telescoping_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Rosy retrospection</h2>
<a href='https://en.wikipedia.org/wiki/Rosy_retrospection' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Rosy retrospection</b> is a proposed psychological phenomenon of recalling the past more positively than it was actually experienced.
</p><p>The highly unreliable nature of human memory is well documented and accepted amongst psychologists. Some research suggests a 'blue retrospective' which also exaggerates negative emotions.
</p><p>Though it is a cognitive bias which distorts one's view of reality, it is suggested that rosy retrospection serves a useful purpose in increasing self-esteem and sense of well-being.
</p><p>Simplifications and exaggerations of memories such as occur in rosy retrospection may make it easier for the brain to store long-term memories, as removing details may reduce the burden of those memories by requiring the generation and maintenance of fewer neural connections.
</p><p>Declinism, the predisposition to view the past more favourably and the future more negatively, may be related to cognitive biases like rosy retrospection.
</p><p>Rosy retrospection is very closely related to the concept of nostalgia though still different respectively in being rosy retrospection being biased towards perceiving the past as better than the present.
</p><p>The English idiom "rose-colored glasses" or "rose-tinted glasses" refers to perceiving something more positively than it is in reality (also in German, French, Polish).
</p><p>The Romans occasionally referred to this phenomenon with the Latin phrase "<span title="Latin-language text"><i lang="la">memoria praeteritorum bonorum</i></span>", which translates into English roughly as "memory of good past", or more idiomatically as "good old days".
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Rosy_retrospection'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Hindsight bias</h2>
<a href='https://en.wikipedia.org/wiki/Hindsight_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p><p><b>Hindsight bias</b>, also known as the <b>knew-it-all-along phenomenon</b> or <b>creeping determinism</b>, is the common tendency for people to perceive past events as having been more predictable than they were.
</p><p>After an event has occurred, people often believe that they could have predicted or perhaps even known with a high degree of certainty what the outcome of the event would be before it occurred. Hindsight bias may cause distortions of memories of what was known or believed before an event occurred and is a significant source of overconfidence in one’s ability to predict the outcomes of future events. Examples of hindsight bias can be seen in the writings of historians describing the outcomes of battles, in physicians’ recall of clinical trials, and in criminal or civil trials as people tend to assign responsibility on the basis of the supposed predictability of accidents.
</p><p>In some countries, 20/20 indicates normal visual acuity at 20 feet, from which derives the idiom "hindsight is 20/20".
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Hindsight_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Outcome bias</h2>
<a href='https://en.wikipedia.org/wiki/Outcome_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>outcome bias</b> is an error made in evaluating the quality of a decision when the outcome of that decision is already known. Specifically, the outcome effect occurs when the same "behavior produce[s] more ethical condemnation when it happen[s] to produce bad rather than good outcome, even if the outcome is determined by chance."
</p><p>While similar to the hindsight bias, the two phenomena are markedly different. Hindsight bias focuses on memory distortion to favor the actor, while the outcome bias focuses exclusively on weighting the outcome heavier than other pieces of information in deciding if a past decision was correct.
</p>
</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Outcome_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Moral luck</h2>
<a href='https://en.wikipedia.org/wiki/Moral_luck' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Moral luck</b> describes circumstances whereby a moral agent is assigned moral blame or praise for an action or its consequences, even if it is clear that said agent did not have full control over either the action or its consequences. This term, introduced by Bernard Williams, has been developed, along with its significance to a coherent moral theory, by Williams and Thomas Nagel in their respective essays on the subject.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Moral_luck'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Declinism</h2>
<a href='https://en.wikipedia.org/wiki/Declinism' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Declinism</b> is the belief that a society or institution is tending towards decline. Particularly, it is the predisposition, caused by cognitive biases such as rosy retrospection, to view the past more favourably and the future more negatively.
</p><p>"The great summit of declinism" according to Adam Gopnick, "was established in 1918, in the book that gave decline its good name in publishing: the German historian Oswald Spengler's best-selling, thousand-page work <i>The Decline of the West</i>."
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Declinism'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Impact bias</h2>
<a href='https://en.wikipedia.org/wiki/Impact_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In the psychology of affective forecasting, the <b>impact bias</b>, a form of which is the <b>durability bias</b>, is the tendency for people to overestimate the length or the intensity of future emotional states.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Impact_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Pessimism bias</h2>
<a href='https://en.wikipedia.org/wiki/Optimism_bias#Pessimism_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Optimism bias</b> or <b>optimistic bias</b> is a cognitive bias that causes someone to believe that they themselves are less likely to experience a negative event. It is also known as <b>unrealistic optimism</b> or <b>comparative optimism</b>. It is common and transcends gender, ethnicity, nationality, and age. Autistic people are less susceptible to this kind of bias. It has also been reported in other animals, such as rats and birds. 
</p><p>Four factors can cause a person to be optimistically biased: their desired end state, their cognitive mechanisms, the information they have about themselves versus others, and overall mood. The optimistic bias is seen in a number of situations. For example: people believing that they are less at risk of being a crime victim, smokers believing that they are less likely to contract lung cancer or disease than other smokers, first-time bungee jumpers believing that they are less at risk of an injury than other jumpers, or traders who think they are less exposed to potential losses in the markets.
</p><p>Although the optimism bias occurs for both positive events (such as believing oneself to be more financially successful than others) and negative events (such as being less likely to have a drinking problem), there is more research and evidence suggesting that the bias is stronger for negative events (the "valence effect"). Different consequences result from these two types of events: positive events often lead to feelings of well being and self-esteem, while negative events lead to consequences involving more risk, such as engaging in risky behaviors and not taking precautionary measures for safety.
</p>

<h2 data-mw-anchor="Factors">Factors</h2>
<p>The factors leading to the optimistic bias can be categorized into four different groups: desired end states of comparative judgment, cognitive mechanisms, information about the self versus a target, and underlying affect. These are explained more in detail below.
</p>
<h3 data-mw-anchor="Measuring">Measuring</h3>
<p>Optimism bias is typically measured through two determinants of risk: absolute risk, where individuals are asked to estimate their likelihood of experiencing a negative event compared to their actual chance of experiencing a negative event (comparison against self), and comparative risk, where individuals are asked to estimate the likelihood of experiencing a negative event (their personal risk estimate) compared to others of the same age and sex (a target risk estimate). Problems can occur when trying to measure absolute risk because it is extremely difficult to determine the actual risk statistic for a person. Therefore, the optimistic bias is primarily measured in comparative risk forms, where people compare themselves against others, through direct and indirect comparisons. Direct comparisons ask whether an individual's own risk of experiencing an event is less than, greater than, or equal to someone else's risk, while indirect comparisons ask individuals to provide separate estimates of their own risk of experiencing an event and others' risk of experiencing the same event.
</p><p>After obtaining scores, researchers are able to use the information to determine if there is a difference in the average risk estimate of the individual compared to the average risk estimate of their peers. Generally, in negative events, the mean risk of an individual appears lower than the risk estimate of others. This is then used to demonstrate the bias' effect. The optimistic bias can only be defined at a group level, because at an individual level the positive assessment could be true. Likewise, difficulties can arise in measurement procedures, as it is difficult to determine when someone is being optimistic, realistic, or pessimistic. Research suggests that the bias comes from an overestimate of group risks rather than underestimating one's own risk.
</p><p>An example: participants assigned a higher probability to picking a card that had a smiling face on its reverse side than one which had a frowning face.
</p>
<h3 data-mw-anchor="Cognitive_mechanisms">Cognitive mechanisms</h3>
<p>The optimistic bias is possibly also influenced by three cognitive mechanisms that guide judgments and decision-making processes: the representativeness heuristic, singular target focus, and interpersonal distance.
</p>
<h4 data-mw-anchor="Representativeness_heuristic">Representativeness heuristic</h4>
<p>The estimates of likelihood associated with the optimistic bias are based on how closely an event matches a person's overall idea of the specific event. Some researchers suggest that the representativeness heuristic is a reason for the optimistic bias: individuals tend to think in stereotypical categories rather than about their actual targets when making comparisons. For example, when drivers are asked to think about a car accident, they are more likely to associate a bad driver, rather than just the average driver. Individuals compare themselves with the negative elements that come to mind, rather than an overall accurate comparison between them and another driver. Additionally, when individuals were asked to compare themselves towards friends, they chose more vulnerable friends based on the events they were looking at. Individuals generally chose a specific friend based on whether they resemble a given example, rather than just an average friend. People find examples that relate directly to what they are asked, resulting in representativeness heuristics.
</p>
<h4 data-mw-anchor="Singular_target_focus">Singular target focus</h4>
<p>One of the difficulties of the optimistic bias is that people know more about themselves than they do about others. While individuals know how to think about themselves as a single person, they still think of others as a generalized group, which leads to biased estimates and inabilities to sufficiently understand their target or comparison group. Likewise, when making judgments and comparisons about their risk compared to others, people generally ignore the average person, but primarily focus on their own feelings and experiences.
</p>
<h4 data-mw-anchor="Interpersonal_distance">Interpersonal distance</h4>
<p>Perceived risk differences occur depending on how far or close a compared target is to an individual making a risk estimate. The greater the perceived distance between the self and the comparison target, the greater the perceived difference in risk. When one brings the comparison target closer to the individual, risk estimates appear closer together than if the comparison target was someone more distant to the participant. There is support for perceived social distance in determining the optimistic bias. Through looking at comparisons of personal and target risk between the in-group level contributes to more perceived similarities than when individuals think about outer-group comparisons which lead to greater perceived differences. In one study, researchers manipulated the social context of the comparison group, where participants made judgements for two different comparison targets: the typical student at their university and a typical student at another university. Their findings showed that not only did people work with the closer comparison first, but also had closer ratings to themselves than the "more different" group.
</p><p>Studies have also noticed that people demonstrate more optimistic bias when making comparisons when the other is a vague individual, but biases are reduced when the other is a familiar person, such as a friend or family member. This also is determined due to the information they have about the individuals closest to them, but not having the same information about other people.
</p>
<h2 data-mw-anchor="Desired_end_states_of_comparative_judgment">Desired end states of comparative judgment</h2>
<p>Many explanations for the optimistic bias come from the goals that people want and outcomes they wish to see. People tend to view their risks as less than others because they believe that this is what other people want to see. These explanations include self-enhancement, self-presentation, and perceived control.
</p>
<h3 data-mw-anchor="Self-enhancement">Self-enhancement</h3>
<p>Self-enhancement suggests that optimistic predictions are satisfying and that it feels good to think that positive events will happen. People can control their anxiety and other negative emotions if they believe they are better off than others. People tend to focus on finding information that supports what they want to see happen, rather than what will happen to them. With regards to the optimistic bias, individuals will perceive events more favorably, because that is what they would like the outcome to be. This also suggests that people might lower their risks compared to others to make themselves look better than average: they are less at risk than others and therefore better.
</p>
<h3 data-mw-anchor="Self-presentation">Self-presentation</h3>
<p>Studies suggest that people attempt to establish and maintain a desired personal image in social situations. People are motivated to present themselves towards others in a good light, and some researchers suggest that the optimistic bias is a representative of self-presentational processes: people want to appear better off than others. This is not through conscious effort. In a study where participants believed their driving skills would be either tested in either real-life or driving simulations, people who believed they were to be tested had less optimistic bias and were more modest about their skills than individuals who would not be tested. Studies also suggest that individuals who present themselves in a pessimistic and more negative light are generally less accepted by the rest of society. This might contribute to overly optimistic attitudes.
</p>
<h3 data-mw-anchor="Personal_control/perceived_control" data-mw-fallback-anchor="Personal_control.2Fperceived_control">Personal control/perceived control</h3>
<p>People tend to be more optimistically biased when they believe they have more control over events than others. For example, people are more likely to think that they will not be harmed in a car accident if they are driving the vehicle. Another example is that if someone believes that they have a lot of control over becoming infected with HIV, they are more likely to view their risk of contracting the disease to be low. Studies have suggested that the greater perceived control someone has, the greater their optimistic bias. Stemming from this, control is a stronger factor when it comes to personal risk assessments, but not when assessing others.
</p><p>A meta-analysis reviewing the relationship between the optimistic bias and perceived control found that a number of moderators contribute to this relationship. In previous research, participants from the United States generally had higher levels of optimistic bias relating to perceived control than those of other nationalities. Students also showed larger levels of the optimistic bias than non-students. The format of the study also demonstrated differences in the relationship between perceived control and the optimistic bias: direct methods of measurement suggested greater perceived control and greater optimistic bias as compared to indirect measures of the bias. The optimistic bias is strongest in situations where an individual needs to rely heavily on direct action and responsibility of situations.
</p><p>An opposite factor of perceived control is that of prior experience. Prior experience is typically associated with less optimistic bias, which some studies suggest is from either a decrease in the perception of personal control, or make it easier for individuals to imagine themselves at risk. Prior experience suggests that events may be less controllable than previously believed.
</p>
<h2 data-mw-anchor="Information_about_self_versus_target">Information about self versus target</h2>
<p>Individuals know a lot more about themselves than they do about others. Because information about others is less available, information about the self versus others leads people to make specific conclusions about their own risk, but results in them having a harder time making conclusions about the risks of others. This leads to differences in judgments and conclusions about self-risks compared to the risks of others, leading to larger gaps in the optimistic bias.
</p>
<h3 data-mw-anchor="Person-positivity_bias">Person-positivity bias</h3>
<p>Person-positivity bias is the tendency to evaluate an object more favorably the more the object resembles an individual human being. Generally, the more a comparison target resembles a specific person, the more familiar it will be. Groups of people are considered to be more abstract concepts, which leads to less favorable judgments. With regards to the optimistic bias, when people compare themselves to an average person, whether someone of the same sex or age, the target continues to be viewed as less human and less personified, which will result in less favorable comparisons between the self and others.
</p>
<h3 data-mw-anchor="Egocentric_thinking">Egocentric thinking</h3>

<p>"Egocentric thinking" refers to how individuals know more of their own personal information and risk that they can use to form judgments and make decisions. One difficulty, though, is that people have a large amount of knowledge about themselves, but no knowledge about others. Therefore, when making decisions, people have to use other information available to them, such as population data, in order to learn more about their comparison group. This can relate to an optimism bias because while people are using the available information they have about themselves, they have more difficulty understanding correct information about others. 
</p><p>It is also possible that someone can escape egocentric thinking. In one study, researchers had one group of participants list all factors that influenced their chances of experiencing a variety of events, and then a second group read the list. Those who read the list showed less optimistic bias in their own reports. It's possible that greater knowledge about others and their perceptions of their chances of risk bring the comparison group closer to the participant.
</p>
<h3 data-mw-anchor="Underestimating_average_person's_control" data-mw-fallback-anchor="Underestimating_average_person.27s_control">Underestimating average person's control</h3>
<p>Also regarding egocentric thinking, it is possible that individuals underestimate the amount of control the average person has. This is explained in two different ways:
</p>
<ol><li>People underestimate the control that others have in their lives.</li>
<li>People completely overlook that others have control over their own outcomes.</li></ol>
<p>For example, many smokers believe that they are taking all necessary precautionary measures so that they won't get lung cancer, such as smoking only once a day, or using filtered cigarettes, and believe that others are not taking the same precautionary measures. It is likely that many other smokers are doing the same things and taking those same precautions.
</p>
<h3 data-mw-anchor="Underlying_affect">Underlying affect</h3>
<p>The last factor of optimistic bias is that of underlying affect and affect experience. Research has found that people show less optimistic bias when experiencing a negative mood, and more optimistic bias when in a positive mood. Sad moods reflect greater memories of negative events, which lead to more negative judgments, while positive moods promote happy memories and more positive feelings. This suggests that overall negative moods, including depression, result in increased personal risk estimates but less optimistic bias overall. Anxiety also leads to less optimistic bias, continuing to suggest that overall positive experiences and positive attitudes lead to more optimistic bias in events.
</p>
<h2 data-mw-anchor="Health_consequences">Health consequences</h2>
<p>In health, the optimistic bias tends to prevent individuals from taking on preventative measures for good health. For example, people who underestimate their comparative risk of heart disease know less about heart disease, and even after reading an article with more information, are still less concerned about risk of heart disease. Because the optimistic bias can be a strong force in decision-making, it is important to look at how risk perception is determined and how this will result in preventative behaviors. Therefore, researchers need to be aware of the optimistic bias and the ways it can prevent people from taking precautionary measures in life choices.
</p><p>Risk perceptions are particularly important for individual behaviors, such as exercise, diet, and even sunscreen use.
</p><p>A large portion of risk prevention focuses on adolescents. Especially with health risk perception, adolescence is associated with an increased frequency of risky health-related behaviors such as smoking, drugs, and unsafe sex. While adolescents are aware of the risk, this awareness does not change behavior habits. Adolescents with strong positive optimistic bias toward risky behaviors had an overall increase in the optimistic bias with age.
</p><p>Unconditional risk questions in cross-sectional studies are used consistently, leading to problems, as they ask about the likelihood of an action occurring, but does not determine if there is an outcome, or compare events that haven't happened to events that have. 
many times there are methodological problems in these tests. 
</p><p>Concerning vaccines, perceptions of those who have not been vaccinated are compared to the perceptions of people who have been. Other problems which arise include the failure to know a person's perception of a risk. Knowing this information will be helpful for continued research on optimistic bias and preventative behaviors.
</p>
<h2 data-mw-anchor="Neurosciences">Neurosciences</h2>
<p>Functional neuroimaging suggests a key role for the rostral Anterior Cingulate Cortex (ACC) in modulating both emotional processing and autobiographical retrieval. It is part of brain network showing extensive correlation between rostral ACC and amygdala during imagining of future positive events and restricted correlation during imagining of future negative events. Based on these data, it is suggested that the rostral ACC has a crucial part to play in creating positive images of the future and ultimately, in ensuring and maintaining the optimism bias.
</p>
<h2 data-mw-anchor="Policy,_planning,_and_management" data-mw-fallback-anchor="Policy.2C_planning.2C_and_management">Policy, planning, and management</h2>
<p>Optimism bias influences decisions and forecasts in policy, planning, and management, e.g., the costs and completion times of planned decisions tend to be underestimated and the benefits overestimated due to optimism bias. The term planning fallacy for this effect was first proposed by Daniel Kahneman and Amos Tversky. There is a growing body of evidence proving that optimism bias represents one of the biggest single causes of risk for megaproject overspend.
</p>
<h2 data-mw-anchor="Valence_effect">Valence effect</h2>
<p><b>Valence effect</b> is used to allude to the effect of valence on unrealistic optimism. It has been studied by Ron S. Gold and his team since 2003. They frame questions for the same event in different ways: "some participants were given information about the conditions that promote a given health-related event, such as developing heart disease, and were asked to rate the comparative likelihood that they would experience the event. Other participants were given matched information about the conditions that prevent the same event and were asked to rate the comparative likelihood that they would avoid the event". They have generally found that unrealistic optimism was greater for negative than positive valence.
</p><p>Valence effects, which is also considered a form of cognitive bias, have several real-world implications. For instance, it can lead to the overestimation of a company's future earnings by investors and this could contribute to a tendency for it to becoming overpriced. In terms of achieving organizational objectives, it could encourage people to produce unrealistic schedules helping drive a so-called planning fallacy, which often result in making poor decisions and project abandonment.
</p>
<h2 data-mw-anchor="Attempts_to_alter_and_eliminate">Attempts to alter and eliminate</h2>
<p>Studies have shown that it is very difficult to eliminate the optimistic bias. Some commentators believe that trying to reduce it may encourage people to adapt to health-protective behaviors. Research has suggested that it cannot be reduced, and that efforts to reduce it tend to lead to even more optimistically biased results. In a research study of four different tests to reduce the optimistic bias, through lists of risk factors, participants perceiving themselves as inferior to others, participants asked to think of high-risk individuals, and giving attributes of why they were at risk, all increased the bias rather than decreased it. Other studies have tried to reduce the bias through reducing distance, but overall it still remains.
</p><p>This seemingly paradoxical situation – in which an attempt to reduce bias can sometimes actually increase it – may be related to the insight behind the semi-jocular and recursively worded "Hofstadter's law", which states that:
</p>
<blockquote class="templatequote"><p>It always takes longer than you expect, even when you take into account Hofstadter's law.</p></blockquote>
<p>Although research has suggested that it is very difficult to eliminate the bias, some factors may help in closing the gap of the optimistic bias between an individual and their target risk group. First, by placing the comparison group closer to the individual, the optimistic bias can be reduced: studies found that when individuals were asked to make comparisons between themselves and close friends, there was almost no difference in the likelihood of an event occurring. Additionally, actually experiencing an event leads to a decrease in the optimistic bias. While this only applies to events with prior experience, knowing the previously unknown will result in less optimism of it not occurring.
</p>
<h2 data-mw-anchor="Pessimism_bias">Pessimism bias</h2>
<p>The opposite of optimism bias is pessimism bias (or pessimistic bias), because the principles of the optimistic bias continue to be in effect in situations where individuals regard themselves as worse off than others. Optimism may occur from either a distortion of personal estimates, representing personal optimism, or a distortion for others, representing personal pessimism.
</p><p><b>Pessimism bias</b> is an effect in which people exaggerate the likelihood that negative things will happen to them. It contrasts with optimism bias.
</p><p>People with depression are particularly likely to exhibit pessimism bias. Surveys of smokers have found that their ratings of their risk of heart disease showed a small but significant pessimism bias; the literature as a whole is inconclusive.
</p>
<h2 data-mw-anchor="See_also">See also</h2>


<h2 data-mw-anchor="References">References</h2>

<h2 data-mw-anchor="Bibliography">Bibliography</h2>
<ul><li><cite id="CITEREFRosenhanMessick1966" class="citation journal cs1">Rosenhan, David; Messick, Samuel (1966). "Affect and expectation" <span>(PDF)</span>. <i>Journal of Personality and Social Psychology</i>. <b>3</b> (1): <span>38–</span>44. doi:10.1037/h0022633. PMID 5902075. Archived from the original <span>(PDF)</span> on 2016-05-24.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Personality+and+Social+Psychology&amp;rft.atitle=Affect+and+expectation&amp;rft.volume=3&amp;rft.issue=1&amp;rft.pages=38-44&amp;rft.date=1966&amp;rft_id=info%3Adoi%2F10.1037%2Fh0022633&amp;rft_id=info%3Apmid%2F5902075&amp;rft.aulast=Rosenhan&amp;rft.aufirst=David&amp;rft.au=Messick%2C+Samuel&amp;rft_id=http%3A%2F%2Fweb.mit.edu%2Fcurhan%2Fwww%2Fdocs%2FArticles%2Fbiases%2F3_J_Personality_Social_Psychology_38_%28Rosenhan%29.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AOptimism+bias"></span></li>
<li>Taylor, Nigel (2000). Making Actuaries Less Human. Staple Inn Actuarial Society, 15. <i>For picking a card see section 6.2 on page 15.</i></li></ul>
<h2 data-mw-anchor="Further_reading">Further reading</h2>
<ul><li><cite id="CITEREFGoldBrown2009" class="citation journal cs1">Gold, Ron S.; Brown, Mark G. (2009). "Explaining the effect of event valence on unrealistic optimism". <i>Psychology, Health &amp; Medicine</i>. <b>14</b> (3): <span>262–</span>272. doi:10.1080/13548500802241910. PMID 19444704. S2CID 27425683.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Psychology%2C+Health+%26+Medicine&amp;rft.atitle=Explaining+the+effect+of+event+valence+on+unrealistic+optimism&amp;rft.volume=14&amp;rft.issue=3&amp;rft.pages=262-272&amp;rft.date=2009&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A27425683%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F19444704&amp;rft_id=info%3Adoi%2F10.1080%2F13548500802241910&amp;rft.aulast=Gold&amp;rft.aufirst=Ron+S.&amp;rft.au=Brown%2C+Mark+G.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AOptimism+bias"></span></li></ul>
<h2 data-mw-anchor="External_links">External links</h2>
<ul><li>"Tali Sharot: The optimism bias", Tali Sharot's talk at TED.com</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Optimism_bias#Pessimism_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Planning fallacy</h2>
<a href='https://en.wikipedia.org/wiki/Planning_fallacy' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>planning fallacy</b> is a phenomenon in which predictions about how much time will be needed to complete a future task display an optimism bias and underestimate the time needed. This phenomenon sometimes occurs regardless of the individual's knowledge that past tasks of a similar nature have taken longer to complete than generally planned. The bias affects predictions only about one's own tasks. On the other hand, when outside observers predict task completion times, they tend to exhibit a pessimistic bias, overestimating the time needed. The planning fallacy involves estimates of task completion times more optimistic than those encountered in similar projects in the past.
</p>

<p>The planning fallacy was first proposed by Daniel Kahneman and Amos Tversky in 1979. In 2003, Lovallo and Kahneman proposed an expanded definition as the tendency to underestimate the time, costs, and risks of future actions and at the same time overestimate the benefits of the same actions. According to this definition, the planning fallacy results in not only time overruns, but also cost overruns and benefit shortfalls.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Planning_fallacy'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Time–saving bias</h2>
<a href='https://en.wikipedia.org/wiki/Time-saving_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Time-saving bias</b> is a concept that describes people's tendency to misestimate the time that could be saved (or lost) when increasing (or decreasing) speed.
</p><p>In general, people underestimate the time that could be saved when increasing from a relatively low speed—e.g., 25 mph (40 km/h) or 40 mph (64 km/h)—and overestimate the time that could be saved when increasing from a relatively high speed—e.g., 55 mph (89 km/h) or 90 mph (140 km/h). People also underestimate the time that could be lost when decreasing from a low speed and overestimate the time that could be lost when decreasing from a high speed.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Time-saving_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Pro–innovation bias</h2>
<a href='https://en.wikipedia.org/wiki/Pro-innovation_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In diffusion of innovation theory, a <b>pro-innovation bias</b> is a belief that innovation should be adopted by the whole society without the need for its alteration. The innovation's "champion" has a such strong bias in favor of the innovation, that they may not see its limitations or weaknesses and continue to promote it nonetheless.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Pro-innovation_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Projection bias</h2>
<a href='https://en.wikipedia.org/wiki/Affective_forecasting#Projection_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p>
<b>Affective forecasting</b>, also known as <b>hedonic forecasting</b> or the <b>hedonic forecasting mechanism</b>, is the prediction of one's affect (emotional state) in the future. As a process that influences preferences, decisions, and behavior, affective forecasting is studied by both psychologists and economists, with broad applications.
</p>

<h2 data-mw-anchor="History">History</h2>
<p>In <i>The Theory of Moral Sentiments</i> (1759), Adam Smith observed the personal challenges, and social benefits, of hedonic forecasting errors:
</p>
<blockquote><p>[Consider t]he poor man's son, whom heaven in its anger has visited with ambition, when he begins to look around him, admires the condition of the rich …. and, in order to arrive at it, he devotes himself for ever to the pursuit of wealth and greatness…. Through the whole of his life he pursues the idea of a certain artificial and elegant repose which he may never arrive at, for which he sacrifices a real tranquillity that is at all times in his power, and which, if in the extremity of old age he should at last attain…, he will find to be in no respect preferable to that humble security and contentment which he had abandoned for it. It is then, in the last dregs of life, his body wasted with toil and diseases, his mind galled and ruffled by the memory of a thousand injuries and disappointments..., that he begins at last to find that wealth and greatness are mere trinkets of frivolous utility….
</p><p><br>
</p><p>
[Yet] it is well that nature imposes upon us in this manner. It is this deception which rouses and keeps in continual motion the industry of mankind.</p></blockquote>
<p>In the early 1990s, Kahneman and Snell began research on hedonic forecasts, examining its impact on decision making. The term "affective forecasting" was later coined by psychologists Timothy Wilson and Daniel Gilbert. Early research tended to focus solely on measuring emotional forecasts, while subsequent studies began to examine the accuracy of forecasts, revealing that people are surprisingly poor judges of their future emotional states. For example, in predicting how events like winning the lottery might affect their happiness, people are likely to overestimate future positive feelings, ignoring the numerous other factors that might contribute to their emotional state outside of the single lottery event. Some of the cognitive biases related to systematic errors in affective forecasts are focalism, hot-cold empathy gap, and impact bias.
</p>
<h2 data-mw-anchor="Applications">Applications</h2>
<p>While affective forecasting has traditionally drawn the most attention from economists and psychologists, their findings have in turn generated interest from a variety of other fields, including happiness research, law, and health care. Its effect on decision-making and well-being is of particular concern to policy-makers and analysts in these fields, although it also has applications in ethics. For example, one's tendency to underestimate one's ability to adapt to life-changing events has led to legal theorists questioning the assumptions behind tort damage compensation. Behavioral economists have incorporated discrepancies between forecasts and actual emotional outcomes into their models of different types of utility and welfare. This discrepancy also concerns healthcare analysts, in that many important health decisions depend upon patients' perceptions of their future quality of life.
</p>
<h2 data-mw-anchor="Overview">Overview</h2>
<p>Affective forecasting can be divided into four components: predictions about valence (i.e. positive or negative), the specific emotions experienced, their duration, and their intensity. While errors may occur in all four components, research overwhelmingly indicates that the two areas most prone to bias, usually in the form of overestimation, are duration and intensity. Immune neglect is a form of impact bias in response to negative events, in which people fail to predict how much their recovery will be hastened by their <b>psychological immune system</b>. The psychological immune system is a metaphor "for that system of defenses that helps you feel better when bad things happen", according to Gilbert. On average, people are fairly accurate about predicting which emotions they will feel in response to future events. However, some studies indicate that predicting specific emotions in response to more complex social events leads to greater inaccuracy. For example, one study found that while many women who imagine encountering gender harassment predict feelings of anger, in reality, a much higher proportion report feelings of fear. Other research suggests that accuracy in affective forecasting is greater for positive affect than negative affect, suggesting an overall tendency to overreact to perceived negative events. Gilbert and Wilson posit that this is a result of the psychological immune system.
</p><p>While affective forecasts take place in the present moment, researchers also investigate its future outcomes. That is, they analyze forecasting as a two-step process, encompassing a current prediction as well as a future event. Breaking down the present and future stages allow researchers to measure accuracy, as well as tease out how errors occur. Gilbert and Wilson, for example, categorize errors based on which component they affect and when they enter the forecasting process. In the present phase of affective forecasting, forecasters bring to mind a mental representation of the future event and predict how they will respond emotionally to it. The future phase includes the initial emotional response to the onset of the event, as well as subsequent emotional outcomes, for example, the fading of the initial feeling.
</p><p>When errors occur throughout the forecasting process, people are vulnerable to biases. These biases disable people from accurately predicting their future emotions. Errors may arise due to extrinsic factors, such as framing effects, or intrinsic ones, such as cognitive biases or expectation effects. Because accuracy is often measured as the discrepancy between a forecaster's present prediction and the eventual outcome, researchers also study how time affects affective forecasting. For example, the tendency for people to represent distant events differently from close events is captured in the construal level theory.
</p><p>The finding that people are generally inaccurate affective forecasters has been most obviously incorporated into conceptualizations of happiness and its successful pursuit, as well as decision making across disciplines. Findings in affective forecasts have stimulated philosophical and ethical debates, for example, on how to define welfare. On an applied level, findings have informed various approaches to healthcare policy, tort law, consumer decision making, and measuring utility (see below sections on economics, law, and health).
</p><p>Newer and conflicting evidence suggests that intensity bias in affective forecasting may not be as strong as previous research indicates. Five studies, including a meta-analysis, recover evidence that overestimation in affective forecasting is partly due to the methodology of past research. Their results indicate that some participants misinterpreted specific questions in affective forecasting testing. For example, one study found that undergraduate students tended to overestimate experienced happiness levels when participants were asked how they were feeling in <i>general</i> with and without reference to the election, compared to when participants were asked how they were feeling <i>specifically</i> in reference to the election. Findings indicated that 75%-81% of participants who were asked general questions misinterpreted them.  After clarification of tasks, participants were able to more accurately predict the intensity of their emotions
</p>
<h2 data-mw-anchor="Major_sources_of_errors">Major sources of errors</h2>
<p>Because forecasting errors commonly arise from literature on cognitive processes, many affective forecasting errors derive from and are often framed as cognitive biases, some of which are closely related or overlapping constructs (e.g. projection bias and empathy gap). Below is a list of commonly cited cognitive processes that contribute to forecasting errors.
</p>
<h3 data-mw-anchor="Major_sources_of_error_in_emotion">Major sources of error in emotion</h3>
<h4 data-mw-anchor="Impact_bias">Impact bias</h4>

<p>One of the most common sources of error in affective forecasting across various populations and situations is impact bias, the tendency to overestimate the emotional impact of a future event, whether in terms of intensity or duration. The tendencies to overestimate intensity and duration are both robust and reliable errors found in affective forecasting.
</p><p>One study documenting impact bias examined college students participating in a housing lottery.  These students predicted how happy or unhappy they would be one year after being assigned to either a desirable or an undesirable dormitory. These college students predicted that the lottery outcomes would lead to meaningful differences in their own level of happiness, but follow-up questionnaires revealed that students assigned to desirable or undesirable dormitories reported nearly the same levels of happiness. Thus, differences in forecasts overestimated the impact of the housing assignment on future happiness.
</p><p>Some studies specifically address "durability bias," the tendency to overestimate the length of time future emotional responses will last. Even if people accurately estimate the intensity of their future emotions, they may not be able to estimate their duration. Durability bias is generally stronger in reaction to negative events. This is important because people tend to work toward events they believe will cause lasting happiness, and according to durability bias, people might be working toward the wrong things. Similar to impact bias, durability bias causes a person to overemphasize where the root cause of their happiness lies.
</p><p>Impact bias is a broad term and covers a multitude of more specific errors. Proposed causes of impact bias include mechanisms like immune neglect,  focalism, and misconstruals. The pervasiveness of impact bias in affective forecasts is of particular concern to healthcare specialists, in that it affects both patients' expectations of future medical events as well as patient-provider relationships. (See health.)
</p>
<h4 data-mw-anchor="Expectation_effects">Expectation effects</h4>
<p>Previously formed expectations can alter emotional responses to the event itself, motivating forecasters to confirm or debunk their initial forecasts. In this way, the self-fulfilling prophecy can lead to the perception that forecasters have made accurate predictions. Inaccurate forecasts can also become amplified by expectation effects. For example, a forecaster who expects a movie to be enjoyable will, upon finding it dull, like it significantly less than a forecaster who had no expectations.
</p>
<h4 data-mw-anchor="Sense-making_processes">Sense-making processes</h4>
<p>Major life events can have a huge impact on people's emotions for a very long time but the intensity of that emotion tends to decrease with time, a phenomenon known as <i>emotional evanescence</i>. When making forecasts, forecasters often overlook this phenomenon. Psychologists have suggested that emotion does not decay over time predictably like radioactive isotopes but that the mediating factors are more complex. People have psychological processes that help dampen emotions. Psychologists have proposed that surprising, unexpected, or unlikely events cause more intense emotional reactions. Research suggests that people are unhappy with randomness and chaos and that they automatically think of ways to make sense of an event when it is surprising or unexpected. This sense-making helps individuals recover from negative events more quickly than they would have expected. This is related to immune neglect in that when these unwanted acts of randomness occur people become upset and try to find meaning or ways to cope with the event. The way that people try to make sense of the situation can be considered a coping strategy made by the body. This idea differs from immune neglect due to the fact that this is more of a momentary idea. Immune neglect tries to cope with the event before it even happens.
</p><p>One study documents how sense-making processes decrease emotional reactions. The study found that a small gift produced greater emotional reactions when it was not accompanied by a reason than when it was, arguably because the reason facilitated the sense-making process, dulling the emotional impact of the gift. Researchers have summarized that pleasant feelings are prolonged after a positive situation if people are uncertain about the situation.
</p><p>People fail to anticipate that they will make sense of events in a way that will diminish the intensity of the emotional reaction. This error is known as <i>ordinization neglect</i>. For example, ("I will be ecstatic for many years if my boss agrees to give me a raise") an employee might believe, especially if the employee believes the probability of a raise was unlikely. Immediately after having the request approved, the employee may be thrilled but with time the employees make sense of the situation (e.g., "I am a very hard worker and my boss must have noticed this") thus dampening the emotional reaction.
</p>
<h4 data-mw-anchor="Immune_neglect">Immune neglect</h4>
<p>Gilbert et al. originally coined the term <b>immune neglect</b> (or <em>immune bias</em>) to describe a function of the psychological immune system, which is the set of processes that restore positive emotions after the experience of negative emotions. Immune neglect is people's unawareness of their tendency to adapt to and cope with negative events. Unconsciously the body will identify a stressful event and try to cope with the event or try to avoid it. Bolger &amp; Zuckerman found that coping strategies vary between individuals and are influenced by their personalities. They assumed that since people generally do not take their coping strategies into account when they predict future events, that people with better coping strategies should have a bigger impact bias or a greater difference between their predicted and actual outcome. For example, asking someone who is afraid of clowns how going to a circus would feel may result in an overestimation of fear because the anticipation of such fear causes the body to begin coping with the negative event. Hoerger et al. examined this further by studying college students' emotions toward football games. They found that students who generally coped with their emotions instead of avoiding them would have a greater impact bias when predicting how they'd feel if their team lost the game. They found that those with better coping strategies recovered more quickly. Since the participants did not think about their coping strategies when making predictions, those who actually coped had a greater impact bias. Those who avoided their emotions, felt very closely to what they predicted they would. In other words, students who were able to deal with their emotions were able to recover from their feelings. The students were unaware that their body was actually coping with the stress and this process made them feel better than not dealing with the stress. Hoerger ran another study on immune neglect after this, which studied both daters' and non-daters' forecasts about Valentine's Day, and how they would feel in the days that followed. Hoerger found that different coping strategies would cause people to have different emotions in the days following Valentine's Day, but participants' predicted emotions would all be similar. This shows that most people do not realize the impact that coping can have on their feelings following an emotional event. He also found that not only did immune neglect create a bias for negative events, but also for positive ones. This shows that people continually make inaccurate forecasts because they do not take into account their ability to cope and overcome emotional events. Hoerger proposed that coping styles and cognitive processes are associated with actual emotional reactions to life events.
</p><p>A variant of immune neglect also proposed by Gilbert and Wilson is the region-beta paradox, where recovery from more intense suffering is faster than recovery from less intense experiences because of the engagement of coping systems. This complicates forecasting, leading to errors. Contrarily, accurate affective forecasting can also promote the region-beta paradox. For example, Cameron and Payne conducted a series of studies in order to investigate the relationship between affective forecasting and the collapse of compassion phenomenon, which refers to the tendency for people's compassion to decrease as the number of people in need of help increases. Participants in their experiments read about either 1 or a group of 8 children from Darfur. These researchers found that people who are skilled at regulating their emotions tended to experience less compassion in response to stories about 8 children from Darfur compared to stories about only 1 child. These participants appeared to collapse their compassion by correctly forecasting their future affective states and proactively avoiding the increased negative emotions resulting from the story. In order to further establish the causal role of proactive emotional regulation in this phenomenon, participants in another study read the same materials and were encouraged to either reduce or experience their emotions. Participants instructed to reduce their emotions reported feeling less upset for 8 children than for 1, presumably because of the increased emotional burden and effort required for the former (an example of the region-beta paradox). These studies suggest that in some cases accurate affective forecasting can actually promote unwanted outcomes such as the collapse of compassion phenomenon by way of the region-beta paradox.
</p>
<h4 data-mw-anchor="Positive_vs_negative_affect">Positive vs negative affect</h4>
<p>Research suggests that the accuracy of affective forecasting for positive and negative emotions is based on the distance in time of the forecast. Finkenauer, Gallucci, van Dijk, and Pollman discovered that people show greater forecasting accuracy for positive than negative affect when the event or trigger being forecast is more distant in time. Contrarily, people exhibit greater affective forecasting accuracy for negative affect when the event/trigger is closer in time. The accuracy of an affective forecast is also related to how well a person predicts the intensity of his or her emotions. In regard to forecasting both positive and negative emotions, Levine, Kaplan, Lench, and Safer have recently shown that people can in fact predict the intensity of their feelings about events with a high degree of accuracy. This finding is contrary to much of the affective forecasting literature currently published, which the authors suggest is due to a procedural artifact in how these studies were conducted.
</p><p>Another important affective forecasting bias is fading affect bias, in which the emotions associated with unpleasant memories fade more quickly than the emotion associated with positive events.
</p>
<h3 data-mw-anchor="Major_sources_of_error_in_cognition">Major sources of error in cognition</h3>
<h4 data-mw-anchor="Focalism">Focalism</h4>

<p>Focalism (or the "focusing illusion") occurs when people focus too much on certain details of an event, ignoring other factors. Research suggests that people have a tendency to exaggerate aspects of life when focusing their attention on it. A well-known example originates from a paper by Kahneman and Schkade, who coined the term "focusing illusion" in 1998. They found that although people tended to believe that someone from the Midwest would be more satisfied if they lived in California, results showed equal levels of life satisfaction in residents of both regions. In this case, concentrating on the easily observed difference in weather bore more weight in predicting satisfaction than other factors. There are many other factors that could have contributed to the desire to move to the Midwest, but the focal point for their decisions was weather. Various studies have attempted to "defocus" participants, meaning instead of focusing on that one factor, they tried to make the participants think of other factors or look at the situation through a different lens. There were mixed results dependent upon the methods used. One successful study asked people to imagine how happy a winner of the lottery and a recently diagnosed HIV patient would be. The researchers were able to reduce the amount of focalism by exposing participants to detailed and mundane descriptions of each person's life, meaning that the more information the participants had on the lottery winner and the HIV patient the less they were able to only focus on few factors, these participants subsequently estimated similar levels of happiness for the HIV patient as well as the lottery-winner. As for the control participants, they made unrealistically disparate predictions of happiness. This could be due to the fact that the more information that is available, the less likely it is one will be able to ignore contributory factors.
</p>
<h4 data-mw-anchor="Time_discounting">Time discounting</h4>

<p>Time discounting (or time preference) is the tendency to weigh present events over future events. Immediate gratification is preferred to delayed gratification, especially over longer periods of time and with younger children or adolescents. For example, a child may prefer one piece of candy now (1 candy/0 seconds=infinity candies/second) instead of five pieces of candy in four months (5 candies/10540800 seconds≈0.00000047candies/second). The bigger the candies/second, the more people like it. This pattern is sometimes referred to as hyperbolic discounting or "present bias" because people's judgements are biased toward present events. Economists often cite time discounting as a source of mispredictions of future utility.
</p>
<h4 data-mw-anchor="Memory">Memory</h4>
<p>Affective forecasters often rely on memories of past events. When people report memories of past events they may leave out important details, change things that occurred, and even add things that have not happened. This suggests the mind constructs memories based on what actually happened, and other factors including the person's knowledge, experiences, and existing schemas.  Using highly available, but unrepresentative memories, increases the impact bias. Baseball fans, for example, tend to use the best game they can remember as the basis for their affective forecast of the game they are about to see. Commuters are similarly likely to base their forecasts of how unpleasant it would feel to miss a train on their memory of the worst time they missed the train  Various studies indicate that retroactive assessments of past experiences are prone to various errors, such as duration neglect or <i>decay bias</i>. People tend to overemphasize the peaks and ends of their experiences when assessing them (peak/end bias), instead of analyzing the event as a whole. For example, in recalling painful experiences, people place greater emphasis on the most discomforting moments as well as the end of the event, as opposed to taking into account the overall duration. Retroactive reports often conflict with present-moment reports of events, further pointing to contradictions between the actual emotions experienced during an event and the memory of them. In addition to producing errors in forecasts about the future, this discrepancy has incited economists to redefine different types of utility and happiness (see the section on economics).
</p><p>Another problem that can arise with affective forecasting is that people tend to remember their past predictions inaccurately. Meyvis, Ratner, and Levav predicted that people forget how they predicted an experience would be beforehand, and thought their predictions were the same as their actual emotions. Because of this, people do not realize that they made a mistake in their predictions, and will then continue to inaccurately forecast similar situations in the future.  Meyvis et al. ran five studies to test whether or not this is true. They found in all of their studies, when people were asked to recall their previous predictions they instead write how they currently feel about the situation. This shows that they do not remember how they thought they would feel, and makes it impossible for them to learn from this event for future experiences.
</p>
<h4 data-mw-anchor="Misconstruals">Misconstruals</h4>
<p>When predicting future emotional states people must first construct a good representation of the event. If people have a lot of experience with the event then they can easily picture the event. When people do not have much experience with the event they need to create a representation of what the event likely contains. For example, if people were asked how they would feel if they lost one hundred dollars in a bet, gamblers are more likely to easily construct an accurate representation of the event. "Construal level theory" theorizes that distant events are conceptualized more abstractly than immediate ones. Thus, psychologists suggest that a lack of concrete details prompts forecasters to rely on more general or idealized representations of events, which subsequently leads to simplistic and inaccurate predictions. For example, when asked to imagine what a 'good day' would be like for them in the near future, people often describe both positive and negative events. When asked to imagine what a 'good day' would be like for them in a year, however, people resort to more uniformly positive descriptions. Gilbert and Wilson call bringing to mind a flawed representation of a forecasted event the <i>misconstrual problem</i>. Framing effects, environmental context, and heuristics (such as schemas) can all affect how a forecaster conceptualizes a future event. For example, the way options are framed affects how they are represented: when asked to forecast future levels of happiness based on pictures of dorms they may be assigned to, college students use physical features of the actual buildings to predict their emotions. In this case, the framing of options highlighted visual aspects of future outcomes, which overshadowed more relevant factors to happiness, such as having a friendly roommate.
</p>
<h4 data-mw-anchor="Projection_bias">Projection bias</h4>
<h5 data-mw-anchor="Overview_2">Overview</h5>
<p>Projection bias is the tendency to falsely project current preferences onto a future event. When people are trying to estimate their emotional state in the future they attempt to give an unbiased estimate. However, people's assessments are contaminated by their current emotional state. Thus, it may be difficult for them to predict their emotional state in the future, an occurrence known as <i>mental contamination</i>. For example, if a college student was currently in a negative mood because he just found out he failed a test, and if the college student forecasted how much he would enjoy a party two weeks later, his current negative mood may influence his forecast. In order to make an accurate forecast the student would need to be aware that his forecast is biased due to mental contamination, be motivated to correct the bias, and be able to correct the bias in the right direction and magnitude.
</p><p>Projection bias can arise from empathy gaps (or hot/cold empathy gaps), which occur when the present and future phases of affective forecasting are characterized by different states of physiological arousal, which the forecaster fails to take into account. For example, forecasters in a state of hunger are likely to overestimate how much they will want to eat later, overlooking the effect of their hunger on future preferences. As with projection bias, economists use the visceral motivations that produce empathy gaps to help explain impulsive or self-destructive behaviors, such as smoking.
</p><p>An important affective forecasting bias related to projection bias is personality neglect. Personality neglect refers to a person's tendency to overlook their personality when making decisions about their future emotions. In a study conducted by Quoidbach and Dunn, students' predictions of their feelings about future exam scores were used to measure affective forecasting errors related to personality. They found that college students who predicted their future emotions about their exam scores were unable to relate these emotions to their own dispositional happiness. To further investigate personality neglect, Quoidbach and Dunn studied happiness in relation to neuroticism. People predicted their future feelings about the outcome of the 2008 US presidential election between Barack Obama and John McCain. Neuroticism was correlated with impact bias, which is the overestimation of the length and intensity of emotions. People who rated themselves as higher in neuroticism overestimated their happiness in response to the election of their preferred candidate, suggesting that they failed to relate their dispositional happiness to their future emotional state.
</p><p>The term "projection bias" was first introduced in the 2003 paper "Projection Bias in Predicting Future Utility" by Loewenstein, O'Donoghue and Rabin.
</p>
<h5 data-mw-anchor="Market_applications_of_projection_bias">Market applications of projection bias</h5>
<p>The novelty of new products oftentimes overexcites consumers and results in the negative consumption externality of impulse buying. To counteract such, George Loewenstein recommends offering "cooling off"  periods for consumers. During such, they would have a few days to reflect on their purchase and appropriately develop a longer-term understanding of the utility they receive from it. This cooling-off period could also benefit the production side by diminishing the need for a salesperson to "hype" certain products. Transparency between consumers and producers would increase as "sellers will have an incentive to put buyers in a long-run average mood rather than an overenthusiastic state". By implementing Loewentstein's recommendation, firms that understand projection bias should minimize information asymmetry; such would diminish the negative consumer externality that comes from purchasing an undesirable good and relieve sellers from extraneous costs required to exaggerate the utility of their product.
</p>
<h5 data-mw-anchor="Life-cycle_consumption">Life-cycle consumption</h5>


<p>Projection bias influences the life cycle of consumption. The immediate utility obtained from consuming particular goods exceeds the utility of future consumption. Consequently, projection bias causes "a person to (plan to) consume too much early in life and too little late in life relative to what would be optimal".  Graph 1 displays decreasing expenditures as a percentage of total income from 20 to 54. The period following where income begins to decline can be explained by retirement. According to Loewenstein's recommendation, a more optimal expenditure and income distribution is displayed in Graph 2. Here, income is left the same as in Graph 1, but expenditures are recalculated by taking the average percentage of expenditures in terms of income from ages 25 to 54 (77.7%) and multiplying such by income to arrive at a theoretical expenditure. The calculation is only applied to this age group because of unpredictable income before 25 and after 54 due to school and retirement.
</p>
<h5 data-mw-anchor="Food_waste">Food waste</h5>
<p>When buying food, people often wrongly project what they will want to eat in the future when they go shopping, which results in food waste.
</p>
<h3 data-mw-anchor="Major_sources_of_error_in_motivation">Major sources of error in motivation</h3>
<h4 data-mw-anchor="Motivated_reasoning">Motivated reasoning</h4>
<p>Generally, affect is a potent source of motivation. People are more likely to pursue experiences and achievements that will bring them more pleasure than less pleasure. In some cases, affective forecasting errors appear to be due to forecasters' strategic use of their forecasts as a means to motivate them to obtain or avoid the forecasted experience. Students, for example, might predict they would be devastated if they failed a test as a way to motivate them to study harder for it. The role of motivated reasoning in affective forecasting has been demonstrated in studies by Morewedge and Buechel (2013). Research participants were more likely to overestimate how happy they would be if they won a prize, or achieved a goal, if they made an affective forecast while they could still influence whether or not they achieved it than if they made an affective forecast after the outcome had been determined (while still in the dark about whether they knew if they won the prize or achieved the goal).
</p>
<h2 data-mw-anchor="In_economics">In economics</h2>
<p>Economists share psychologists' interests in affective forecasting insomuch as it affects the closely related concepts of utility, decision making, and happiness.
</p>
<h3 data-mw-anchor="Utility">Utility</h3>
<p>Research in affective forecasting errors complicates conventional interpretations of utility maximization, which presuppose that to make rational decisions, people must be able to make accurate forecasts about future experiences or utility. Whereas economics formerly focused largely on utility in terms of a person's preferences (decision utility), the realization that forecasts are often inaccurate suggests that measuring preferences at a time of choice may be an incomplete concept of utility. Thus, economists such as Daniel Kahneman, have incorporated differences between affective forecasts and later outcomes into corresponding types of utility. Whereas a current forecast reflects <i>expected</i> or <i>predicted utility</i>, the actual outcome of the event reflects <i>experienced utility</i>. Predicted utility is the "weighted average of all possible outcomes under certain circumstances."  Experienced utility refers to the perceptions of pleasure and pain associated with an outcome. Kahneman and Thaler provide an example of "the hungry shopper," in which case the shopper takes pleasure in the purchase of food due to their current state of hunger. The usefulness of such purchasing is based on their current experience and their anticipated pleasure in fulfilling their hunger.
</p>
<h3 data-mw-anchor="Decision_making">Decision making</h3>
<p>Affective forecasting is an important component of studying human decision making. Research in affective forecasts and economic decision making include investigations of durability bias in consumers and predictions of public transit satisfaction. In relevance to the durability bias in consumers, a study was conducted by Wood and Bettman, that showed that people make decisions regarding the consumption of goods based on the predicted pleasure, and the duration of that pleasure, that the goods will bring them.  Overestimation of such pleasure, and its duration, increases the likelihood that the good will be consumed. Knowledge on such an effect can aid in the formation of marketing strategies of consumer goods. Studies regarding the predictions of public transit satisfaction reveal the same bias. However, with a negative impact on consumption, due to their lack of experience with public transportation, car users predict that they will receive less satisfaction with the use of public transportation than they actually experience. This can lead them to refrain from the use of such services, due to inaccurate forecasting. Broadly, the tendencies people have to make biased forecasts deviate from rational models of decision making. Rational models of decision making presume an absence of bias, in favor of making comparisons based on all relevant and available information. Affective forecasting may cause consumers to rely on the feelings associated with consumption rather than the utility of the good itself. One application of affective forecasting research is in economic policy. The knowledge that forecasts, and therefore, decisions, are affected by biases as well as other factors (such as framing effects), can be used to design policies that maximize the utility of people's choices. This approach is not without its critics, however, as it can also be seen to justify economic paternalism.
</p><p>Prospect theory describes how people make decisions. It differs from expected utility theory in that it takes into account the relativity of how people view utility and incorporates loss aversion, or the tendency to react more strongly to losses rather than gains. Some researchers suggest that loss aversion is in itself an affective forecasting error since people often overestimate the impact of future losses.
</p>
<h3 data-mw-anchor="Happiness_and_well-being">Happiness and well-being</h3>
<p>Economic definitions of happiness are tied to concepts of welfare and utility, and researchers are often interested in how to increase levels of happiness in the population. The economy has a major influence on the aid that is provided through welfare programs because it provides funding for such programs. 
Many welfare programs are focused on providing assistance with the attainment of basic necessities such as food and shelter. This may be due to the fact that happiness and well-being are best derived from personal perceptions of one's ability to provide these necessities. This statement is supported by research that states after basic needs have been met, income has less of an impact on perceptions of happiness. Additionally, the availability of such welfare programs can enable those that are less fortunate to have additional discretionary income. Discretionary income can be dedicated to enjoyable experiences, such as family outings, and in turn, provides an additional dimension to their feelings and experience of happiness. Affective forecasting provides a unique challenge to answering the question regarding the best method for increasing levels of happiness, and economists are split between offering more choices to maximize happiness, versus offering experiences that contain more <i>objective </i>or <i>experienced utility</i>. Experienced utility refers to how useful an experience is in its contribution to feelings of happiness and well-being.  Experienced utility can refer to both material purchases and experiential purchases. Studies show that experiential purchases, such as a bag of chips, result in forecasts of higher levels of happiness than material purchases, such as the purchase of a pen. This prediction of happiness as a result of a purchase experience exemplifies affective forecasting. It is possible that an increase in choices, or means, of achieving desired levels of happiness will be predictive of increased levels of happiness. For example, if one is happy with their ability to provide themselves with both a choice of necessities and a choice of enjoyable experiences they are more likely to predict that they will be happier than if they were forced to choose between one or the other. Also, when people are able to reference multiple experiences that contribute to their feelings of happiness, more opportunities for comparison will lead to a forecast of more happiness. Under these circumstances, both the number of choices and the quantity of experienced utility have the same effect on affective forecasting, which makes it difficult to choose a side of the debate on which method is most effective in maximizing happiness.
</p><p>Applying findings from affective forecasting research to happiness also raises methodological issues: should happiness measure the outcome of an experience or the satisfaction experienced as a result of the choice made based upon a forecast? For example, although professors may forecast that getting tenure would significantly increase their happiness, research suggests that in reality, happiness levels between professors who are or are not awarded tenure are insignificant. In this case happiness is measured in terms of the outcome of an experience.  Affective forecasting conflicts such as this one have also influenced theories of hedonic adaptation, which compares happiness to a treadmill, in that it remains relatively stable despite forecasts.
</p>
<h2 data-mw-anchor="In_law">In law</h2>
<p>Similar to how some economists have drawn attention to how affective forecasting violates assumptions of rationality, legal theorists point out that inaccuracies in, and applications of, these forecasts have implications in law that have remained overlooked. The application of affective forecasting, and its related research, to legal theory reflects a wider effort to address how emotions affect the legal system. In addition to influencing legal discourse on emotions, and welfare, Jeremy Blumenthal cites additional implications of affective forecasting in tort damages, capital sentencing and sexual harassment.
</p>
<h3 data-mw-anchor="Tort_damages">Tort damages</h3>
<p>Jury awards for tort damages are based on compensating victims for pain, suffering, and loss of quality of life. However, findings in affective forecasting errors have prompted some to suggest that juries are overcompensating victims since their forecasts overestimate the negative impact of damages on the victims' lives. Some scholars suggest implementing jury education to attenuate potentially inaccurate predictions, drawing upon research that investigates how to decrease inaccurate affective forecasts.
</p>
<h3 data-mw-anchor="Capital_sentencing">Capital sentencing</h3>
<p>During the process of capital sentencing, juries are allowed to hear victim impact statements (VIS) from the victim's family. This demonstrates affective forecasting in that its purpose is to present how the victim's family has been impacted emotionally and, or, how they expect to be impacted in the future. These statements can cause juries to overestimate the emotional harm, causing harsh sentencing, or underestimate harm, resulting in inadequate sentencing. The time frame in which these statements are present also influences affective forecasting. By increasing the time gap between the crime itself and sentencing (the time at which victim impact statements are given), forecasts are more likely to be influenced by the error of immune neglect (See Immune neglect) Immune neglect is likely to lead to underestimation of future emotional harm, and therefore results in inadequate sentencing. As with tort damages, jury education is a proposed method for alleviating the negative effects of forecasting error.
</p>
<h3 data-mw-anchor="Sexual_harassment">Sexual harassment</h3>
<p>In cases involving sexual harassment, judgements are more likely to blame the victim for their failure to react in a timely fashion or their failure to make use of services that were available to them in the event of sexual harassment. This is because prior to the actual experience of harassment, people tend to overestimate their affective reactions as well as their proactive reactions in response to sexual harassment. This exemplifies the focalism error (See Focalism) in which forecasters ignore alternative factors that may influence one's reaction, or failure to react. For example, in their study, Woodzicka and LaFrance studied women's predictions of how they would react to sexual harassment during an interview. Forecasters overestimated their affective reactions of anger, while underestimating the level of fear they would experience. They also overestimated their proactive reactions. In Study 1, participants reported that they would refuse to answer questions of a sexual nature and, or, report the question to the interviewer's supervisor. However, in Study 2, of those who had actually experienced sexual harassment during an interview, none of them displayed either proactive reaction. If juries are able to recognize such errors in forecasting, they may be able to adjust such errors. Additionally, if juries are educated on other factors that may influence the reactions of those who are victims of sexual harassment, such as intimidation, they are more likely to make more accurate forecasts, and less likely to blame victims for their own victimization.
</p>
<h2 data-mw-anchor="In_health">In health</h2>
<p>Affective forecasting has implications in health decision making and medical ethics and policy. Research in health-related affective forecasting suggests that nonpatients consistently underestimate the quality of life associated with chronic health conditions and disability. The so-called "disability paradox" states the discrepancy between self-reported levels of happiness amongst chronically ill people versus the predictions of their happiness levels by healthy people. The implications of this forecasting error in medical decision making can be severe, because judgments about future quality of life often inform health decisions. Inaccurate forecasts can lead patients, or more commonly their health care agent, to refuse life-saving treatment in cases when the treatment would involve a drastic change in lifestyle, for example, the amputation of a leg. A patient, or health care agent, who falls victim to focalism would fail to take into account all the aspects of life that would remain the same after losing a limb. Although Halpern and Arnold suggest interventions to foster awareness of forecasting errors and improve medical decision making amongst patients, the lack of direct research in the impact of biases in medical decisions provides a significant challenge.
</p><p>Research also indicates that affective forecasts about future quality of life are influenced by the forecaster's current state of health. Whereas healthy individuals associate future low health with low quality of life, less healthy individuals do not forecast necessarily low quality of life when imagining having poorer health. Thus, patient forecasts and preferences about their own quality of life may conflict with public notions. Because a primary goal of healthcare is maximizing quality of life, knowledge about patients' forecasts can potentially inform policy on how resources are allocated.
</p><p>Some doctors suggest that research findings in affective forecasting errors merit medical paternalism. Others argue that although biases exist and should support changes in doctor-patient communication, they do not unilaterally diminish decision-making capacity and should not be used to endorse paternalistic policies. This debate captures the tension between medicine's emphasis on protecting the autonomy of the patient and an approach that favors intervention in order to correct biases.
</p>
<h2 data-mw-anchor="Improving_forecasts">Improving forecasts</h2>
<p>Individuals who recently have experienced an emotionally charged life event will display the impact bias. The individual predicts they will feel happier than they actually feel about the event. Another factor that influences overestimation is focalism which causes individuals to concentrate on the current event. Individuals often fail to realize that other events will also influence how they currently feel.  Lam et al. (2005) found that the perspective that individuals take influences their susceptibility to biases when making predictions about their feelings.
</p><p>A perspective that overrides impact bias is mindfulness. Mindfulness is a skill that individuals can learn to help them prevent overestimating their feelings. Being mindful helps the individual understand that they may currently feel negative emotions, but the feelings are not permanent. The Five Factor Mindfulness Questionnaire (FFMQ) can be used to measure an individual's mindfulness. The five factors of mindfulness are observing, describing, acting with awareness, non-judging of inner experience, and non-reactivity to inner experience. The two most important factors for improving forecasts are observing and acting with awareness.  The observing factor assesses how often an individual attends to their sensations, emotions, and outside environment. The ability to observe allows the individual to avoid focusing on one single event, and be aware that other experiences will influence their current emotions. Acting with awareness requires assessing how individuals tend to current activities with careful consideration and concentration. Emanuel, Updegraff, Kalmbach, and Ciesla (2010) stated that the ability to act with awareness reduces the impact bias because the individual is more aware that other events co-occur with the present event. Being able to observe the current event can help individuals focus on pursuing future events that provide long-term satisfaction and fulfillment.
</p>
<h2 data-mw-anchor="See_also">See also</h2>

<h2 data-mw-anchor="References">References</h2>

<h2 data-mw-anchor="Further_reading">Further reading</h2>
<ul><li><cite id="CITEREFFiske2004" class="citation book cs1">Fiske, Susan T. (2004). <i>Social Beings: A Core Motives Approach to Social Psychology</i>. Wiley. ISBN <bdi>978-0-471-45151-8</bdi>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Social+Beings%3A+A+Core+Motives+Approach+to+Social+Psychology&amp;rft.pub=Wiley&amp;rft.date=2004&amp;rft.isbn=978-0-471-45151-8&amp;rft.aulast=Fiske&amp;rft.aufirst=Susan+T.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAffective+forecasting"></span></li>
<li><cite id="CITEREFGilbert2006" class="citation book cs1">Gilbert, Daniel T. (2006). <span title="Free registration required"><i>Stumbling on happiness</i></span>. Alfred A. Knopf. ISBN <bdi>978-1-4000-7742-7</bdi>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Stumbling+on+happiness&amp;rft.pub=Alfred+A.+Knopf&amp;rft.date=2006&amp;rft.isbn=978-1-4000-7742-7&amp;rft.aulast=Gilbert&amp;rft.aufirst=Daniel+T.&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fstumblingonhappi00gilb&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAffective+forecasting"></span></li>
<li><cite id="CITEREFSannaSchwarz2004" class="citation journal cs1">Sanna, Lawrence J.; Schwarz, Norbert (2004). "Integrating Temporal Biases: The Interplay of Focal Thoughts and Accessibility Experiences". <i>Psychological Science</i>. <b>15</b> (7): <span>474–</span>481. doi:10.1111/j.0956-7976.2004.00704.x. PMID 15200632. S2CID 10998751.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Psychological+Science&amp;rft.atitle=Integrating+Temporal+Biases%3A+The+Interplay+of+Focal+Thoughts+and+Accessibility+Experiences&amp;rft.volume=15&amp;rft.issue=7&amp;rft.pages=474-481&amp;rft.date=2004&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A10998751%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F15200632&amp;rft_id=info%3Adoi%2F10.1111%2Fj.0956-7976.2004.00704.x&amp;rft.aulast=Sanna&amp;rft.aufirst=Lawrence+J.&amp;rft.au=Schwarz%2C+Norbert&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAffective+forecasting"></span></li>
<li><cite id="CITEREFWilson2002" class="citation book cs1">Wilson, Timothy D. (2002). <span title="Free registration required"><i>Strangers to Ourselves: Discovering the Adaptive Unconscious</i></span>. Belknap Press of Harvard University Press. ISBN <bdi>978-0-674-01382-7</bdi>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Strangers+to+Ourselves%3A+Discovering+the+Adaptive+Unconscious&amp;rft.pub=Belknap+Press+of+Harvard+University+Press&amp;rft.date=2002&amp;rft.isbn=978-0-674-01382-7&amp;rft.aulast=Wilson&amp;rft.aufirst=Timothy+D.&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fstrangerstoo_wils_2002_000_10736667&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAffective+forecasting"></span></li>
<li><cite id="CITEREFHseeHastie2006" class="citation journal cs1">Hsee, Christopher K.; Hastie, Reid (2006). "Decision and experience: why don't we choose what makes us happy?". <i>Trends in Cognitive Sciences</i>. <b>10</b> (1): <span>31–</span>37. CiteSeerX <span title="Freely accessible">10.1.1.178.7054</span>. doi:10.1016/j.tics.2005.11.007. PMID 16318925. S2CID 12262319.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Trends+in+Cognitive+Sciences&amp;rft.atitle=Decision+and+experience%3A+why+don%27t+we+choose+what+makes+us+happy%3F&amp;rft.volume=10&amp;rft.issue=1&amp;rft.pages=31-37&amp;rft.date=2006&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.178.7054%23id-name%3DCiteSeerX&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A12262319%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F16318925&amp;rft_id=info%3Adoi%2F10.1016%2Fj.tics.2005.11.007&amp;rft.aulast=Hsee&amp;rft.aufirst=Christopher+K.&amp;rft.au=Hastie%2C+Reid&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAffective+forecasting"></span></li></ul>
<dl><dt>On the projection bias</dt></dl>
<ul><li><cite id="CITEREFConlinO'DonoghueVogelsang2007" class="citation journal cs1">Conlin, Michael; O'Donoghue, Ted; Vogelsang, Timothy J. (2007). "Projection Bias in Catalog Orders". <i>The American Economic Review</i>. <b>97</b> (4): <span>1217–</span>1249. CiteSeerX <span title="Freely accessible">10.1.1.333.7742</span>. doi:10.1257/aer.97.4.1217. JSTOR 30034090.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+American+Economic+Review&amp;rft.atitle=Projection+Bias+in+Catalog+Orders&amp;rft.volume=97&amp;rft.issue=4&amp;rft.pages=1217-1249&amp;rft.date=2007&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.333.7742%23id-name%3DCiteSeerX&amp;rft_id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F30034090%23id-name%3DJSTOR&amp;rft_id=info%3Adoi%2F10.1257%2Faer.97.4.1217&amp;rft.aulast=Conlin&amp;rft.aufirst=Michael&amp;rft.au=O%27Donoghue%2C+Ted&amp;rft.au=Vogelsang%2C+Timothy+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAffective+forecasting"></span></li>
<li><cite id="CITEREFSimonsohn2010" class="citation journal cs1">Simonsohn, Uri (2010). "Weather To Go To College". <i>The Economic Journal</i>. <b>120</b> (543): <span>270–</span>280. CiteSeerX <span title="Freely accessible">10.1.1.179.1288</span>. doi:10.1111/j.1468-0297.2009.02296.x. S2CID 154699464.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Economic+Journal&amp;rft.atitle=Weather+To+Go+To+College&amp;rft.volume=120&amp;rft.issue=543&amp;rft.pages=270-280&amp;rft.date=2010&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.179.1288%23id-name%3DCiteSeerX&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A154699464%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1468-0297.2009.02296.x&amp;rft.aulast=Simonsohn&amp;rft.aufirst=Uri&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAffective+forecasting"></span></li></ul>
<h2 data-mw-anchor="External_links">External links</h2>
<ul><li>Daniel Gilbert "Why are we happy?" (video lecture), TED.com, Retrieved 2009-08-29</li>
<li>Psychlopedia on Affective Forecasting</li>
<li>Daniel Gilbert, video interview</li>
<li>Affective forecasting on Psychology Today</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Affective_forecasting#Projection_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Restraint bias</h2>
<a href='https://en.wikipedia.org/wiki/Restraint_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Restraint bias</b> is the tendency for people to overestimate their ability to control impulsive behavior. An inflated self-control belief may lead to greater exposure to temptation, and increased impulsiveness. Therefore, the restraint bias has bearing on addiction. For example, someone might use drugs, simply because they believe they can resist any potential addiction.
An individual's inability to control, or their temptation can come from several different  visceral impulses. Visceral impulses can include hunger, sexual arousal, and fatigue. These impulses provide information about the current state and behavior needed to keep the body satisfied.
</p><p><b>Empathy Gap Effect:</b>
The Empathy Gap Effect deals with individuals having trouble appreciating the power that the impulse states have on their behavior. There is a cold-to-hot empathy gap that states when people are in a cold state, like not experiencing hunger, they tended to underestimate those influences in a hot state. The underestimation of the visceral impulses can be contributed to restricted memory for the visceral experience which means the individual can recall the impulsive state but cannot recreate the sensation of the impulsive state.
</p><p><b>Impulse Control and Attention:</b>
Studies have concluded that when people believe that they have stronger sense of self-control over situations in their environment, they have greater impulse control. Individuals also tend to overestimate their capacity for self-control when one is told that they have a high capacity for self-restraint. The more someone is told that they have a high capacity for self-restraint, the more they believe it and display higher levels of impulse control. Attention has a lot to do with biases, self and impulse controls in our environment. The less attention an individual pays to something, the less control they have over whatever they are doing. Focusing attention to oneself can lead to successful self-control which can be helpful in many aspects of life. Self-control engages conflict between competing pressures, pressures that can be brought on by situational or internal prompts from the environment. Some of the cues make the individual act on or engage in that behavior or act to prevent the individual from taking action.
</p>
</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Restraint_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Self–consistency bias</h2>
<a href='https://en.wikipedia.org/wiki/List_of_cognitive_biases#Consistency_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>

<p>Cognitive biases are systematic patterns of deviation from norm and/or rationality in judgment.  They are often studied in psychology, sociology and behavioral economics.
</p><p>Although the reality of most of these biases is confirmed by reproducible research, there are often controversies about how to classify these biases or how to explain them. Several theoretical causes are known for some cognitive biases, which provides a classification of biases by their common generative mechanism (such as noisy information-processing). Gerd Gigerenzer has criticized the framing of cognitive biases as errors in judgment, and favors interpreting them as arising from rational deviations from logical thought.
</p><p>Explanations include information-processing rules (i.e., mental shortcuts), called <i>heuristics</i>, that the brain uses to produce decisions or judgments. Biases have a variety of forms and appear as cognitive ("cold") bias, such as mental noise, or motivational ("hot") bias, such as when beliefs are distorted by wishful thinking. Both effects can be present at the same time.
</p><p>There are also controversies over some of these biases as to whether they count as useless or irrational, or whether they result in useful attitudes or behavior. For example, when getting to know others, people tend to ask leading questions which seem biased towards confirming their assumptions about the person. However, this kind of confirmation bias has also been argued to be an example of social skill; a way to establish a connection with the other person.
</p><p>Although this research overwhelmingly involves human subjects, some studies have found bias in non-human animals as well. For example, loss aversion has been shown in monkeys and hyperbolic discounting has been observed in rats, pigeons, and monkeys.
</p>

<h2 data-mw-anchor="Belief,_decision-making_and_behavioral" data-mw-fallback-anchor="Belief.2C_decision-making_and_behavioral">Belief, decision-making and behavioral</h2>
<p>These biases affect belief formation, reasoning processes, business and economic decisions, and human behavior in general.
</p>
<h3 data-mw-anchor="Anchoring_bias">Anchoring bias</h3>

<p>The anchoring bias, or focalism, is the tendency to rely too heavily—to "anchor"—on one trait or piece of information when making decisions (usually the first piece of information acquired on that subject).
Anchoring bias includes or involves the following:
</p>
<ul><li>Common source bias, the tendency to combine or compare research studies from the same source, or from sources that use the same methodologies or data.</li>
<li>Conservatism bias, the tendency to insufficiently revise one's belief when presented with new evidence.</li>
<li>Functional fixedness, a tendency limiting a person to using an object only in the way it is traditionally used.</li>
<li>Law of the instrument, an over-reliance on a familiar tool or methods, ignoring or under-valuing alternative approaches. "If all you have is a hammer, everything looks like a nail."</li></ul>
<h3 data-mw-anchor="Apophenia">Apophenia</h3>

<p>The tendency to perceive meaningful connections between unrelated things.
The following are types of apophenia:
</p>
<ul><li>Clustering illusion, the tendency to overestimate the importance of small runs, streaks, or clusters in large samples of random data (that is, seeing phantom patterns).</li>
<li>Illusory correlation, a tendency to inaccurately perceive a relationship between two unrelated events.</li>
<li>Pareidolia, a tendency to perceive a vague and random stimulus (often an image or sound) as significant, e.g., seeing images of animals or faces in clouds, the man in the Moon, and hearing non-existent hidden messages on records played in reverse.</li></ul>
<h3 data-mw-anchor="Availability_heuristic">Availability heuristic</h3>

<p>The availability heuristic (also known as the availability bias) is the tendency to overestimate the likelihood of events with greater "availability" in memory, which can be influenced by how recent the memories are or how unusual or emotionally charged they may be. The availability heuristic includes or involves the following:
</p>
<ul><li>Anthropocentric thinking, the tendency to use human analogies as a basis for reasoning about other, less familiar, biological phenomena.</li>
<li>Anthropomorphism is characterization of animals, objects, and abstract concepts as possessing human traits, emotions, or intentions. The opposite bias, of not attributing feelings or thoughts to another person, is dehumanised perception, a type of objectification.</li>
<li>Attentional bias, the tendency of perception to be affected by recurring thoughts.</li>
<li>Frequency illusion or Baader–Meinhof phenomenon. The frequency illusion is that once something has been noticed then every instance of that thing is noticed, leading to the belief it has a high frequency of occurrence (a form of selection bias). The Baader–Meinhof phenomenon is the illusion where something that has recently come to one's attention suddenly seems to appear with improbable frequency shortly afterwards. It was named after an incidence of frequency illusion in which the Baader–Meinhof Group was mentioned.</li>
<li>Implicit association, where the speed with which people can match words depends on how closely they are associated.</li>
<li>Salience bias, the tendency to focus on items that are more prominent or emotionally striking and ignore those that are unremarkable, even though this difference is often irrelevant by objective standards. See also von Restorff effect.</li>
<li>Selection bias, which happens when the members of a statistical sample are not chosen completely at random, which leads to the sample not being representative of the population.</li>
<li>Survivorship bias, which is concentrating on the people or things that "survived" some process and inadvertently overlooking those that did not because of their lack of visibility.</li>
<li>Quantification bias, the tendency to ascribe more weight to measured/quantified metrics than to unquantifiable values. See also: McNamara fallacy.</li>
<li>Well travelled road effect, the tendency to underestimate the duration taken to traverse oft-travelled routes and overestimate the duration taken to traverse less familiar routes.</li></ul>
<h3 data-mw-anchor="Cognitive_dissonance">Cognitive dissonance</h3>

<p>Cognitive dissonance is the perception of contradictory information and the mental toll of it.
</p>
<ul><li>Normalcy bias, a form of cognitive dissonance, is the refusal to plan for, or react to, a disaster which has never happened before.</li>
<li>Effort justification is a person's tendency to attribute greater value to an outcome if they had to put effort into achieving it. This can result in more value being applied to an outcome than it actually has. An example of this is the IKEA effect, the tendency for people to place a disproportionately high value on objects that they partially assembled themselves, such as furniture from IKEA, regardless of the quality of the end product.</li>
<li>Ben Franklin effect, where a person who has performed a favor for someone is more likely to do another favor for that person than they would be if they had <i>received</i> a favor from that person.</li></ul>
<h3 data-mw-anchor="Confirmation_bias">Confirmation bias</h3>

<p>Confirmation bias is the tendency to search for, interpret, focus on and remember information in a way that confirms one's preconceptions. There are multiple other cognitive biases which involve or are types of confirmation bias:
</p>
<ul><li>Backfire effect, a tendency to react to disconfirming evidence by strengthening one's previous beliefs.</li>
<li>Congruence bias, the tendency to test hypotheses exclusively through direct testing, instead of testing possible alternative hypotheses.</li>
<li>Experimenter's or expectation bias, the tendency for experimenters to believe, certify, and publish data that agree with their expectations for the outcome of an experiment, and to disbelieve, discard, or downgrade the corresponding weightings for data that appear to conflict with those expectations.</li>
<li>Observer-expectancy effect, when a researcher expects a given result and therefore unconsciously manipulates an experiment or misinterprets data in order to find it (see also subject-expectancy effect).</li>
<li>Selective perception, the tendency for expectations to affect perception.</li>
<li>Semmelweis reflex, the tendency to reject new evidence that contradicts a paradigm.</li></ul>
<h3 data-mw-anchor="Egocentric_bias">Egocentric bias</h3>

<p>Egocentric bias is the tendency to rely too heavily on one's own perspective and/or have a different perception of oneself relative to others. The following are forms of egocentric bias:
</p>
<ul><li>Bias blind spot, the tendency to see oneself as less biased than other people, or to be able to identify more cognitive biases in others than in oneself.</li>
<li>False consensus effect, the tendency for people to overestimate the degree to which others agree with them.</li>
<li>False uniqueness bias, the tendency of people to see their projects and themselves as more singular than they actually are.</li>
<li>Forer effect or Barnum effect, the tendency for individuals to give high accuracy ratings to descriptions of their personality that supposedly are tailored specifically for them, but are in fact vague and general enough to apply to a wide range of people. This effect can provide a partial explanation for the widespread acceptance of some beliefs and practices, such as astrology, fortune telling, graphology, and some types of personality tests.</li>
<li>Illusion of asymmetric insight, where people perceive their knowledge of their peers to surpass their peers' knowledge of them.</li>
<li>Illusion of control, the tendency to overestimate one's degree of influence over other external events.</li>
<li>Illusion of transparency, the tendency for people to overestimate the degree to which their personal mental state is known by others, and to overestimate how well they understand others' personal mental states.</li>
<li>Illusion of validity, the tendency to overestimate the accuracy of one's judgments, especially when available information is consistent or inter-correlated.</li>
<li>Illusory superiority, the tendency to overestimate one's desirable qualities, and underestimate undesirable qualities, relative to other people. (Also known as "Lake Wobegon effect", "better-than-average effect", or "superiority bias".)</li>
<li>Naïve cynicism, expecting more egocentric bias in others than in oneself.</li>
<li>Naïve realism, the belief that we see reality as it really is—objectively and without bias; that the facts are plain for all to see; that rational people will agree with us; and that those who do not are either uninformed, lazy, irrational, or biased.</li>
<li>Overconfidence effect, a tendency to have excessive confidence in one's own answers to questions. For example, for certain types of questions, answers that people rate as "99% certain" turn out to be wrong 40% of the time.</li>
<li>Planning fallacy, the tendency for people to underestimate the time it will take them to complete a given task.</li>
<li>Restraint bias, the tendency to overestimate one's ability to show restraint in the face of temptation.</li>
<li>Trait ascription bias, the tendency for people to view themselves as relatively variable in terms of personality, behavior, and mood while viewing others as much more predictable.</li>
<li>Third-person effect, a tendency to believe that mass-communicated media messages have a greater effect on others than on themselves.</li></ul>
<h3 data-mw-anchor="Extension_neglect">Extension neglect</h3>

<p>Extension neglect occurs where the quantity of the sample size is not sufficiently taken into consideration when assessing the outcome, relevance or judgement. The following are forms of extension neglect:
</p>
<ul><li>Base rate fallacy or base rate neglect, the tendency to ignore general information and focus on information only pertaining to the specific case, even when the general information is more important.</li>
<li>Compassion fade, the tendency to behave more compassionately towards a small number of identifiable victims than to a large number of anonymous ones.</li>
<li>Conjunction fallacy, the tendency to assume that specific conditions are more probable than a more general version of those same conditions.</li>
<li>Duration neglect, the neglect of the duration of an episode in determining its value.</li>
<li>Hyperbolic discounting, where discounting is the tendency for people to have a stronger preference for more immediate payoffs relative to later payoffs. Hyperbolic discounting leads to choices that are inconsistent over time—people make choices today that their future selves would prefer not to have made, despite using the same reasoning. Also known as current moment bias or present bias, and related to Dynamic inconsistency. A good example of this is a study showed that when making food choices for the coming week, 74% of participants chose fruit, whereas when the food choice was for the current day, 70% chose chocolate.</li>
<li>Insensitivity to sample size, the tendency to under-expect variation in small samples.</li>
<li>Less-is-better effect, the tendency to prefer a smaller set to a larger set judged separately, but not jointly.</li>
<li>Neglect of probability, the tendency to completely disregard probability when making a decision under uncertainty.</li>
<li>Scope neglect or scope insensitivity, the tendency to be insensitive to the size of a problem when evaluating it. For example, being willing to pay as much to save 2,000 children or 20,000 children.</li>
<li>Zero-risk bias, the preference for reducing a small risk to zero over a greater reduction in a larger risk.</li></ul>
<h3 data-mw-anchor="False_priors">False priors</h3>

<p>False priors are initial beliefs and knowledge which interfere with the unbiased evaluation of factual evidence and lead to incorrect conclusions. Biases based on false priors include:
</p>
<ul><li>Agent detection bias, the inclination to presume the purposeful intervention of a sentient or intelligent agent.</li>
<li>Automation bias, the tendency to depend excessively on automated systems which can lead to erroneous automated information overriding correct decisions.</li>
<li>Gender bias, a widespread set of implicit biases that discriminate against a gender. For example, the assumption that women are less suited to jobs requiring high intellectual ability. Or the assumption that people or animals are male in the absence of any indicators of gender.</li>
<li>Sexual overperception bias, the tendency to overestimate sexual interest of another person in oneself, and sexual underperception bias, the tendency to underestimate it.</li>
<li>Stereotyping, expecting a member of a group to have certain characteristics without having actual information about that individual.</li></ul>
<h3 data-mw-anchor="Framing_effect">Framing effect</h3>

<p>The framing effect is the tendency to draw different conclusions from the same information, depending on how that information is presented. Forms of the framing effect include:
</p>
<ul><li>Contrast effect, the enhancement or reduction of a certain stimulus's perception when compared with a recently observed, contrasting object.</li>
<li>Decoy effect, where preferences for either option A or B change in favor of option B when option C is presented, which is completely dominated by option B (inferior in all respects) and partially dominated by option A.</li>
<li>Default effect, the tendency to favor the default option when given a choice between several options.</li>
<li>Denomination effect, the tendency to spend more money when it is denominated in small amounts (e.g., coins) rather than large amounts (e.g., bills).</li>
<li>Distinction bias, the tendency to view two options as more dissimilar when evaluating them simultaneously than when evaluating them separately.</li>
<li>Domain neglect bias, the tendency to neglect relevant domain knowledge while solving interdisciplinary problems.</li>
<li>Context neglect bias, the tendency to neglect the human context of technological challenges.</li></ul>
<h3 data-mw-anchor="Logical_fallacy">Logical fallacy</h3>

<ul><li>Berkson's paradox, the tendency to misinterpret statistical experiments involving conditional probabilities.</li>
<li>Escalation of commitment, irrational escalation, or sunk cost fallacy, where people justify increased investment in a decision, based on the cumulative prior investment, despite new evidence suggesting that the decision was probably wrong.</li>
<li>G. I. Joe fallacy, the tendency to think that knowing about cognitive bias is enough to overcome it.</li>
<li>Gambler's fallacy, the tendency to think that future probabilities are altered by past events, when in reality they are unchanged. The fallacy arises from an erroneous conceptualization of the law of large numbers. For example, "I've flipped heads with this coin five times consecutively, so the chance of tails coming out on the sixth flip is much greater than heads."</li>
<li>Hot-hand fallacy (also known as "hot hand phenomenon" or "hot hand"), the belief that a person who has experienced success with a random event has a greater chance of further success in additional attempts.</li>
<li>Plan continuation bias, failure to recognize that the original plan of action is no longer appropriate for a changing situation or for a situation that is different from anticipated.</li>
<li>Subadditivity effect, the tendency to judge the probability of the whole to be less than the probabilities of the parts.</li>
<li>Time-saving bias, a tendency to underestimate the time that could be saved (or lost) when increasing (or decreasing) from a relatively low speed, and to overestimate the time that could be saved (or lost) when increasing (or decreasing) from a relatively high speed.</li>
<li>Zero-sum bias, where a situation is incorrectly perceived to be like a zero-sum game (i.e., to be a situation whereby one person gains at the expense of another).</li></ul>
<h3 data-mw-anchor="Prospect_theory">Prospect theory</h3>


<p>The following relate to prospect theory:
</p>
<ul><li>Ambiguity effect, the tendency to avoid options for which the probability of a favorable outcome is unknown.</li>
<li>Disposition effect, the tendency to sell an asset that has accumulated in value and resist selling an asset that has declined in value.</li>
<li>Dread aversion, just as losses yield double the emotional impact of gains, dread yields double the emotional impact of savouring.</li>
<li>Endowment effect, the tendency for people to demand much more to give up an object than they would be willing to pay to acquire it.</li>
<li>Loss aversion, where the perceived disutility of giving up an object is greater than the utility associated with acquiring it. (see also Sunk cost fallacy)</li>
<li>Pseudocertainty effect, the tendency to make risk-averse choices if the expected outcome is positive, but make risk-seeking choices to avoid negative outcomes.</li>
<li>Status quo bias, the tendency to prefer things to stay relatively the same.</li>
<li>System justification, the tendency to defend and bolster the status quo. Existing social, economic, and political arrangements tend to be preferred, and alternatives disparaged, sometimes even at the expense of individual and collective self-interest.</li></ul>
<h3 data-mw-anchor="Self-assessment">Self-assessment</h3>
<ul><li>Dunning–Kruger effect, the tendency for unskilled individuals to overestimate their own ability and the tendency for experts to underestimate their own ability.</li>
<li>Hot-cold empathy gap, the tendency to underestimate the influence of visceral drives on one's attitudes, preferences, and behaviors.</li>
<li>Hard–easy effect, the tendency to overestimate one's ability to accomplish hard tasks, and underestimate one's ability to accomplish easy tasks.</li>
<li>Illusion of explanatory depth, the tendency to believe that one understands a topic much better than one actually does. The effect is strongest for explanatory knowledge, whereas people tend to be better at self-assessments for procedural, narrative, or factual knowledge.</li>
<li>Impostor Syndrome, a psychological occurrence in which an individual doubts their skills, talents, or accomplishments and has a persistent internalized fear of being exposed as a fraud.  Also known as impostor phenomenon.</li>
<li>Objectivity illusion, the phenomena where people tend to believe that they are more objective and unbiased than others. This bias can apply to itself – where people are able to see when others are affected by the objectivity illusion, but unable to see it in themselves. See also <i>bias blind spot.</i></li></ul>
<h3 data-mw-anchor="Truth_judgment">Truth judgment</h3>
<ul><li>Belief bias, an effect where someone's evaluation of the logical strength of an argument is biased by the believability of the conclusion.</li>
<li>Illusory truth effect, the tendency to believe that a statement is true if it is easier to process, or if it has been stated multiple times, regardless of its actual veracity. These are specific cases of truthiness.</li>
<li>Rhyme as reason effect, where rhyming statements are perceived as more truthful.</li>
<li>Subjective validation, where statements are perceived as true if a subject's belief demands it to be true. Also assigns perceived connections between coincidences. (Compare confirmation bias.)</li></ul>
<h3 data-mw-anchor="Other">Other</h3>

<h3 data-mw-anchor="Social">Social</h3>
<h4 data-mw-anchor="Association_fallacy">Association fallacy</h4>

<p>Association fallacies include:
</p>
<ul><li>Authority bias, the tendency to attribute greater accuracy to the opinion of an authority figure (unrelated to its content) and be more influenced by that opinion.</li>
<li>Cheerleader effect, the tendency for people to appear more attractive in a group than in isolation.</li>
<li>Halo effect, the tendency for a person's positive or negative traits to "spill over" from one personality area to another in others' perceptions of them (see also physical attractiveness stereotype).</li></ul>
<h4 data-mw-anchor="Attribution_bias">Attribution bias</h4>

<p>Attribution bias includes:
</p>
<ul><li>Actor-observer bias, the tendency for explanations of other individuals' behaviors to overemphasize the influence of their personality and underemphasize the influence of their situation (see also Fundamental attribution error), and for explanations of one's own behaviors to do the opposite (that is, to overemphasize the influence of our situation and underemphasize the influence of our own personality).</li>
<li>Defensive attribution hypothesis, a tendency to attribute more blame to a harm-doer as the outcome becomes more severe or as personal or situational similarity to the victim decreases.</li>
<li>Extrinsic incentives bias, an exception to the <i>fundamental attribution error</i>, where people view others as having (situational) extrinsic motivations and (dispositional) intrinsic motivations for oneself</li>
<li>Fundamental attribution error, the tendency for people to overemphasize personality-based explanations for behaviors observed in others while under-emphasizing the role and power of situational influences on the same behavior (see also actor-observer bias, group attribution error, positivity effect, and negativity effect).</li>
<li>Group attribution error, the biased belief that the characteristics of an individual group member are reflective of the group as a whole or the tendency to assume that group decision outcomes reflect the preferences of group members, even when information is available that clearly suggests otherwise.</li>
<li>Hostile attribution bias, the tendency to interpret others' behaviors as having hostile intent, even when the behavior is ambiguous or benign.</li>
<li>Intentionality bias, the tendency to judge human action to be intentional rather than accidental.</li>
<li>Just-world fallacy, the tendency for people to want to believe that the world is fundamentally just, causing them to rationalize an otherwise inexplicable injustice as deserved by the victim(s).</li>
<li>Moral luck, the tendency for people to ascribe greater or lesser moral standing based on the outcome of an event.</li>
<li>Puritanical bias, the tendency to attribute cause of an undesirable outcome or wrongdoing by an individual to a moral deficiency or lack of self-control rather than taking into account the impact of broader societal determinants .</li>
<li>Self-serving bias, the tendency to claim more responsibility for successes than failures. It may also manifest itself as a tendency for people to evaluate ambiguous information in a way beneficial to their interests (see also group-serving bias).</li>
<li>Ultimate attribution error, similar to the fundamental attribution error, in this error a person is likely to make an internal attribution to an entire group instead of the individuals within the group.</li></ul>
<h4 data-mw-anchor="Conformity">Conformity</h4>

<p>Conformity is involved in the following:
</p>
<ul><li>Availability cascade, a self-reinforcing process in which a collective belief gains more and more plausibility through its increasing repetition in public discourse (or "repeat something long enough and it will become true"). See also availability heuristic.</li>
<li>Bandwagon effect, the tendency to do (or believe) things because many other people do (or believe) the same. Related to groupthink and herd behavior.</li>
<li><span><span id="Courtesy_bias"></span><span>Courtesy bias</span></span>, the tendency to give an opinion that is more socially correct than one's true opinion, so as to avoid offending anyone.</li>
<li>Groupthink, the psychological phenomenon that occurs within a group of people in which the desire for harmony or conformity in the group results in an irrational or dysfunctional decision-making outcome. Group members try to minimize conflict and reach a consensus decision without critical evaluation of alternative viewpoints by actively suppressing dissenting viewpoints, and by isolating themselves from outside influences.</li>
<li>Groupshift, the tendency for decisions to be more risk-seeking or risk-averse than the group as a whole, if the group is already biased in that direction</li>
<li>Social desirability bias, the tendency to over-report socially desirable characteristics or behaviours in oneself and under-report socially undesirable characteristics or behaviours. See also: § Courtesy bias.</li>
<li>Truth bias is people's inclination towards believing, to some degree, the communication of another person, regardless of whether or not that person is actually lying or being untruthful.</li></ul>
<h4 data-mw-anchor="Ingroup_bias">Ingroup bias</h4>

<p>Ingroup bias is the tendency for people to give preferential treatment to others they perceive to be members of their own groups. It is related to the following:
</p>
<ul><li>Not invented here, an aversion to contact with or use of products, research, standards, or knowledge developed outside a group.</li>
<li>Outgroup homogeneity bias, where individuals see members of other groups as being relatively less varied than members of their own group.</li></ul>
<h4 data-mw-anchor="Other_social_biases">Other social biases</h4>

<h2 data-mw-anchor="Memory">Memory <span id="Memory_biases"></span></h2>
<p>In psychology and cognitive science, a memory bias is a cognitive bias that either enhances or impairs the recall of a memory (either the chances that the memory will be recalled at all, or the amount of time it takes for it to be recalled, or both), or that alters the content of a reported memory. There are many types of memory bias, including:
</p>
<h3 data-mw-anchor="Misattribution_of_memory">Misattribution of memory</h3>


<p>The misattributions include:
</p>
<ul><li>Cryptomnesia, where a memory is mistaken for novel thought or imagination, because there is no subjective experience of it being a memory.</li>
<li>False memory, where imagination is mistaken for a memory.</li>
<li>Social cryptomnesia, a failure by people and society in general to remember the origin of a change, in which people know that a change has occurred in society, but forget how this change occurred; that is, the steps that were taken to bring this change about, and who took these steps. This has led to reduced social credit towards the minorities who made major sacrifices that led to a change in societal values.</li>
<li>Source confusion, episodic memories are confused with other information, creating distorted memories.</li>
<li>Suggestibility, where ideas suggested by a questioner are mistaken for memory.</li>
<li>The Perky effect, where real images can influence imagined images, or be misremembered as imagined rather than real</li></ul>
<h3 data-mw-anchor="Other_memory_biases">Other memory biases</h3>

<h2 data-mw-anchor="See_also">See also</h2>


<h2 data-mw-anchor="Footnotes">Footnotes</h2>

<h2 data-mw-anchor="References">References</h2>

<h2 data-mw-anchor="Further_reading">Further reading</h2>

<h2 data-mw-anchor="External_links">External links</h2>
<ul><li><span typeof="mw:File"></span> Media related to Memory biases at Wikimedia Commons</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/List_of_cognitive_biases#Consistency_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Overconfidence effect</h2>
<a href='https://en.wikipedia.org/wiki/Overconfidence_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>overconfidence effect</b> is a well-established bias in which a person's subjective <i>confidence</i> in their judgments is reliably greater than the objective <i>accuracy</i> of those judgments, especially when confidence is relatively high. Overconfidence is one example of a miscalibration of subjective probabilities. Throughout the research literature, overconfidence has been defined in three distinct ways: (1) <i>overestimation</i> of one's actual performance; (2) <i>overplacement</i> of one's performance relative to others; and (3) <i>overprecision</i> in expressing unwarranted certainty in the accuracy of one's beliefs.
</p><p>The most common way in which overconfidence has been studied is by asking people how confident they are of specific beliefs they hold or answers they provide.  The data show that confidence systematically exceeds accuracy, implying people are more sure that they are correct than they deserve to be. If human confidence had perfect calibration, judgments with 100% confidence would be correct 100% of the time, 90% confidence correct 90% of the time, and so on for the other levels of confidence. By contrast, the key finding is that confidence exceeds accuracy so long as the subject is answering hard questions about an unfamiliar topic. For example, in a spelling task, subjects were correct about 80% of the time, whereas they claimed to be 100% certain. Put another way, the error rate was 20% when subjects expected it to be 0%.  In a series where subjects made true-or-false responses to general knowledge statements, they were overconfident at all levels. When they were 100% certain of their answer to a question, they were wrong 20% of the time.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Overconfidence_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Social desirability bias</h2>
<a href='https://en.wikipedia.org/wiki/Social_desirability_bias' target='_blank'>Wikipedia Link</a>
<div class='content'></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Social_desirability_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Third–person effect</h2>
<a href='https://en.wikipedia.org/wiki/Third-person_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>third-person effect</b>  hypothesis predicts that people tend to perceive that mass media messages have a greater effect on others than on themselves, based on personal biases. The third-person effect manifests itself through an individual's overestimation of the effect of a mass communicated message on the generalized other, or an underestimation of the effect of a mass communicated message on themselves.
</p><p>These types of perceptions stem from a self-motivated social desirability (not feeling influenced by mass messages promotes self-esteem), a social-distance corollary (choosing to dissociate oneself from the others who may be influenced), and a perceived exposure to a message (others choose to be influenced by persuasive communication). Other names for the effect are "Third-person perception" and "Web Third-person effect". From 2015, the effect is named "Web Third-person effect" when it is verified in social media, media websites, blogs and in websites in general.  
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Third-person_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>False consensus effect</h2>
<a href='https://en.wikipedia.org/wiki/False_consensus_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In psychology, the <b>false consensus effect</b>, also known as <b>consensus bias</b>, is a pervasive cognitive bias that causes people to overestimate the extent to which other people share their beliefs and views; it is the tendency to "see their own behavioral choices and judgments as relatively common and appropriate to existing circumstances". In other words, they assume that their personal qualities, characteristics, beliefs, and actions are relatively widespread through the general population.
</p><p>This false consensus is significant because it increases self-esteem (overconfidence effect).  This bias is especially prevalent in group settings where one thinks the collective opinion of their own group matches that of the larger population. Since the members of a group reach a consensus and rarely encounter those who dispute it, they tend to believe that everybody thinks the same way. The false-consensus effect is not restricted to cases where people believe that their values are shared by the majority, but it still manifests as an overestimate of the extent of their belief. Additionally, when confronted with evidence that a consensus does not exist, people often assume that those who do not agree with them are defective in some way. 
</p><p>The false consensus effect has been widely observed and supported by empirical evidence.  One recent study has shown that consensus bias may improve decisions about other people's preferences. Ross, Green and House first defined the false consensus effect in 1977 with emphasis on the relative commonness that people perceive about their own responses; however, similar projection phenomena had already caught attention in psychology. Specifically, concerns with respect to connections between individual's personal predispositions and their estimates of peers appeared in the literature for a while. For instances, Katz and Allport in 1931 illustrated that students’ estimates of the amount of others on the frequency of cheating was positively correlated to their own behavior. Later, around 1970, same phenomena were found on political beliefs and prisoner's dilemma situation. In 2017, researchers identified a persistent egocentric bias when participants learned about other people's snack-food preferences. Moreover, recent studies suggest that the false consensus effect can also affect professional decision makers; specifically, it has been shown that even experienced marketing managers project their personal product preferences onto consumers.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/False_consensus_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Hard–easy effect</h2>
<a href='https://en.wikipedia.org/wiki/Hard–easy_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>
The <b>hard–easy effect</b> is a cognitive bias that manifests itself as a tendency to overestimate the probability of one's success at a task perceived as hard, and to underestimate the likelihood of one's success at a task perceived as easy. The hard-easy effect takes place, for example, when individuals exhibit a degree of underconfidence in answering relatively easy questions and a degree of overconfidence in answering relatively difficult questions. "Hard tasks tend to produce overconfidence but worse-than-average perceptions," reported Katherine A. Burson, Richard P. Larrick, and Jack B. Soll in a 2005 study, "whereas easy tasks tend to produce underconfidence and better-than-average effects."
</p><p>The hard-easy effect falls under the umbrella of "social comparison theory", which was originally formulated by Leon Festinger in 1954. Festinger argued that individuals are driven to evaluate their own opinions and abilities accurately, and social comparison theory explains how individuals carry out those evaluations by comparing themselves to others.
</p><p>In 1980, Ferrell and McGoey called it the "discriminability effect"; in 1992, Griffin and Tversky called it the "difficulty effect".
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Hard–easy_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Lake Wobegone effect</h2>
<a href='https://en.wikipedia.org/wiki/Lake_Wobegon#The_Lake_Wobegon_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Lake Wobegon</b> is a fictional town created by Garrison Keillor as the setting of the recurring segment "News from Lake Wobegon" for the radio program <i>A Prairie Home Companion</i> broadcast from Saint Paul, Minnesota. The fictional town serves as the setting for many of Keillor's stories and novels, gaining an international audience with <i>Lake Wobegon Days</i> in 1985. Described as a small rural town in central Minnesota, the events and adventures of the townspeople provided Keillor with a wealth of humorous and often touching stories.
</p><p>Keillor has said that people often ask him if it is a real town, and when he replied that it was not, they seemed disappointed because "people want stories to be true". So he began to say it was in "central Minnesota, near Stearns County, up around Holdingford, not far from St. Rosa and Albany and Freeport, northwest of St. Cloud", which he says is "sort of the truth, I guess".
</p>

<h2 data-mw-anchor="Name">Name</h2>

<p>Keillor has said the town's name comes from an old Native American word meaning "the place where we waited all day in the rain [for you]." Keillor explains, "<i>Wobegon</i> sounded Indian to me and Minnesota is full of Indian names. They mask the ethnic heritage of the town, which I wanted to do, since it was half Norwegian, half German." The English word <i>woebegone</i> means "affected with woe."
</p>
<h2 data-mw-anchor="Recurring_monologue_elements">Recurring monologue elements</h2>
<p>Keillor's weekly monologue about Lake Wobegon included recurring elements:
</p>
<ul><li>The typical monologue began: "Well, it's been a quiet week in Lake Wobegon, Minnesota, my hometown, out there on the edge of the prairie."</li>
<li>Lake Wobegon was called "the little town that time forgot and the decades cannot improve."</li>
<li>The monologue would close: "That's the news from Lake Wobegon, where all the women are strong, all the men are good-looking, and all the children are above average."</li></ul>
<h2 data-mw-anchor="Models">Models</h2>

<p>The fictional settlement Lake Wobegon resembles many small farm towns in the Upper Midwest, especially western Minnesota, North Dakota, and to some extent, northern Iowa, Wisconsin, eastern South Dakota and northeastern Montana. These are rural, sparsely populated areas that were settled only in the late 19th and early 20th centuries, largely by homesteading immigrants from Germany and Scandinavia. One of these, Holdingford, Minnesota, which Keillor said is "most Wobegonic", is on Stearns County's Lake Wobegon Regional Trail and advertises itself as the "Gateway to Lake Wobegon", even hosting a "Lake Wobegon Cafe."
</p><p>Keillor formed most of his ideas for Lake Wobegon while working at public radio station KSJR on the campus of St. John's University in Collegeville, basing it on Avon, where he lived, and other local towns such as Albany, Freeport, Cold Spring, Richmond, Rockville, St. Joseph, St. Stephen, St. Wendell and Holdingford. Stearns County was predominantly German and Catholic in the 1970s, and the second-most Catholic county in the US (second only to New Orleans). To balance the religious and ethnic demography of Stearns County with the rest of Minnesota, Keillor "imported" Lutheran and Scandinavian elements into the town, making it more recognizable and therefore more interesting to the rest of the state.
</p>
<h2 data-mw-anchor="National_location_hints">National location hints</h2>
<p>Lake Wobegon is portrayed as the seat of Mist County, Minnesota, a tiny county near Minnesota's geographic center that supposedly does not appear on maps because of the "incompetence of surveyors who mapped out the state in the 19th century": the surveyors worked inward from the state's boundaries, and when they reached Lake Wobegon, had no room left for it on the map. The town's slogan is <i>Gateway to Central Minnesota.</i> Holdingford now has the same slogan.
</p><p>Lake Wobegon is occasionally said to be near St. Olaf, Minnesota, another fictional town referred to in <i>The Golden Girls</i> television series. (There is actually a St. Olaf College in Northfield, Minnesota.) The town's school and amateur sports teams compete against the Uff-das of Upsala, a real town in southwest Morrison County, which is close to Holdingford. The town residents drink Wendy's Beer, brewed in St. Wendel, a real town in northeast Stearns County. The nearest good-sized town referred to in Keillor's monologues is St. Cloud. Lake Wobegon is sometimes compared favorably to a rival fictional town called Millet; a real town called Rice lies 20 miles north of St. Cloud.
</p><p>Microsoft Virtual Earth returned a location northeast of St. Cloud when Lake Wobegon was entered into its search engine. The programs distributed at live performances of <i>A Prairie Home Companion</i> in 2005 had a map showing Lake Wobegon about two miles north of Holdingford, northwest of St. Cloud.
</p><p>Keillor often refers to a cafe in downtown Lake Wobegon called the "Chatterbox Cafe". There was a real cafe and gas station in Olivia by that name, but it is now closed and abandoned, with nothing remaining to identify it but one sign. Olivia is in north-central Renville County.
</p><p>The Minnesota Rails and Trails project began creating the Lake Wobegon Trail in 1998. It now stretches from Waite Park, Minnesota just west of St. Cloud, to Freeport, Minnesota, where it forks; one trail heads northwest to Osakis, Minnesota, the other northeast to Holdingford, Minnesota and Bowlus, Minnesota, and on across the Mississippi River. Keillor participated in the trail opening ceremonies and said that Holdingford was the most "Wobegonic" town in his mind. The Lake Wobegon Trail Marathon takes place every year in May on the trail. Runners leave from Holdingford and run to St. Joseph, Minnesota.
</p>
<h2 data-mw-anchor="History_and_character">History and character</h2>
<p>Keillor chronicles a number of bizarre incidents in the fictional town's early history, akin to the events in Black River Falls in <i>Wisconsin Death Trip</i>.
</p><p>Keillor identifies the original founders of what became Lake Wobegon as New England Unitarian missionaries, at least one of whom came to convert the Native American Ojibwe Indians through interpretive dance. A college was founded at what was then called New Albion, but the project was abandoned after a severe winter and numerous attacks by bears. The project had only one survivor, a very practical woman who married a French Canadian fur trapper who fed her in exchange for her help with the chores. This pragmatic couple were the founders of the current settlement.
</p><p>New Albion's founders decided to settle at Lake Wobegon because they had gotten lost and did not know how to get back to where they had last been. To celebrate this, the colony's motto was <i>Ubi Quid Ubi</i> (Latin: "We're Here!...Where are we?"). Later the motto in the Lake Wobegon incorporated town seal is described as <i>Sumus Quod Sumus</i> (Latin: "We Are What We Are").
</p><p>Most of the population are descendants of German immigrants, who are mostly members of the Catholic parish of Our Lady of Perpetual Responsibility, and descendants of Norwegian and Swedish immigrants, who attend Lake Wobegon Lutheran Church. Keillor's family were members of the Sanctified Brethren.
</p><p>The 800 residents (1950 Census: 728) are proud of the <i>Statue of the Unknown Norwegian</i> (so called because the model left before the sculptor could get his name). Lake Wobegon is in competition with its fictional rival, St. Olaf, for having the most descendants of the same common ancestor. Lake Wobegon became a secret dumping ground of nuclear waste during the 1950s.
</p><p>The fictional town is the home of the Whippets baseball team, tuna hotdish, snow, Norwegian bachelor farmers, ice fishing, tongues frozen to cold metal objects, and lutefisk—fish treated with lye which, after being reconstituted, is reminiscent of "the afterbirth of a dog or the world's largest chunk of phlegm." But it is also the home of the Mist County Fair, old-fashioned show yards with flowers "like Las Vegas showgirls", sweet corn, a magnificent grain elevator, and the pleasant lake itself.
</p>
<h2 data-mw-anchor="The_Lake_Wobegon_effect">The Lake Wobegon effect</h2>

<p>The Lake Wobegon effect is a common name for illusory superiority, a natural human tendency to overestimate one's capabilities. The characterization that "all the women are strong, all the men are good-looking, and the children are all above average" has been used to describe a real and pervasive human tendency to overestimate one's achievements and capabilities in relation to others. In one survey of high school students, only 2% of the students reported that they were below average in leadership ability. The authors of a study suggest that what they consider the “Lake Wobegon effect” can in some cases negatively affect doctors' treatment advice when, in planning treatment, doctors portray the patients as “above average”.
</p><p>Keillor himself has offered a contrarian opinion on the use of the term, observing that the effect does not actually apply in Lake Wobegon itself. In response to a listener query on the Prairie Home website, he pointed out that, in keeping with their Scandinavian heritage, Wobegonians prefer to downplay, rather than overestimate, their capabilities or achievements.
</p>
<h2 data-mw-anchor="Local_life">Local life</h2>

<p>Businesses, organizations, and landmarks in Lake Wobegon include:
</p><ul><li>Jack's Auto Repair, including Jack's School of Thought (correspondence), Warm Car Service, Dry Goods Emporium, Jack's Fountain Lounge, and Jack's Home, "a rest spa for people of all ages"</li>
<li>Ralph's Pretty Good Grocery: "If you can't find it at Ralph's, you can probably get along (pretty good) without it."</li>
<li>Bertha's Kitty Boutique ("for persons who care about cats")</li>
<li>The Sidetrack Tap, run by Wally and Evelyn; "The dim little place in the dark where the pinball machine never tilts, the clock is a half-hour slow, and love never dies."</li>
<li>The Chatterbox Café, "The place to go that's just like home."</li>
<li>Café Boeuf, "Where the elite meet to greet and eat," with maitre d' Maurice.</li>
<li>Art's Baits &amp; Night o' Rest Motel (Art got sick of people being around, so you can't rent rooms there these days.)</li>
<li>Our Lady of Perpetual Responsibility Roman Catholic Church; Father Emil (retired), Father Wilmer (current)</li>
<li>Lake Wobegon Lutheran Church; Pastor Ingqvist (transferred), Pastor Barbara Ham (Interim Pastor), Pastor Liz (current)</li>
<li>Bunsen Motors (Ford dealer), run by Clint and Clarence Bunsen, local Lutherans</li>
<li>Krebsbach Chevrolet, run by Florian Krebsbach, local Catholic, and his son Carl.</li>
<li>Moonlight Bay Supper Club</li>
<li>Buck's Rent-a-Tux</li>
<li><i>The Herald Star</i>, town newspaper run by Harold Star</li>
<li>Skoeglin's 5 and Dime</li>
<li>LuAnne Magendanz's Bon Marché Beauty Parlor and Salon</li>
<li>Co-op Hardware (formerly Bigger Hammer Hardware, from the joke: "If at first you don't succeed, try using a bigger hammer.")</li>
<li>Clifford's (also known as "The Mercantile," which many residents still call it)</li>
<li>The Sons of Knute Temple, Norwegian fraternal organization</li>
<li>The Whippets, Town Team Baseball, "We'll Whip ya, whip ya good!"</li>
<li>The Herdsmen, champion church ushering team</li>
<li>The Curl Up and Dye, another local salon</li>
<li>Tentative Point, (better known as Lover's Lane)</li>
<li>Sons of Pitches, a men's chorus made up of the Original Main Street's finest in the Home of Sinclair Lewis</li>
<li>Lake Wobegon Piles ("twin 18-foot-high islands in the center of Lake Wobegon" created in 1956)</li>
<li>Mist County Historical Society Museum</li>
<li>Wally "Old Hard Hands" Bunsen Memorial Field (where The Whippets whip 'em all)</li>
<li>Lake Wobegon Loons (five-man football)</li>
<li>Powdermilk Biscuit Plant (on the road to Worthington)</li>
<li>Lake Wobegon High School
<ul><li>Lake Wobegon Leonards high school sports teams</li></ul></li>
<li>Municipal Sanitary Landfill</li>
<li>Statue of the Unknown Norwegian</li>
<li>Farmer's Union Grain Elevator</li>
<li>Bob's Bank, in the green mobile home</li>
<li>World's Largest Pile of Burlap Bags (created by Earl Dickmeyer to fund his and his wife's move to Fort Myers, Florida, and the centerpiece for a mysterious cure to ailments, such as kidney stones)</li></ul>
<h2 data-mw-anchor="In_literature">In literature</h2>
<p>Keillor has written several semi-autobiographical books about life in Lake Wobegon, including:
</p>
<ul><li><i>Lake Wobegon Days</i> (1985), ISBN 0-14-013161-2; a recorded version of this won a Grammy Award for Best Spoken Word or Non-Musical Recording in 1988</li>
<li><i>Leaving Home</i> (1987; collection of Lake Wobegon stories), ISBN 0-670-81976-X</li>
<li><i>We Are Still Married</i> (1989; collection including some Lake Wobegon stories), ISBN 0-670-82647-2</li>
<li><i>Wobegon Boy</i> (1997), ISBN 0-670-87807-3; a recorded version of this was nominated for a Grammy Award for Best Spoken Word Album in 1999</li>
<li><i>Lake Wobegon Summer 1956</i> (2001), ISBN 0-571-21014-7; a recorded version of this was nominated for a Grammy Award for Best Spoken Word Album in 2002</li>
<li><i>In Search of Lake Wobegon</i> (Photographs by Richard Olsenius, 2001), ISBN 978-0-670-03037-8</li>
<li><i>Pontoon: A Novel of Lake Wobegon </i>  (2007), ISBN 0-670-06356-8</li>
<li><i>Liberty: A Novel of Lake Wobegon </i>  (2008), ISBN 0-670-01991-7</li>
<li><i>Life among the Lutherans</i> (2009), ISBN 978-0-8066-7061-4</li>
<li><i>Pilgrims: A Wobegon Romance</i> (2009), ISBN 978-0-670-02109-3</li></ul>
<h2 data-mw-anchor="In_pop_culture">In pop culture</h2>
<ul><li>The 1993 <i>The Simpsons</i> episode Marge on the Lam opens with the Simpson family watching public television; a Keilloresque host delivers a monologue about Badger Falls with the closing words, "Where the men are pink-cheeked, the women are robust, and the children are pink-cheeked and robust."</li>
<li><i>Forensic Files</i> - The t-shirt worn by the killer John Famalaro that was entered into evidence in the murder of Denise Hueber was a Lake Wobegon t-shirt.</li>
<li>In Season 7, episode 7, of <i>The Office</i> ("The Christening") Erin Hannon tunes into <i>A Prairie Home Companion</i> on the car radio when picking up Michael Scott, Andy Bernard and a church kid from the side of the road.</li>
<li>In the 1984 Garfield animated TV special "Garfield in the Rough", Garfield, Jon, and Odie hear a radio news bulletin about a panther that has escaped from a local zoo earlier that morning and been reported in the "Lake Wobegon area".</li>
<li>Encryption software Pretty Good Privacy is named for Ralph's Pretty Good Grocery.</li></ul>
<h2 data-mw-anchor="See_also">See also</h2>
<ul><li>Lake Wobegon Trails, two paved recreational rail trails in central Minnesota named after the fictional Lake Wobegon in Garrison Keillor's <i>Prairie Home Companion</i></li>
<li>Lake Wobegon Marathon, marathon that is run along the Wobegon trail from Holdingford to St. Joseph</li>
<li>Lake Ore-be-gone</li></ul>
<h2 data-mw-anchor="References">References</h2>

<h2 data-mw-anchor="External_links">External links</h2>
<ul><li>Lake Wobegon Trail in Stearns County, Minnesota</li>
<li><i>In Search of Lake Wobegon</i> from <i>National Geographic</i>, part of an article plus links to related sites</li>
<li>News From Lake Wobegon podcast, American Public Media</li>
<li>A Prairie Home Companion</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Lake_Wobegon#The_Lake_Wobegon_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Dunning–Kruger effect</h2>
<a href='https://en.wikipedia.org/wiki/Dunning–Kruger_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">

</p>


<p>The <b>Dunning–Kruger effect</b> is a cognitive bias in which people with limited competence in a particular domain overestimate their abilities. It was first described by David Dunning and Justin Kruger in 1999. Some researchers also include the opposite effect for high performers: their tendency to underestimate their skills. In popular culture, the Dunning–Kruger effect is often misunderstood as a claim about general overconfidence of people with low intelligence instead of specific overconfidence of people unskilled at a particular task. 
</p><p>Numerous similar studies have been done. The Dunning–Kruger effect is usually measured by comparing self-assessment with objective performance. For example, participants may take a quiz and estimate their performance afterward, which is then compared to their actual results. The original study focused on logical reasoning, grammar, and social skills. Other studies have been conducted across a wide range of tasks. They include skills from fields such as business, politics, medicine, driving, aviation, spatial memory, examinations in school, and literacy.
</p><p>There is disagreement about the causes of the Dunning–Kruger effect. According to the metacognitive explanation, poor performers misjudge their abilities because they fail to recognize the qualitative difference between their performances and the performances of others. The statistical model explains the empirical findings as a statistical effect in combination with the general tendency to think that one is better than average. Some proponents of this view hold that the Dunning–Kruger effect is mostly a statistical artifact. The rational model holds that overly positive prior beliefs about one's skills are the source of false self-assessment. Another explanation claims that self-assessment is more difficult and error-prone for low performers because many of them have very similar skill levels.
</p><p>There is also disagreement about where the effect applies and about how strong it is, as well as about its practical consequences. Inaccurate self-assessment could potentially lead people to making bad decisions, such as choosing a career for which they are unfit, or engaging in dangerous behavior. It may also inhibit people from addressing their shortcomings to improve themselves. Critics argue that such an effect would have much more dire consequences than what is observed.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Dunning–Kruger_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Egocentric bias</h2>
<a href='https://en.wikipedia.org/wiki/Egocentric_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Egocentric bias</b> is the tendency to rely too heavily on one's own perspective and/or have a higher opinion of oneself than reality. It appears to be the result of the psychological need to satisfy one's ego and to be advantageous for memory consolidation. Research has shown that experiences, ideas, and beliefs are more easily recalled when they match one's own, causing an egocentric outlook. Michael Ross and Fiore Sicoly first identified this cognitive bias in their 1979 paper, "Egocentric Biases in Availability and Attribution". Egocentric bias is referred to by most psychologists as a general umbrella term under which other related phenomena fall.
</p><p>The effects of egocentric bias can differ based on personal characteristics, such as age and the number of languages one speaks.   Thus far, there have been many studies focusing on specific implications of egocentric bias in different contexts.  Research on collaborative group tasks have emphasized that people view their own contributions differently than they view that of others.  Other areas of research have been aimed at studying how mental health patients display egocentric bias, and at the relationship between egocentric bias and voter distribution.  These types of studies surrounding egocentric bias usually involve written or verbal questionnaires, based on the subject's personal life or their decision in various hypothetical scenarios.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Egocentric_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Optimism bias</h2>
<a href='https://en.wikipedia.org/wiki/Optimism_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Optimism bias</b> or <b>optimistic bias</b> is a cognitive bias that causes someone to believe that they themselves are less likely to experience a negative event. It is also known as <b>unrealistic optimism</b> or <b>comparative optimism</b>. It is common and transcends gender, ethnicity, nationality, and age. Autistic people are less susceptible to this kind of bias. It has also been reported in other animals, such as rats and birds. 
</p><p>Four factors can cause a person to be optimistically biased: their desired end state, their cognitive mechanisms, the information they have about themselves versus others, and overall mood. The optimistic bias is seen in a number of situations. For example: people believing that they are less at risk of being a crime victim, smokers believing that they are less likely to contract lung cancer or disease than other smokers, first-time bungee jumpers believing that they are less at risk of an injury than other jumpers, or traders who think they are less exposed to potential losses in the markets.
</p><p>Although the optimism bias occurs for both positive events (such as believing oneself to be more financially successful than others) and negative events (such as being less likely to have a drinking problem), there is more research and evidence suggesting that the bias is stronger for negative events (the "valence effect"). Different consequences result from these two types of events: positive events often lead to feelings of well being and self-esteem, while negative events lead to consequences involving more risk, such as engaging in risky behaviors and not taking precautionary measures for safety.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Optimism_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Forer effect</h2>
<a href='https://en.wikipedia.org/wiki/Barnum_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">

</p>

<p>The <b>Barnum effect</b>, also called the <b>Forer effect</b> or, less commonly, the <b>Barnum–Forer effect</b>, is a common psychological phenomenon whereby individuals give high accuracy ratings to descriptions of their personality that supposedly are tailored specifically to them, yet which are in fact vague and general enough to apply to a broad range of people. This effect can provide a partial explanation for the widespread acceptance of some paranormal beliefs and practices, such as astrology, fortune telling, aura reading, and some types of personality tests.
</p><p>It was originally called the "fallacy of personal validation" by psychologist Bertram Forer. The term "Barnum effect" was coined in 1956 by psychologist Paul Meehl in his essay "Wanted – A Good Cookbook", because he relates the vague personality descriptions used in certain "pseudo-successful" psychological tests to those given by showman P. T. Barnum.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Barnum_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Barnum effect</h2>
<a href='https://en.wikipedia.org/wiki/Barnum_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">

</p>

<p>The <b>Barnum effect</b>, also called the <b>Forer effect</b> or, less commonly, the <b>Barnum–Forer effect</b>, is a common psychological phenomenon whereby individuals give high accuracy ratings to descriptions of their personality that supposedly are tailored specifically to them, yet which are in fact vague and general enough to apply to a broad range of people. This effect can provide a partial explanation for the widespread acceptance of some paranormal beliefs and practices, such as astrology, fortune telling, aura reading, and some types of personality tests.
</p><p>It was originally called the "fallacy of personal validation" by psychologist Bertram Forer. The term "Barnum effect" was coined in 1956 by psychologist Paul Meehl in his essay "Wanted – A Good Cookbook", because he relates the vague personality descriptions used in certain "pseudo-successful" psychological tests to those given by showman P. T. Barnum.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Barnum_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Self–serving bias</h2>
<a href='https://en.wikipedia.org/wiki/Self-serving_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p>A <b>self-serving bias</b> is any cognitive or perceptual process that is distorted by the need to maintain and enhance self-esteem, or the tendency to perceive oneself in an overly favorable manner. It is the belief that individuals tend to ascribe success to their own abilities and efforts, but ascribe failure to external factors. When individuals reject the validity of negative feedback, focus on their strengths and achievements but overlook their faults and failures, or take more credit for their group's work than they give to other members, they are protecting their self-esteem from threat and injury. These cognitive and perceptual tendencies perpetuate illusions and error, but they also serve the self's need for esteem.  For example, a student who attributes earning a good grade on an exam to their own intelligence and preparation but attributes earning a poor grade to the teacher's poor teaching ability or unfair test questions might be exhibiting a self-serving bias. Studies have shown that similar attributions are made in various situations, such as the workplace, interpersonal relationships, sports, and consumer decisions.
</p><p>Both motivational processes (i.e. self-enhancement, self-presentation) and cognitive processes (i.e. locus of control, self-esteem) influence the self-serving bias. There are both cross-cultural (i.e. individualistic and collectivistic culture differences) and special clinical population (i.e. depression) considerations within the bias. Much of the research on the self-serving bias has used participant self-reports of attribution based on experimental manipulation of task outcomes or in naturalistic situations. Some more modern research, however, has shifted focus to physiological manipulations, such as emotional inducement and neural activation, in an attempt to better understand the biological mechanisms that contribute to the self-serving bias.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Self-serving_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Actor–observer bias</h2>
<a href='https://en.wikipedia.org/wiki/Actor–observer_asymmetry#bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Actor–observer asymmetry</b> (also <b>actor–observer bias</b> or <b>actor–observer difference</b>) is a bias one exhibits when forming attributions about the behavior of others or themselves. When explaining their own behavior, people are more likely to attribute their actions to the particular situation rather than their personality, also known as a situational attribution. However, when an observer is explaining the behavior of another person, they are more likely to attribute this behavior to the actors' personality rather than situational factors, also known as dispositional attribution. For example, a politician explaining why they voted against war may say it is because war is not needed, a situational factor. On the other hand, a person judging why the politician voted in this way may say it is because the politician is too liberal, a personality trait.
</p><p>Sometimes, the actor–observer asymmetry is defined as the fundamental attribution error, defined as when people tend to explain behavior using internal, personal characteristics rather than the external factors or situational influences.However, Malle (2006) highlights that these two phenomena should be distinguished because the fundamental attribution error refers to inferring stable internal traits from behaviour, whereas actor-observer asymmetry specifically refers to explanations of behaviour.
</p><p>Actor-observer asymmetry is often explained using perspectives and salience. When forming attributions, perspective highlights the situation, and what is occurring around the perceiver is most salient. As a result, perceivers may be more likely to make attributions based on these salient situational factors. However, when judging someone else, their behaviour is more salient than the situation. This may explain the greater chance of making dispositional attributions. Furthermore, when making judgements on one's own behaviour, much more information regarding the self is available, including knowledge of past behaviour. On the other hand, when judging others' behaviour, much less information is available. This lack of quality information likely also contributes to differences in attributions made. 
</p><p>The specific hypothesis of an actor–observer asymmetry in attribution was originally proposed by Edward Jones and Richard Nisbett, who stated that "actors tend to attribute the causes of their behavior to stimuli inherent in the situation, while observers tend to attribute behavior to stable dispositions of the actor". Supported by initial evidence, the hypothesis was long held as firmly established. However, a meta-analysis of all the published tests of the hypothesis between 1971 and 2004 found that there was no actor–observer asymmetry of the sort that had been previously proposed. The author of the study interpreted this result not so much as proof that actors and observers explained behavior exactly the same way but as evidence that the original hypothesis was fundamentally flawed in the way it framed people's explanations of behavior as either stable dispositional attributions or situational attributions.
</p><p>Considerations of actor–observer differences can be found in other disciplines as well, such as philosophy (e.g. privileged access, incorrigibility), management studies, artificial intelligence, semiotics, anthropology, and political science.
</p>

<h2 data-mw-anchor="Background_and_Initial_Formulation">Background and Initial Formulation</h2>
<p>The background of the actor-observer asymmetry was established in the 1960s, with social psychology's increasing interest in the cognitive mechanisms by which people make sense of their own and other people's behavior. This interest was instigated by Fritz Heider's book, <i>The Psychology of Interpersonal Relations</i>, and the research in its wake has become known as "attribution research" or "attribution theory."
</p><p>The specific hypothesis of an "actor–observer asymmetry" was first proposed by social psychologists Jones and Nisbett in 1971. Jones and Nisbett hypothesized that these two roles (actors and observers) produce asymmetric explanations.Their research findings were that "there is pervasive tendency for actors to attribute their actions to situational requirements, whereas observers tend to attribute the same actions to stable personal dispositions". By this theory, a student who studies hard for an exam is likely to explain her own (the actor's) intensive studying by referring to the upcoming difficult exam (a situational factor), whereas other people (the observers) are likely to explain her studying by referring to her dispositions, such as being hardworking or ambitious.
</p>
<h2 data-mw-anchor="Early_Evidence">Early Evidence</h2>
<p>Soon after the publication of the actor–observer hypothesis, numerous research studies tested its validity, most notably the first such test in 1973 by Nisbett et al. The authors found initial evidence for the hypothesis, and so did Storms,who also examined one possible explanation of the hypothesis: actors explain their behaviors because they attend to the situation (not to their own behaviors) whereas observers attend to the actor's behavior (not to the situation). Based largely on this initial supporting evidence, the confidence in the hypothesis became uniformly high.
</p><p>In the Nisbett et al. (1973) study, actor-observer asymmetry was tested by having participants select between two traits (such as energetic and relaxed), choosing which trait best matched the personality of the target, or if the trait that best matched them depended on the situation. They had participants chose between traits many times to see if participants mainly chose a specific trait or said it depended on the situation. Participants repeated the task saying what trait best matched for different people: their best friend, father, a famous news anchor, and themselves. The results showed that participants more frequently stated that the trait depended on the situation for themselves whereas for others' they often chose one trait that best described them. This provided evidence for actor-observer asymmetry because participants viewed other's personality traits as stable whereas their own as dependent on the situation.
</p><p>Functional neuroimaging studies have also demonstrated differential activation of brain regions when making self-focused vs. other-focused judgments. The medial prefrontal cortex (mPFC), left temporoparietal junction (TPJ), and posterior cingulate were involved in both self-related and other-related judgments. However, self-related judgments more often activated the ventral mPFC (vmPFC), left ventrolateral PFC, and left insula. In contrast, other-related judgments more frequently activated the dorsal mPFC (dmPFC), bilateral TPJ, and cuneus. These findings provide neurological depth to support the actor-observer asymmetry, with fundamentally different cognitive and neural processes involved in different types of attribution. Such work highlights how differential attribution is not only a cognitive bias but a biological one, too.
</p>
<h2 data-mw-anchor="Recent_Evidence_and_Refutation">Recent Evidence and Refutation</h2>
<p>Over 100 studies have been published since 1971 in which the hypothesis was put to further tests (often in the context of testing another hypothesis about causal attributions). Bertram Malle examined this entire literature in a meta-analysis, finding that, across 170 individual tests, the asymmetry practically did not exist. Under circumscribed conditions (i.e. if the actor was portrayed as highly idiosyncratic, or in negative events), it could sometimes be found, but under other conditions, the opposite was found. The conclusion was that the widely held assumption of an actor–observer asymmetry was false.
</p><p>External influences on the actor-observer effect are largely underemphasized. Research has shown that the actor-observer asymmetry is more likely to occur when an outcome is uncertain, partially controllable, and important. These findings suggest that the actor-observer asymmetry is not a fixed bias but rather a context-dependent phenomenon, challenging the idea that it universally governs attribution patterns.
</p>
<h2 data-mw-anchor="Cross-Cultural_Perspective">Cross-Cultural Perspective</h2>

<p>A significant body of literature exists to support the idea that there are cross-cultural differences in the attribution process. When considering the fundamental attribution error, it has been extended to be known as the "ultimate attribution error" instead, for initially in its discovery it was assumed to be a universal, or a <i>fundamental,</i> phenomenon. It has since been demonstrated that Western cultures are more susceptible to making the fundamental attribution error in comparison to Eastern cultures. Today, the ultimate attribution error is understood to occur when members of an in-group attribute negative behaviours of an out-group to their disposition, while attributing positive behaviours to situational factors. The opposite is true for when members of their own in-group engage in positive or negative behaviours.
</p><p>In general, studies have shown that collectivist cultures lean towards making situational attributions for the behaviour of others, whereas individualistic cultures lean towards making dispositional attributions. More specifically, in an 1985 study by Cha &amp; Nam, it was found that Korean individuals used more situationally-relevant information than Americans when making causal attributions. Notably, Choi &amp; Nisbett conducted an experiment where participants witnessed an individual writing an essay maintaining a certain view, and both Americans and Koreans believed that the essay reflected the true views of the writer. However, when put in the same position and asked to write an essay about a particular topic themselves, only the Americans continued to believe that the essay was reflective of the writer's attitudes, whereas the Korean participants took into account the situational restraints, and acknowledged that the content of the essay may not truly represent the views held by the writer. Even in regards to interpreting one's own behaviour, individualistic cultures possess the tendency to make situational attributions for their own behaviours. This variation may arise out of one's need to protect their self-esteem or confidence, but also illustrates the differences in cognition and perception between actors and observers.
</p>
<h2 data-mw-anchor="Broader_Implications">Broader Implications</h2>
<p>Findings on the actor-observer asymmetry extend beyond social perception, influencing how individuals internalize judgments from others. Others’ attributions can influence one’s self-view. When someone is frequently exposed to a critical observer who attributes mistakes to personal flaws or enduring character traits, they may begin to adopt this perspective, interpreting their own actions through the same lens. Internalizing such criticism can lead to a belief that their abilities are severely lacking and that their character is fundamentally flawed. Conversely, if a person regularly hears a supportive observer acknowledge their competence while recognizing that certain tasks are inherently challenging, they are more likely to develop a balanced approach to interpreting both their successes and setbacks.
</p>
<h2 data-mw-anchor="Related_concepts">Related concepts</h2>
<h3 data-mw-anchor="Self-serving_bias">Self-serving bias</h3>
<p>In attribution, the actor–observer asymmetry is often confused with the concept of self-serving bias — the claim that people attribute positive outcomes of their behaviour to dispositional factors, while attributing negative outcomes to situational factors. The difference between the two hypotheses is that the actor–observer asymmetry requires a specific comparison between actor explanations and observer explanations, while the self-serving bias refers only to actor explanations. Furthermore, actor-observer asymmetry is expected to hold for all events and behaviors (whether they are positive or negative), while the self-serving bias is often formulated as a complete reversal in actors' and observers' explanation tendencies as a function of positive or negative events. For example, the self-serving bias holds that for positive events, actors will select explanations that refer to their own dispositions, (e.g., "I am smart"); however, for negative events, actors will select explanations that refer to the situation, (e.g., "the test was hard").
</p>
<h3 data-mw-anchor="Correspondence_bias">Correspondence bias</h3>
<p>The correspondence bias is similar to actor-observer asymmetry in that both involve systematic differences in how people attribute behavior. However, the correspondence bias specifically focuses on disposition-congruent judgements of others based on their behaviours, even if these behaviours originate due to the situation. It states that observers believe they know an individual’s underlying disposition solely based on their actions. Actor-observer asymmetry, on the other hand, more closely aligns with a self-serving bias.
</p><p>Much like actor-observer asymmetry, correspondence bias is supported by several cognitive and environmental factors that contribute to its prevalence. There are four key mechanisms that each produce different forms of this bias: lack of awareness, unrealistic expectations, inflated categorizations, and incomplete corrections.
</p><p>A lack of awareness is constituted by ignorance of the situation in forming attributions. This often occurs due to naive realism, the tendency to believe that one’s own perception of reality is objective and unbiased. Such beliefs may cause observers to think the actor shares their interpretation of the situation, preventing further deliberation to consider situational factors.
</p><p>Unrealistic expectations include underestimating the power of the situation in various contexts. Interestingly, situational influence can also be overestimated, although this condition does not result in the correspondence bias.
</p><p>Inflated categorization refers to how ambiguous behaviors can be “inflated” due to the situation in which they occurred. If a perciever uses contextual cues to infer the nature, strength, etc. of behaviours, any disparities between their inference and reality will become especially striking. These disparities then prompt strong dispositional attributions.
</p><p>Incomplete corrections are the inability to properly correct for one’s immediate assessment of the situation. Observers may judge based on disposition at first, then consider situational factors, but the adjustment between these cognitive mechanisms is not always optimal. Thus, disposition is still largely overrepresented in cognitive appraisals.
</p><p>Despite the specific mechanism that produces correspondence bias, all forms highlight the pervasive tendency to overattribute behavior to dispositional factors while neglecting situational influences. This process gives rise to various positive and negative implications. For example, while correspondence bias gives observers control of their social world by predicting others, it can also lead to false interpretations of the situation. In some cases, the benefits outweigh the costs by saving the observer valuable time and cognitive effort, but nevertheless, this heuristic must be used with caution.
</p><p>Additionally, the correspondence bias has a forward thinking component. Observers tend to attribute the actions of others to their future behavior. When someone witnesses another person's actions, they are likely to attribute those same actions to that person's future behavior, which is why first impressions are so important. Once an action is observed, it can be difficult for the observer to imagine the actor behaving differently. On the other hand, actors may find it difficult to attribute a single action to their own overall behavior. They view themselves as more responsive and in control of situational matters. While actors can attribute their past actions, observers can only attribute the one action they have witnessed to the actor, leading them to attribute dispositional rather than situational factors to the actor's behavior.
</p>
<h3 data-mw-anchor="Trait_Ascription">Trait Ascription</h3>
<p>The concept of trait ascription bias provides an alternative explanation for actor-observer asymmetry. Trait ascription bias refers to the tendency to perceive one's own personality, beliefs, and behaviors as dynamic and adaptable while viewing others as more fixed and predictable. This leads people to oversimplify and categorize others based on their actions, attributing behavior to inherent traits, whereas they see their own actions as influenced by context and circumstance.
</p>
<h2 data-mw-anchor="See_also">See also</h2>

<ul><li>Attribution (psychology)</li>
<li>Fundamental attribution error</li>
<li>List of biases in judgment and decision making</li>
<li>Self-serving bias</li></ul>
<h2 data-mw-anchor="References">References</h2>

<h3 data-mw-anchor="Bibliography">Bibliography</h3></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Actor–observer_asymmetry#bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Illusion of control</h2>
<a href='https://en.wikipedia.org/wiki/Illusion_of_control' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>illusion of control</b> is the tendency for people to overestimate their ability to control events. It was named by U.S. psychologist Ellen Langer and is thought to influence gambling behavior and belief in the paranormal. Along with illusory superiority and optimism bias, the illusion of control is one of the positive illusions.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Illusion_of_control'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Illusory superiority</h2>
<a href='https://en.wikipedia.org/wiki/Illusory_superiority' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>

<p class="mw-empty-elt">
</p>

<p>In social psychology, <b>illusory superiority</b> is a cognitive bias wherein people overestimate their own qualities and abilities compared to others. Illusory superiority is one of many positive illusions, relating to the self, that are evident in the study of intelligence, the effective performance of tasks and tests, and the possession of desirable personal characteristics and personality traits. Overestimation of abilities compared to an objective measure is known as the <i>overconfidence effect</i>.
</p><p>The term "illusory superiority" was first used by the researchers Van Yperen and Buunk, in 1991. The phenomenon is also known as the <b>above-average effect</b>, the <b>superiority bias</b>, the <b>leniency error</b>, the <b>sense of relative superiority</b>, the <b><i>primus inter pares</i> effect</b>, and the <b>Lake Wobegon effect</b>, named after the fictional town where all the children are above average. The Dunning-Kruger effect is a form of illusory superiority shown by people on a task where their level of skill is low.
</p><p>
A vast majority of the literature on illusory superiority originates from studies on participants in the United States. However, research that only investigates the effects in one specific population is severely limited as this may not be a true representation of human psychology. More recent research investigating self-esteem in other countries suggests that illusory superiority depends on culture. Some studies indicate that East Asians tend to underestimate their own abilities in order to improve themselves and get along with others.</p>
</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Illusory_superiority'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Fundamental attribution error</h2>
<a href='https://en.wikipedia.org/wiki/Fundamental_attribution_error' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In social psychology, the <b>fundamental attribution error</b> is a cognitive attribution bias in which observers underemphasize situational and environmental factors for the behavior of an actor while overemphasizing dispositional or personality factors. In other words, observers tend to overattribute the behaviors of others to their personality (e.g., <i>he is late because he's selfish</i>) and underattribute them to the situation or context (e.g., <i>he is late because he got stuck in traffic</i>). Although personality traits and predispositions are considered to be observable facts in psychology, the fundamental attribution error is an error because it misinterprets their effects.
</p><p>The group attribution error is identical to the fundamental attribution error, where the bias is shown between members of different groups rather than different individuals.
</p><p>The ultimate attribution error is a derivative of the fundamental attribution error and group attribution error relating to the actions of groups, with an additional layer of self-justification relating to whether the action of an individual is representative of the wider group.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Fundamental_attribution_error'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Defensive attribution hypothesis</h2>
<a href='https://en.wikipedia.org/wiki/Defensive_attribution_hypothesis' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>defensive attribution hypothesis</b> (or <i>bias</i>, <i>theory</i>, or simply <i><b>defensive attribution</b></i>) is a social psychological term where an observer attributes the causes for a mishap to minimize their fear of being a victim or a cause in a similar situation. The attributions of blame are negatively correlated to similarities between the observer and the people involved in the mishap, i.e. more responsibility is attributed to the people involved who are dissimilar to the observer. Assigning responsibility allows the observer to believe that the mishap was controllable and thus preventable.
</p><p>A defensive attribution may also be used to protect the person's self-esteem if, despite everything, the mishap does occur, because blame can be assigned to the "other" (person or situation). The use of defensive attributions is considered a cognitive bias because an individual will change their beliefs about a situation based upon their motivations or desires rather than the factual characteristics of the situation.<sup class="reference nowrap"><span title="Page / location: 112">: 112 </span></sup>
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Defensive_attribution_hypothesis'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Trait ascription bias</h2>
<a href='https://en.wikipedia.org/wiki/Trait_ascription_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Trait ascription bias</b> is the tendency for people to view <i>themselves</i> as relatively variable in terms of personality, behavior and mood while viewing others as much more predictable in their personal traits across different situations. More specifically, it is a tendency to describe one's own behaviour in terms of situational factors while preferring to describe another's behaviour by ascribing fixed dispositions to their personality. This may occur because peoples' own internal states are more readily observable and available to them than those of others.
</p><p>This attributional bias intuitively plays a role in the formation and maintenance of stereotypes and prejudice, combined with the negativity effect. However, trait ascription and trait-based models of personality remain contentious in modern psychology and social science research. Trait ascription bias refers to the situational and dispositional evaluation and description of personality traits on a personal level. A similar bias on the group level is called the outgroup homogeneity bias.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Trait_ascription_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Effort justification</h2>
<a href='https://en.wikipedia.org/wiki/Effort_justification' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Effort justification</b> is an idea and paradigm in social psychology stemming from Leon Festinger's theory of cognitive dissonance. Effort justification is a person's tendency to attribute the value of an outcome they put effort into achieving as greater than the objective value of the outcome.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Effort_justification'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Risk compensation</h2>
<a href='https://en.wikipedia.org/wiki/Risk_compensation' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Risk compensation</b>  is a theory which suggests that people typically adjust their behavior in response to perceived levels of risk, becoming more careful where they sense greater risk and less careful if they feel more protected. Although usually small in comparison to the fundamental benefits of safety interventions, it may result in a lower net benefit than expected or even higher risks.
</p><p>By way of example, it has been observed that motorists drove closer to the vehicle in front when the vehicles were fitted with anti-lock brakes. There is also evidence that the risk compensation phenomenon could explain the failure of condom distribution programs to reverse HIV prevalence and that condoms may foster disinhibition, with people engaging in risky sex both with and without condoms.
</p><p>By contrast, shared space is an urban street design method which consciously aims to increase the level of perceived risk and uncertainty, thereby slowing traffic and reducing the number and seriousness of injuries.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Risk_compensation'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Peltzman effect</h2>
<a href='https://en.wikipedia.org/wiki/Risk_compensation#Peltzman_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Risk compensation</b>  is a theory which suggests that people typically adjust their behavior in response to perceived levels of risk, becoming more careful where they sense greater risk and less careful if they feel more protected. Although usually small in comparison to the fundamental benefits of safety interventions, it may result in a lower net benefit than expected or even higher risks.
</p><p>By way of example, it has been observed that motorists drove closer to the vehicle in front when the vehicles were fitted with anti-lock brakes. There is also evidence that the risk compensation phenomenon could explain the failure of condom distribution programs to reverse HIV prevalence and that condoms may foster disinhibition, with people engaging in risky sex both with and without condoms.
</p><p>By contrast, shared space is an urban street design method which consciously aims to increase the level of perceived risk and uncertainty, thereby slowing traffic and reducing the number and seriousness of injuries.
</p>

<h2 data-mw-anchor="Overview">Overview</h2>
<p>Risk compensation is related to the broader term behavioral adaptation which includes all behavior changes in response to safety measures, whether compensatory or not. However, since researchers are primarily interested in the compensatory or negative adaptive behavior the terms are sometimes used interchangeably. The more recent version emerged from road safety research after it was claimed that many interventions failed to achieve the expected level of benefits but has since been investigated in many other fields.
</p>
<h3 data-mw-anchor="Peltzman_effect">Peltzman effect</h3>
<p>The reduction of predicted benefit from regulations that intend to increase safety is sometimes referred to as the <i>Peltzman effect</i> in recognition of Sam Peltzman, a professor of economics at the University of Chicago Booth School of Business, who published "The Effects of Automobile Safety Regulation" in the <i>Journal of Political Economy</i> in 1975 in which he controversially suggested that "offsets (due to risk compensation) are virtually complete, so that regulation has not decreased highway deaths". Peltzman claimed to originate this theory in the 1970s but it was used to oppose the requirement of safety equipment on trains in the Nineteenth Century. 
</p><p>A reanalysis of his original data found numerous errors and his model failed to predict fatality rates before regulation. According to Peltzman, regulation was at best useless, at worst counterproductive. Peltzman found that the level of risk compensation in response to highway safety regulations was <i>complete</i> in original study. But "Peltzman's theory does not predict the magnitude of risk compensatory behaviour." Substantial further empirical work has found that the effect exists in many contexts but generally offsets less than half of the direct effect. In the U.S., motor vehicle fatalities per population declined by more than half from the beginning of regulation in the 1960s through 2012. Vehicle safety standards accounted for most of the reduction augmented by seat belt use laws, changes in the minimum drinking age, and reductions in teen driving.
</p><p>The Peltzman effect can also result in a redistributing effect where the consequences of risky behaviour are increasingly felt by innocent parties (see moral hazard). By way of example, if a risk-tolerant driver responds to driver-safety interventions, such as compulsory seat belts, crumple zones, antilock brakes, etc. by driving faster with less attention, then this can result in increases in injuries and deaths to pedestrians.
</p>
<h3 data-mw-anchor="Risk_homeostasis">Risk homeostasis</h3>
<p>Risk homeostasis is a controversial hypothesis, initially proposed in 1982 by Gerald J. S. Wilde, a professor at Queen's University in Canada, which suggests that people maximise their benefit by comparing the expected costs and benefits of safer and riskier behaviour and which introduced the idea of the <i>target level of risk</i>. He proposed four constituents to a person's calculations relating to risk:
</p>
<ul><li>Expected benefits of risky behavior (e.g., gaining time by speeding, fighting boredom, increasing mobility)</li>
<li>Expected costs of risky behavior (e.g., speeding tickets, car repairs, insurance surcharges)</li>
<li>Expected benefits of safe behavior (e.g., insurance discounts for accident-free periods, enhancement of reputation of responsibility)</li>
<li>Expected costs of safe behavior (e.g., using an uncomfortable seat belt, being called a coward by one's peers, time loss)</li></ul>
<p>Wilde noted that when Sweden changed from driving on the left to driving on the right in 1967, this was followed by a marked reduction in the traffic fatality rate for 18 months after which the trend returned to its previous values. He suggested that drivers had responded to increased perceived danger by taking more care, only to revert to previous habits as they became accustomed to the new regime. A similar pattern was seen following Iceland's switch from left- to right-hand driving.
</p><p>In a Munich study, part of a fleet of taxicabs were equipped with anti-lock brakes (ABS), while the remainder had conventional brake systems. In other respects, the two types of cars were identical. The crash rates, studied over three years, were a little higher for the cabs with ABS, Wilde concluded that drivers of ABS-equipped cabs took more risks, assuming that ABS would take care of them; non-ABS drivers were said to drive more carefully since they could not rely on ABS in a dangerous situation.
</p><p>The idea of risk homeostasis is disputed. One author claimed that it received "little support", another suggested that it "commands about as much credence as the flat earth hypothesis", a third noted that the proposal did create considerable media attention: "What set the debate alight, rather like petrol on flames, was the proposition in 1982 that road users did not just adapt to perceptions of changing risk through compensatory behaviors, but that the process was a homeostatic one, producing overall equilibrium in safety-related outcomes". Others claimed that road fatality statistics, which have fallen considerably since the introduction of safety measures, do not support the theory.
</p>
<h3 data-mw-anchor="Preventive_measures">Preventive measures</h3>
<p>To create preventive measures in order to make a certain activity safer, risk compensation and risk compensation behavior has to be mapped in order to evaluate whether the measures are effective. When measures create risk compensation this might nullify the made measures. Then the measures might not lead to less injuries or in worse cases enhance injuries.

</p>
<h2 data-mw-anchor="Examples">Examples</h2>
<h3 data-mw-anchor="Road_transport">Road transport</h3>
<h4 data-mw-anchor="Anti-lock_brakes">Anti-lock brakes</h4>
<p>Anti-lock braking systems are designed to increase vehicle safety by allowing the vehicle to steer while braking.
</p><p>A number of studies show that drivers of vehicles with ABS tend to drive faster, follow closer and brake later, accounting for the failure of ABS to result in any measurable improvement in road safety. The studies were performed in Canada, Denmark, and Germany. A study led by Clifford Winston and Fred Mannering, a professor of civil engineering at the University of South Florida supports risk compensation, terming it the "offset hypothesis". A study of crashes involving taxicabs in Munich of which half had been equipped with anti-lock brakes noted that crash rate was substantially the same for both types of cab, and concluded this was due to drivers of ABS-equipped cabs taking more risks.
</p><p>However, the Insurance Institute for Highway Safety released a study in 2010 that found motorcycles with ABS were 37 percent less likely to be involved in a fatal crash than models without ABS. A 2004 study found that ABS reduced the risk of multiple vehicle crashes by 18 percent, but had increased the risk of run-off-road crashes by 35 percent.
</p>
<h4 data-mw-anchor="Seat_belts">Seat belts</h4>
<p>A 1994 research study of people who both wore and habitually did not wear seatbelts concluded that drivers were found to drive faster and less carefully when belted.
</p><p>Several important driving behaviors were observed on the road before and after the belt use law was enforced in Newfoundland, and in Nova Scotia during the same period without a law. Belt use increased from 16 percent to 77 percent in Newfoundland and remained virtually unchanged in Nova Scotia. Four driver behaviors (speed, stopping at intersections when the control light was amber, turning left in front of oncoming traffic, and gaps in following distance) were measured at various sites before and after the law. Changes in these behaviors in Newfoundland were similar to those in Nova Scotia, except that drivers in Newfoundland drove slower on expressways after the law, contrary to the risk compensation theory.
</p><p>In Britain in 1981 at a time when the government was considering the introduction of seat belt legislation, John Adams of University College London, suggested that there was no convincing evidence of a correlation between the seat-belt legislation and reduction of injuries and fatalities based on a comparison between states with and without seat belt laws. He also suggested that some injuries were displaced from car drivers to pedestrians and other road users. The "Isles Report" echoed these concerns. Adams subsequently argued that the reduction in fatalities that followed the introduction of legislation could not be attributed with confidence to seat-belt use due to the simultaneous introduction of breath testing for driving under the influence of alcohol.
</p><p>However, a 2007 study based on data from the Fatality Analysis Reporting System (FARS) of the National Highway Traffic Safety Administration concluded that between 1985 and 2002 there were "significant reductions in fatality rates for occupants and motorcyclists after the implementation of belt use laws", and that "seatbelt use rate is significantly related to lower fatality rates for the total, pedestrian, and all non-occupant models even when controlling for the presence of other state traffic safety policies and a variety of demographic factors". A comprehensive 2003 US study also did "not find any evidence that higher seat belt usage has a significant effect on driving behavior." Their results showed that "overall, mandatory seat belt laws unambiguously reduce traffic fatalities."
</p>
<h4 data-mw-anchor="Swedish_change_to_driving_on_the_right">Swedish change to driving on the right</h4>
<p>In Sweden, following the change from driving on the left to driving on the right in 1967 there was a drop in crashes and fatalities, which was linked to the increased apparent risk. The number of motor insurance claims went down by 40 percent, returning to normal over the next six weeks. Fatality levels took two years to return to normal.
</p>
<h4 data-mw-anchor="Speed_limits">Speed limits</h4>
<p>The control of traffic speeds using effectively enforced speed limits and other traffic calming methods plays an important role in the reduction of road traffic casualties; speed limit changes alone without accompanying enforcement or traffic calming measures will not.
</p><p>A 1994 study conducted to test the risk homeostasis theory, using a driving simulator, found that increasing posted speed limits and a reduction of speeding fines had significantly increased driving speed but resulted in no change in the accident frequency. It also showed that increased accident cost caused large and significant reductions in accident frequency but no change in speed choice. The results suggest that regulation of specific risky behaviors such as speed choice may have little influence on accident rates.
</p>
<h4 data-mw-anchor="Shared_space">Shared space</h4>

<p>Shared space is an approach to the design of roads, where risk compensation is consciously used to <i>increase</i> the level of uncertainty for drivers and other road users by removing traditional demarcations between vehicle traffic by removing curbs, road surface markings, and traffic signs. The approach has been found to result in lower vehicle speeds and fewer road casualties.
</p>
<h4 data-mw-anchor="Bicycle_helmets">Bicycle helmets</h4>
<p>Campaigns and legislation to encourage the wearing of cycle helmets have not been shown to reduce significant head injuries, and "there is evidence to suggest that some cyclists ride less cautiously when helmeted because they feel more protected". In one experimental study, adults accustomed to wearing helmets cycled more slowly without a helmet, but no difference in helmeted and unhelmeted cycling speed was found for cyclists who do not usually wear helmets.  A Spanish study of traffic accidents between 1990 and 1999 found no strong evidence of risk compensation in helmet wearers but concluded that "this possibility cannot be ruled out".
</p><p>Motorists may also alter their behavior toward helmeted cyclists. One study by Walker in England found that 2,500 vehicles passed a helmeted cyclist with measurably less clearance (8.5 cm) than that given to the same cyclist unhelmeted (out of an average total passing distance of 1.2 to 1.3 metres). The significance of these differences has been re-analysed by Olivier, who argued that the effect on safety was not significant since the passing distances were over 1 metre, and again by Walker, who disagreed with Olivier's conclusion.
</p><p>In 1988, Rodgers re-analysed data which supposedly showed helmets to be effective and found both data errors and methodological weaknesses. He concluded that in fact the data showed "bicycle-related fatalities are positively and significantly associated with increased helmet use" and mentioned risk compensation as one possible explanation of this association.
</p>
<h3 data-mw-anchor="Infrastructure">Infrastructure</h3>

<p>Levees are structures which run parallel to rivers and are meant to offer protection from flooding. The perception of safety can lead to unsafe land development in the floodplain which is supposed to be protected by the levee. Consequently, when a flood does occur or the levee breaches, the effects of that disaster will be greater than if the levee had not been built.
</p>
<h3 data-mw-anchor="Sport">Sport</h3>
<h4 data-mw-anchor="Martial_arts">Martial arts</h4>
<p>This principle is recognised in some martial arts, including karate, where it is suggested that wearing protective gloves might lead to harder strikes and punches, possibly resulting in more severe injuries.  It has also been suggested in historical European martial arts.
</p>
<h4 data-mw-anchor="Ski_helmets">Ski helmets</h4>
<p>Recent studies indicate that skiers wearing helmets go faster on average than non-helmeted skiers, and that overall risk index is higher in helmeted skiers than non-helmeted skiers. Moreover, while helmets may help prevent minor head injuries, increased usage of helmets has not reduced the overall fatality rate.
</p><p>Other recent studies have concluded that helmet use is not associated with riskier behavior among skiers and snowboarders, and that helmet usage reduces the risk and severity of head injuries.
</p>
<h4 data-mw-anchor="Football_helmets">Football helmets</h4>
<p>Some researchers have found the counterintuitive result that wearing helmets in gridiron football actually increases the chance of injury, and thus they recommend players occasionally practice without helmets. When hard shells were first introduced, the number of head injuries increased because players had a false sense of security and made more dangerous tackles.
</p>
<h4 data-mw-anchor="Skydiving">Skydiving</h4>
<p>'Booth's rule #2', often attributed to skydiving pioneer Bill Booth, states, "the safer skydiving gear becomes, the more chances skydivers will take, in order to keep the fatality rate constant". Even though skydiving equipment has made huge leaps forward in terms of reliability, including the introduction of safety devices such as AADs, the fatality rate has stayed roughly constant when adjusted for the increasing number of participants. This can largely be attributed to an increase in the popularity of high performance canopies, which fly much faster than traditional parachutes. A greater number of landing fatalities in recent years has been attributed to high speed maneuvers close to the ground.
</p>
<h3 data-mw-anchor="Safety_equipment_in_children">Safety equipment in children</h3>
<p>Experimental studies have suggested that children who wear protective equipment are likely to take more risks.
</p>
<h3 data-mw-anchor="Health">Health</h3>
<h4 data-mw-anchor="Risky_sexual_behavior_and_HIV/AIDS" data-mw-fallback-anchor="Risky_sexual_behavior_and_HIV.2FAIDS">Risky sexual behavior and HIV/AIDS</h4>
<p>Evidence on risk compensation associated with HIV prevention interventions is mixed. Harvard researcher Edward C. Green argued that the risk compensation phenomenon could explain the failure of condom distribution programs to reverse HIV prevalence, providing a detailed explanations of his views in an op-ed article for <i>The Washington Post</i> and an extended interview with the BBC. A 2007 article in the <i>Lancet</i> suggested that "condoms seem to foster disinhibition, in which people engage in risky sex either with condoms or with the intention of using condoms". Another report compared risk behaviour of men based on whether they were circumcised.
A 2015 study showed that adolescents with safe-sex beliefs (adolescents who believe that sex with condoms is 100% safe) have an earlier sexual initiation.
</p>
<h4 data-mw-anchor="PrEP">PrEP</h4>
<p>While pre-exposure prophylaxis (PrEP) with anti-HIV drugs appears to be extremely successful in suppressing the spread of HIV infection, there is some evidence that the reduction in HIV risk has led to some people taking more sexual risks; specifically, reduced use of condoms in anal sex, raising risks of spreading sexually transmitted diseases other than HIV.
</p>
<h2 data-mw-anchor="See_also">See also</h2>
<ul><li>Moral hazard</li>
<li>Omission bias</li>
<li>Rebound effect</li>
<li>Unintended consequences</li>
<li>Self-licensing</li>
<li>Tullock's spike, a thought experiment by Gordon Tullock in reversing the risk compensation effect</li></ul>
<h2 data-mw-anchor="Notes">Notes</h2>

<h3 data-mw-anchor="Sources">Sources</h3>
<ul><li><cite id="CITEREFHedlund2000" class="citation journal cs1">Hedlund, J. (2000). "Risky business: safety regulations, risk compensation, and individual behavior". <i>Injury Prevention</i>. <b>6</b> (2): <span>82–</span>89. doi:10.1136/ip.6.2.82. PMC <span title="Freely accessible">1730605</span>. PMID 10875661.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Injury+Prevention&amp;rft.atitle=Risky+business%3A+safety+regulations%2C+risk+compensation%2C+and+individual+behavior&amp;rft.volume=6&amp;rft.issue=2&amp;rft.pages=82-89&amp;rft.date=2000&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC1730605%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F10875661&amp;rft_id=info%3Adoi%2F10.1136%2Fip.6.2.82&amp;rft.aulast=Hedlund&amp;rft.aufirst=J.&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC1730605&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li>
<li><cite id="CITEREFO'NeillWilliams1998" class="citation journal cs1">O'Neill, B; Williams, A (June 1998). "Risk homeostasis hypothesis: a rebuttal". <i>Injury Prevention</i>. <b>4</b> (2): <span>92–</span>3. doi:10.1136/ip.4.2.92. PMC <span title="Freely accessible">1730350</span>. PMID 9666359.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Injury+Prevention&amp;rft.atitle=Risk+homeostasis+hypothesis%3A+a+rebuttal&amp;rft.volume=4&amp;rft.issue=2&amp;rft.pages=92-3&amp;rft.date=1998-06&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC1730350%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F9666359&amp;rft_id=info%3Adoi%2F10.1136%2Fip.4.2.92&amp;rft.aulast=O%27Neill&amp;rft.aufirst=B&amp;rft.au=Williams%2C+A&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC1730350&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li>
<li><cite id="CITEREFRudin-BrownJamson2013" class="citation book cs1">Rudin-Brown, Christina; Jamson, Samantha (2013). <i>Behavioural Adaptation and Road Safety: Theory, Evidence and Action</i>. CRC Press. p. 67. ISBN <bdi>978-1-4398-5667-3</bdi>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Behavioural+Adaptation+and+Road+Safety%3A+Theory%2C+Evidence+and+Action&amp;rft.pages=67&amp;rft.pub=CRC+Press&amp;rft.date=2013&amp;rft.isbn=978-1-4398-5667-3&amp;rft.aulast=Rudin-Brown&amp;rft.aufirst=Christina&amp;rft.au=Jamson%2C+Samantha&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li>
<li><cite id="CITEREFRuedl_et_al.2010" class="citation journal cs1">Ruedl, G; et al. (February 2010). "Factors associated with self-reported risk-taking behaviour on ski slopes". <i>Br J Sports Med</i>. <b>44</b> (3): <span>204–</span>6. doi:10.1136/bjsm.2009.066779. PMID 20231601. S2CID 27944820.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Br+J+Sports+Med&amp;rft.atitle=Factors+associated+with+self-reported+risk-taking+behaviour+on+ski+slopes&amp;rft.volume=44&amp;rft.issue=3&amp;rft.pages=204-6&amp;rft.date=2010-02&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A27944820%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F20231601&amp;rft_id=info%3Adoi%2F10.1136%2Fbjsm.2009.066779&amp;rft.aulast=Ruedl&amp;rft.aufirst=G&amp;rft.au=Pocecco%2C+E&amp;rft.au=Sommersacher%2C+R&amp;rft.au=Gatterer%2C+H&amp;rft.au=Kopp%2C+M&amp;rft.au=Nachbauer%2C+W&amp;rft.au=Burtscher%2C+M&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li>
<li><cite id="CITEREFVrolix2006" class="citation report cs1">Vrolix, Klara (2006). Behavioral adaptation, risk compensation, risk homeostatis and moral hazard in traffic safety. <i>Hasselt University</i> (Report). hdl:<span title="Freely accessible">1942/4002</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=report&amp;rft.btitle=Behavioral+adaptation%2C+risk+compensation%2C+risk+homeostatis+and+moral+hazard+in+traffic+safety&amp;rft.date=2006&amp;rft_id=info%3Ahdl%2F1942%2F4002&amp;rft.aulast=Vrolix&amp;rft.aufirst=Klara&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li>
<li><cite id="CITEREFWilde1998" class="citation journal cs1">Wilde, G. J S (1998). "Risk homeostasis theory: an overview". <i>Injury Prevention</i>. <b>4</b> (2): <span>89–</span>91. doi:10.1136/ip.4.2.89. PMC <span title="Freely accessible">1730348</span>. PMID 9666358.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Injury+Prevention&amp;rft.atitle=Risk+homeostasis+theory%3A+an+overview&amp;rft.volume=4&amp;rft.issue=2&amp;rft.pages=89-91&amp;rft.date=1998&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC1730348%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F9666358&amp;rft_id=info%3Adoi%2F10.1136%2Fip.4.2.89&amp;rft.aulast=Wilde&amp;rft.aufirst=G.+J+S&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC1730348&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li>
<li><cite id="CITEREFLessons_to_be_Learned2013" class="citation web cs1">"Lessons to be Learned: The 2012 Fatality Summary". 11 April 2013. Archived from the original on 2016-03-08.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lessons+to+be+Learned%3A+The+2012+Fatality+Summary&amp;rft.date=2013-04-11&amp;rft_id=http%3A%2F%2Fparachutistonline.com%2Ffeature%2Flessons-to-be-learned&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li></ul>
<h2 data-mw-anchor="References">References</h2>

<h2 data-mw-anchor="Further_reading">Further reading</h2>
<ul><li><cite id="CITEREFAdams1995" class="citation book cs1">Adams, John (1995). <i>Risk</i>. Routledge. ISBN <bdi>978-1-85728-068-5</bdi>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Risk&amp;rft.pub=Routledge&amp;rft.date=1995&amp;rft.isbn=978-1-85728-068-5&amp;rft.aulast=Adams&amp;rft.aufirst=John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li>
<li><cite id="CITEREFWilde1994" class="citation book cs1">Wilde, Gerald J. S. (1994). <i>Target Risk: Dealing with the Danger of Death, Disease and Damage in Everyday Decisions</i>. PDE Publications. ISBN <bdi>978-0-9699124-0-8</bdi>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Target+Risk%3A+Dealing+with+the+Danger+of+Death%2C+Disease+and+Damage+in+Everyday+Decisions&amp;rft.pub=PDE+Publications&amp;rft.date=1994&amp;rft.isbn=978-0-9699124-0-8&amp;rft.aulast=Wilde&amp;rft.aufirst=Gerald+J.+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li>
<li><cite id="CITEREFPeltzman2007" class="citation journal cs1">Peltzman, Sam (2007). "Regulation and the Wealth of Nations: The Connection between Government Regulation and Economic Progress" <span>(PDF)</span>. <i>New Perspectives on Political Economy</i>. <b>3</b> (2): <span>185–</span>204. doi:10.62374/e73dpa44. Archived from the original <span>(PDF)</span> on 18 July 2011.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=New+Perspectives+on+Political+Economy&amp;rft.atitle=Regulation+and+the+Wealth+of+Nations%3A+The+Connection+between+Government+Regulation+and+Economic+Progress&amp;rft.volume=3&amp;rft.issue=2&amp;rft.pages=185-204&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.62374%2Fe73dpa44&amp;rft.aulast=Peltzman&amp;rft.aufirst=Sam&amp;rft_id=http%3A%2F%2Fpcpe.libinst.cz%2Fnppe%2F3_2%2Fnppe3_2_3.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li>
<li><cite id="CITEREFPeltzman2010" class="citation journal cs1">Peltzman, Sam (7 June 2010). "Regulation and the Natural Progress of Opulence". <i>Economic Affairs</i>. <b>30</b> (2): <span>33–</span>39. doi:10.1111/j.1468-0270.2010.02006.x. S2CID 154585032. SSRN 1621983.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Economic+Affairs&amp;rft.atitle=Regulation+and+the+Natural+Progress+of+Opulence&amp;rft.volume=30&amp;rft.issue=2&amp;rft.pages=33-39&amp;rft.date=2010-06-07&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A154585032%23id-name%3DS2CID&amp;rft_id=https%3A%2F%2Fpapers.ssrn.com%2Fsol3%2Fpapers.cfm%3Fabstract_id%3D1621983%23id-name%3DSSRN&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1468-0270.2010.02006.x&amp;rft.aulast=Peltzman&amp;rft.aufirst=Sam&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li>
<li><cite id="CITEREFEcenbarger2009" class="citation news cs1">Ecenbarger, William (April 2009). "Buckle Up Your Seatbelt and Behave". <i>Smithsonian Magazine</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Smithsonian+Magazine&amp;rft.atitle=Buckle+Up+Your+Seatbelt+and+Behave&amp;rft.date=2009-04&amp;rft.aulast=Ecenbarger&amp;rft.aufirst=William&amp;rft_id=https%3A%2F%2Fwww.smithsonianmag.com%2Fscience-nature%2Fbuckle-up-your-seatbelt-and-behave-117182619%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li>
<li><cite id="CITEREFEvans1986" class="citation journal cs1">Evans, Leonard (March 1986). "Risk Homeostasis Theory and Traffic Accident Data". <i>Risk Analysis</i>. <b>6</b> (1): <span>81–</span>94. Bibcode:1986RiskA...6...81E. doi:10.1111/j.1539-6924.1986.tb00196.x. PMID 3602497.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Risk+Analysis&amp;rft.atitle=Risk+Homeostasis+Theory+and+Traffic+Accident+Data&amp;rft.volume=6&amp;rft.issue=1&amp;rft.pages=81-94&amp;rft.date=1986-03&amp;rft_id=info%3Apmid%2F3602497&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1539-6924.1986.tb00196.x&amp;rft_id=info%3Abibcode%2F1986RiskA...6...81E&amp;rft.aulast=Evans&amp;rft.aufirst=Leonard&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li></ul>
<h2 data-mw-anchor="External_links">External links</h2>
<ul><li><cite id="CITEREFEmling2005" class="citation news cs1">Emling, Shelley (13 February 2005). "British planners take to 'naked streets'<span></span>". <i>Times Argus</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Times+Argus&amp;rft.atitle=British+planners+take+to+%27naked+streets%27&amp;rft.date=2005-02-13&amp;rft.aulast=Emling&amp;rft.aufirst=Shelley&amp;rft_id=https%3A%2F%2Fwww.timesargus.com%2Fnews%2Fbritish-planners-take-to-naked-streets%2Farticle_4a511453-7e8f-5b92-98ff-4afc35771c8d.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARisk+compensation"></span></li>
<li>Sam Peltzman on IDEAS at RePEc</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Risk_compensation#Peltzman_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Hyperbolic discounting</h2>
<a href='https://en.wikipedia.org/wiki/Hyperbolic_discounting' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In economics, <b>hyperbolic discounting</b> is a time-<i>inconsistent</i> model of delay discounting. It is one of the cornerstones of behavioral economics and its brain-basis is actively being studied by neuroeconomics researchers.
</p><p>According to the discounted utility approach, intertemporal choices are no different from other choices, except that some consequences are delayed and hence must be anticipated and discounted (i.e., reweighted to take into account the delay).
</p><p>Given two similar rewards, humans show a preference for one that arrives in a more prompt timeframe. Humans are said to <i>discount</i> the value of the later reward, by a factor that increases with the length of the delay. In the financial world, this process is normally modeled in the form of exponential discounting, a time-<i>consistent</i> model of discounting. Many psychological studies have since demonstrated deviations in instinctive preference from the constant discount rate assumed in exponential discounting. Hyperbolic discounting is an alternative mathematical model that agrees more closely with these findings.
</p><p>According to hyperbolic discounting, valuations fall relatively rapidly for earlier delay periods (as in, from now to one week), but then fall more slowly for longer delay periods (for instance, more than a few days). For example, in an early study subjects said they would be indifferent between receiving $15 immediately or $30 after 3 months, $60 after 1 year, or $100 after 3 years. These indifferences reflect annual discount rates that declined from 277% to 139% to 63% as delays got longer.  This contrasts with exponential discounting, in which valuation falls by a constant factor per unit delay and the discount rate stays the same.
</p><p>The standard experiment used to reveal a test subject's hyperbolic discounting curve is to compare short-term preferences with long-term preferences. For instance: "Would you prefer a dollar today or three dollars tomorrow?" or "Would you prefer a dollar in one year or three dollars in one year and one day?" It has been claimed that a significant fraction of subjects will take the lesser amount today, but will gladly wait one extra day in a year in order to receive the higher amount instead.  Individuals with such preferences are described as "present-biased".
</p><p>The most important consequence of hyperbolic discounting is that it creates temporary preferences for small rewards that occur sooner over larger, later ones. Individuals using hyperbolic discounting reveal a strong tendency to make choices that are inconsistent over time – they make choices today that their future self would prefer not to have made, despite knowing the same information. This dynamic inconsistency happens because hyperbolas distort the relative value of options with a fixed difference in delays in proportion to how far the choice-maker is from those options.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Hyperbolic_discounting'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Appeal to novelty</h2>
<a href='https://en.wikipedia.org/wiki/Appeal_to_novelty' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>appeal to novelty</b> (also called <b>appeal to modernity</b> or <i><b>argumentum ad novitatem</b></i>) is a logical fallacy in which one prematurely claims that an idea or proposal is correct or superior, <i>exclusively</i> because it is new and modern. In a controversy between status quo and new inventions, an appeal to novelty argument is not in itself a valid argument. The fallacy may take two forms: overestimating the new and modern, prematurely and without investigation assuming it to be best-case, or underestimating status quo, prematurely and without investigation assuming it to be worst-case.
</p><p>Investigation may prove these claims to be true, but it is a fallacy to prematurely conclude this <i>only from the general claim that all novelty is good</i>. 
</p><p>Chronological snobbery is a form of appeal to novelty, in which one argues that the only relevant knowledge and practices are those established in the last decades. The opposite of an appeal to novelty is an appeal to tradition, in which one argues that the "old ways" are always superior to new ideas.
</p><p>Appeals to novelty are often successful in a modern world where everyone is eager to be on the "cutting edge" of technology. The dot-com bubble of the early 2000s could easily be interpreted as a sign of the dangers of naïvely embracing new ideas without first viewing them with a critical eye. Also, advertisers frequently extoll the newness of their products as a reason to buy.  Conversely, this is satirised by skeptics as bleeding edge technology, which may itself be an example of an appeal to tradition.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Appeal_to_novelty'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Identifiable victim effect</h2>
<a href='https://en.wikipedia.org/wiki/Identifiable_victim_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>identifiable victim effect</b> is the tendency of individuals to offer greater aid when a specific, identifiable person ("victim") is observed under hardship, as compared to a large, vaguely defined group with the same need. 
</p><p>The identifiable victim effect has two components. People are more inclined to help an identified victim than an unidentified one, and people are more inclined to help a single identified victim than a group of identified victims. Although helping an identified victim may be commendable, the identifiable victim effect is considered a cognitive bias. From a consequentialist point of view, the cognitive error is the failure to offer N times as much help to N unidentified victims.
</p><p>The identifiable victim effect has a mirror image that is sometimes called the identifiable perpetrator effect. Research has shown that individuals are more inclined to mete out punishment, even at their own expense, when they are punishing a specific, identified perpetrator.
</p><p>The conceptualization of the identifiable victim effect as it is known today is commonly attributed to American economist Thomas Schelling. He wrote that harm to a particular person invokes “anxiety and sentiment, guilt and awe, responsibility and religion, [but]…most of this awesomeness disappears when we deal with statistical death”.
</p><p>Historical figures from Joseph Stalin to Mother Teresa are credited with statements that epitomize the identifiable victim effect. The remark "One death is a tragedy; a million deaths is a statistic" is widely, although probably incorrectly, attributed to Stalin. The remark "If I look at the mass I will never act. If I look at the one, I will," is attributed to Mother Teresa.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Identifiable_victim_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Sunk cost fallacy</h2>
<a href='https://en.wikipedia.org/wiki/Sunk_cost#Loss_aversion_and_the_sunk_cost_fallacy' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In economics and business decision-making, a <b>sunk cost</b> (also known as <b>retrospective cost</b>) is a cost that has already been incurred and cannot be recovered. Sunk costs are contrasted with <i>prospective costs</i>, which are future costs that may be avoided if action is taken. In other words, a sunk cost is a sum paid in the past that is no longer relevant to decisions about the future. Even though economists argue that sunk costs are no longer relevant to future rational decision-making, people in everyday life often take previous expenditures in situations, such as repairing a car or house, into their future decisions regarding those properties.
</p>

<h2 data-mw-anchor="Bygones_principle">Bygones principle</h2>
<p>According to classical economics and standard microeconomic theory, only prospective (future) costs are relevant to a rational decision. At any moment in time, the best thing to do depends only on <i>current</i> alternatives. The only things that matter are the <i>future</i> consequences. Past mistakes are irrelevant. Any costs incurred prior to making the decision have already been incurred no matter what decision is made. They may be described as "water under the bridge", and making decisions on their basis may be described as "crying over spilt milk". In other words, people should not let sunk costs influence their decisions; sunk costs are irrelevant to rational decisions. Thus, if a new factory was originally projected to cost $100 million, and yield $120 million in value, and after $30 million is spent on it the value projection falls to $65 million, the company should abandon the project rather than spending an additional $70 million to complete it. Conversely, if the value projection falls to $75 million, the company, as a rational actor, should continue the project.  This is known as the <i>bygones principle</i> or the <i>marginal principle</i>.
</p><p>The bygones principle is grounded in the branch of normative decision theory known as <i>rational choice theory</i>, particularly in expected utility hypothesis. Expected utility theory relies on a property known as <i>cancellation</i>, which says that it is rational in decision-making to disregard (cancel) any state of the world that yields the same outcome regardless of one's choice. Past decisions—including sunk costs—meet that criterion.
</p><p>The bygones principle can also be formalised as the notion of "separability". Separability requires agents to take decisions by comparing the available options in eventualities that can still occur, uninfluenced by how the current situation was reached or by eventualities that are precluded by that history. In the language of decision trees, it requires the agent's choice at a particular choice node to be independent of unreachable parts of the tree. This formulation makes clear how central the principle is to standard economic theory by, for example, founding the folding-back algorithm for individual sequential decisions and game-theoretical concepts such as sub-game perfection.
</p><p>Until a decision-maker irreversibly commits resources, the prospective cost is an avoidable future cost and is properly included in any decision-making process. For instance, if someone is considering pre-ordering movie tickets, but has not actually purchased them yet, the cost remains avoidable.
</p><p>Both retrospective and prospective costs could be either fixed costs (continuous for as long as the business is operating and unaffected by output volume) or variable costs (dependent on volume). However, many economists consider it a mistake to classify sunk costs as "fixed" or "variable". For example, if a firm sinks $400 million on an enterprise software installation, that cost is "sunk" because it was a one-time expense and cannot be recovered once spent. A "fixed" cost would be monthly payments made as part of a service contract or licensing deal with the company that set up the software. The upfront irretrievable payment for the installation should <i>not</i> be deemed a "fixed" cost, with its cost spread out over time. Sunk costs should be kept separate. The "variable costs" for this project might include data centre power usage, for example.
</p><p>There are cases in which taking sunk costs into account in decision-making, violating the bygones principle, is rational. For example, for a manager who wishes to be perceived as persevering in the face of adversity, or to avoid blame for earlier mistakes, it may be rational to persist with a project for personal reasons even if it is not the benefit of their company. Or, if they hold private information about the undesirability of abandoning a project, it is fully rational to persist with a project that outsiders think displays the fallacy of sunk cost.
</p>
<h2 data-mw-anchor="Fallacy_effect">Fallacy effect</h2>

<p>The bygones principle does not always accord with real-world behavior. Sunk costs often influence people's decisions, with people believing that investments (i.e., sunk costs) justify further expenditures. People demonstrate "a greater tendency to continue an endeavor once an investment in money, effort, or time has been made". This is the <b>sunk cost fallacy</b>, and such behavior may be described as "throwing good money after bad", while refusing to succumb to what may be described as "cutting one's losses". People can remain in failing relationships because they "have already invested too much to leave". Other people are swayed by arguments that a war must continue because lives will have been sacrificed in vain unless victory is achieved. Individuals caught up in psychologically manipulative scams will continue investing time, money and emotional energy into the project, despite doubts or suspicions that something is not right. These types of behaviour do not seem to accord with rational choice theory and are often classified as behavioural errors.
</p><p>Rego, Arantes, and Magalhães point out that the sunk cost effect exists in committed relationships. They devised two experiments, one of which showed that people in a relationship which they had invested money and effort in were more likely to keep that relationship going than end it; and in the second experiment, while people are in a relationship which they had invested enough time in, they tended to devote more time to the relationship. It also means people fall into the sunk cost fallacy. Although people should ignore sunk costs and make rational decisions when planning for the future, time, money, and effort often make people continue to maintain this relationship, which is equivalent to continuing to invest in failed projects.
</p><p>According to evidence reported by De Bondt and Makhija (1988), managers of many utility companies in the United States have been overly reluctant to terminate economically unviable nuclear plant projects. In the 1960s, the nuclear power industry promised "energy too cheap to meter". Nuclear power lost public support in the 1970s and 1980s, when public service commissions around the nation ordered prudency reviews. From these reviews, De Bondt and Makhija find evidence that the commissions denied many utility companies even partial recovery of nuclear construction costs on the grounds that they had been mismanaging the nuclear construction projects in ways consistent with throwing good money after bad.
</p>

<p>There is also evidence of government representatives failing to ignore sunk costs. The term "Concorde fallacy" derives from the fact that the British and French governments continued to fund the joint development of the costly Concorde supersonic airplane even after it became apparent that there was no longer an economic case for the aircraft. The British government privately regarded the project as a commercial disaster that should never have been started. Political and legal issues made it impossible for either government to pull out.
</p><p>The idea of sunk costs is often employed when analyzing business decisions. A common example of a sunk cost for a business is the promotion of a brand name. This type of marketing incurs costs that cannot normally be recovered. It is not typically possible to later "demote" one's brand names in exchange for cash. A second example is research and development (R&amp;D) costs. Once spent, such costs are sunk and should have no effect on future pricing decisions. A pharmaceutical company's attempt to justify high prices because of the need to recoup R&amp;D expenses would be fallacious. The company would charge a high price whether R&amp;D cost one dollar or one million. R&amp;D costs and the ability to recoup those costs are a factor in deciding whether to spend the money on R&amp;D in the first place.
</p><p>Dijkstra and Hong proposed that part of a person's behavior is influenced by a person's current emotions. Their experiments showed that emotional responses benefit from the sunk cost fallacy. Negative influences lead to the sunk cost fallacy. For example, anxious people face the stress brought about by the sunk cost fallacy. When stressed, they are more motivated to invest in failed projects rather than take additional approaches. Their report shows that the sunk cost fallacy will have a greater impact on people under high load conditions and people's psychological state and external environment will be the key influencing factors.
</p><p>The sunk cost effect may cause cost overrun. In business, an example of sunk costs may be an investment into a factory or research that now has a lower value or none. For example, $20 million has been spent on building a power plant; the value now is zero because it is incomplete (and no sale or recovery is feasible). The plant can be completed for an additional $10 million or abandoned and a different but equally valuable facility built for $5 million. Abandonment and construction of the alternative facility is the more rational decision, even though it represents a total loss of the original expenditure—the original sum invested is a sunk cost. If decision-makers are irrational or have the "wrong" (different) incentives, the completion of the project may be chosen. For example, politicians or managers may have more incentive to avoid the appearance of a total loss. In practice, there is considerable ambiguity and uncertainty in such cases, and decisions may in retrospect appear irrational that were, at the time, reasonable to the economic actors involved and in the context of their incentives. A decision-maker might make rational decisions according to their incentives, outside of efficiency or profitability.  This is considered to be an <i>incentive problem</i> and is distinct from a sunk cost problem. Some research has also noted circumstances where the <i>sunk cost effect</i> is reversed; that is, where individuals appear irrationally eager to write off earlier investments in order to take up a new endeavor.
</p>
<h3 data-mw-anchor="Plan_continuation_bias">Plan continuation bias</h3>
<p>A related phenomenon is plan continuation bias, which is recognised as a subtle cognitive bias that tends to force the continuation of a plan or course of action even in the face of changing conditions. In the field of aerospace it has been recognised as a significant causal factor in accidents, with a 2004 NASA study finding that in 9 out of the 19 accidents studied, aircrew exhibited this behavioural bias.
</p><p>This is a hazard for ships' captains or aircraft pilots who may stick to a planned course even when it is leading to fatal disaster and they should abort instead. A famous example is the Torrey Canyon oil spill in which a tanker ran aground when its captain persisted with a risky course rather than accepting a delay. It has been a factor in numerous air crashes and an analysis of 279 approach and landing accidents (ALAs) found that it was the fourth most common cause, occurring in 11% of cases. Another analysis of 76 accidents found that it was a contributory factor in 42% of cases.
</p><p>There are also two predominant factors that characterise the bias. The first is an overly optimistic estimate of probability of success, possibly to reduce cognitive dissonance having made a decision. The second is that of personal responsibility: when you are personally accountable, it is difficult for you to admit that you were wrong.
</p><p>Projects often suffer cost overruns and delays due to the planning fallacy and related factors including excessive optimism, an unwillingness to admit failure, groupthink and aversion to loss of sunk costs.
</p>
<h2 data-mw-anchor="Psychological_factors">Psychological factors</h2>

<p>Evidence from behavioral economics suggests that there are at least four specific psychological factors underlying the sunk cost effect:
</p>
<ul><li>Framing effects, a cognitive bias where people decide on options based on whether the options are presented with positive or negative connotations; e.g. as a loss or as a gain. People tend to avoid risk when a positive frame is presented but seek risks when a negative frame is presented.</li>
<li>An overoptimistic probability bias, whereby after an investment the evaluation of one's investment-reaping dividends is increased.</li>
<li>The requisite of personal responsibility. Sunk cost appears to operate chiefly in those who feel a personal responsibility for the investments that are to be viewed as a sunk cost.</li>
<li>The desire not to appear wasteful—"One reason why people may wish to throw good money after bad is that to stop investing would constitute an admission that the prior money was wasted."</li></ul>
<p>Taken together, these results suggest that the sunk cost effect may reflect non-standard measures of utility, which is ultimately subjective and unique to the individual.
</p>
<h3 data-mw-anchor="Framing_effect">Framing effect</h3>
<p>The framing effect which underlies the sunk cost effect builds upon the concept of extensionality where the outcome is the same regardless of how the information is framed. This is in contradiction to the concept of intentionality, which is concerned with whether the presentation of information changes the situation in question.
</p><p>Take two mathematical functions:
</p>
<ol><li><span><i>f</i>(<i>x</i>) = 2<i>x</i> + 10</span></li>
<li><span><i>f</i>(<i>x</i>) = 2 · (<i>x</i> + 5)</span></li></ol>
<p>While these functions are framed differently, regardless of the input 'x', the outcome is analytically equivalent. Therefore, if a rational decision maker were to choose between these two functions, the likelihood of each function being chosen should be the same. However, a framing effect places unequal biases towards preferences that are otherwise equal.
</p><p>The most common type of framing effect was theorised in Kahneman &amp; Tversky, 1979 in the form of valence framing effects. This form of framing signifies types of framing. The first type can be considered positive where the 'sure thing' option highlights the positivity whereas if it is negative, the 'sure thing' option highlights the negativity, while both being analytically identical. For example, saving 200 people from a sinking ship of 600 is equivalent to letting 400 people drown. The former framing type is positive and the latter is negative.
</p><p>Ellingsen, Johannesson, Möllerström and Munkammar have categorised framing effects in a social and economic orientation into three broad classes of theories. Firstly, the framing of options presented can affect internalised social norms or social preferences - this is called variable sociality hypothesis. Secondly, the social image hypothesis suggests that the frame in which the options are presented will affect the way the decision maker is viewed and will in turn affect their behaviour. Lastly, the frame may affect the expectations that people have about each other's behaviour and will in turn affect their own behaviour.
</p>
<h3 data-mw-anchor="Overoptimistic_probability_bias">Overoptimistic probability bias</h3>
<p>In 1968, Knox and Inkster approached 141 horse bettors: 72 of the people had just finished placing a $2.00 bet within the past 30 seconds, and 69 people were about to place a $2.00 bet in the next 30 seconds. Their hypothesis was that people who had just committed themselves to a course of action (betting $2.00) would reduce post-decision dissonance by believing more strongly than ever that they had picked a winner. Knox and Inkster asked the bettors to rate their horse's chances of winning on a 7-point scale. What they found was that people who were about to place a bet rated the chance that their horse would win at an average of 3.48 which corresponded to a "fair chance of winning" whereas people who had just finished betting gave an average rating of 4.81 which corresponded to a "good chance of winning". Their hypothesis was confirmed: after making a $2.00 commitment, people became more confident their bet would pay off. Knox and Inkster performed an ancillary test on the patrons of the horses themselves and managed (after normalization) to repeat their finding almost identically. Other researchers have also found evidence of inflated probability estimations.
</p>
<h3 data-mw-anchor="Sense_of_personal_responsibility">Sense of personal responsibility</h3>
<p>In a study of 96 business students, Staw and Fox gave the subjects a choice between making an R&amp;D investment either in an underperforming company department, or in other sections of the hypothetical company. Staw and Fox divided the participants into two groups: a low responsibility condition and a high responsibility condition. In the high responsibility condition, the participants were told that they, as manager, had made an earlier, disappointing R&amp;D investment. In the low responsibility condition, subjects were told that a former manager had made a previous R&amp;D investment in the underperforming division and were given the same profit data as the other group. In both cases, subjects were then asked to make a new $20 million investment. There was a significant interaction between assumed responsibility and average investment, with the high responsibility condition averaging $12.97 million and the low condition averaging $9.43 million. Similar results have been obtained in other studies.
</p>
<h3 data-mw-anchor="Desire_not_to_appear_wasteful">Desire not to appear wasteful</h3>

<p>A ticket buyer who purchases a ticket in advance to an event they eventually turn out not to enjoy makes a semi-public commitment to watching it. To leave early is to make this lapse of judgment manifest to strangers, an appearance they might otherwise choose to avoid. As well, the person may not want to leave the event because they have already paid, so they may feel that leaving would waste their expenditure. Alternatively, they may take a sense of pride in having recognised the opportunity cost of the alternative use of time.
</p>
<h2 data-mw-anchor="Neuroeconomics_&amp;_neuroscience_approaches_to_study_sunk_costs" data-mw-fallback-anchor="Neuroeconomics_.26_neuroscience_approaches_to_study_sunk_costs">Neuroeconomics &amp; neuroscience approaches to study sunk costs</h2>
<p>In recent years, there has been a resurgence in studies of how the brain processes information with respect to sunk costs. Measuring sensitivity to sunk costs in laboratory studies can be challenging, as it is often difficult to disentangle the influence of sunk costs from future returns on investment. In a cross-species study in humans, rats, and mice, Sweis et al discovered a conserved evolutionary history to sensitivity to sunk costs across species. 
</p><p>This has opened up more questions as to what might the evolutionary drivers be behind why the brain is capable of processing information in this way, what utility, if any, sensitivity to sunk costs may confer, and how might distinct circuits in the brain give rise to this sort of valuation depending on the framing of the question, circumstances of the environment, or state of the individual. Ongoing work is characterizing how neurons encode sensitivity to sunk costs, how sunk costs appear only after certain types of choices, and how sunk costs could contribute to mood burden.
</p>
<h2 data-mw-anchor="See_also">See also</h2>


<h2 data-mw-anchor="References">References</h2>

<h2 data-mw-anchor="Further_reading">Further reading</h2>
<ul><li><cite id="CITEREFAmankwah-Amoah2014" class="citation journal cs1">Amankwah-Amoah, J. (2014). "A unified framework of explanations for strategic persistence in the wake of others' failures". <i>Journal of Strategy and Management</i>. <b>7</b> (4): <span>422–</span>444. doi:10.1108/JSMA-01-2014-0009.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Strategy+and+Management&amp;rft.atitle=A+unified+framework+of+explanations+for+strategic+persistence+in+the+wake+of+others%27+failures&amp;rft.volume=7&amp;rft.issue=4&amp;rft.pages=422-444&amp;rft.date=2014&amp;rft_id=info%3Adoi%2F10.1108%2FJSMA-01-2014-0009&amp;rft.aulast=Amankwah-Amoah&amp;rft.aufirst=J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASunk+cost"></span></li>
<li><cite id="CITEREFArkesAyton1999" class="citation journal cs1">Arkes, H.R.; Ayton, P. (1999). "The Sunk Cost and Concorde effects: are humans less rational than lower animals?". <i>Psychological Bulletin</i>. <b>125</b> (5): <span>591–</span>600. doi:10.1037/0033-2909.125.5.591. S2CID 10296273.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Psychological+Bulletin&amp;rft.atitle=The+Sunk+Cost+and+Concorde+effects%3A+are+humans+less+rational+than+lower+animals%3F&amp;rft.volume=125&amp;rft.issue=5&amp;rft.pages=591-600&amp;rft.date=1999&amp;rft_id=info%3Adoi%2F10.1037%2F0033-2909.125.5.591&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A10296273%23id-name%3DS2CID&amp;rft.aulast=Arkes&amp;rft.aufirst=H.R.&amp;rft.au=Ayton%2C+P.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASunk+cost"></span></li>
<li>Bade, Robin; and Michael Parkin. <i>Foundations of Microeconomics.</i> Addison Wesley Paperback 1st Edition: 2001.</li>
<li>Bernheim, D. and Whinston, M. "Microeconomics". McGraw-Hill Irwin, New York, NY, 2008. ISBN 978-0-07-290027-9.</li>
<li><cite id="CITEREFDoody2020" class="citation journal cs1">Doody, Ryan (2020). "The Sunk Cost 'Fallacy' Is Not a Fallacy" <span>(PDF)</span>. <i>Ergo, an Open Access Journal of Philosophy</i>. <b>6</b> (40): <span>1153–</span>1190. doi:<span title="Freely accessible">10.3998/ergo.12405314.0006.040</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Ergo%2C+an+Open+Access+Journal+of+Philosophy&amp;rft.atitle=The+Sunk+Cost+%27Fallacy%27+Is+Not+a+Fallacy&amp;rft.volume=6&amp;rft.issue=40&amp;rft.pages=1153-1190&amp;rft.date=2020&amp;rft_id=info%3Adoi%2F10.3998%2Fergo.12405314.0006.040&amp;rft.aulast=Doody&amp;rft.aufirst=Ryan&amp;rft_id=http%3A%2F%2Frdoody.com%2FSunkCostFallacyIsNotaFallacy.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASunk+cost"></span></li>
<li>Kahneman, D. (2011) <i>Thinking, Fast and Slow</i>, Farrar, Straus and Giroux, ISBN 978-0374275631. (Reviewed by Freeman Dyson in New York Review of Books, 22 December 2011, pp. 40–44.)</li>
<li>Klein, G. and Bauman, Y. The Cartoon Introduction to Economics Volume One: Microeconomics Hill and Wang 2010 ISBN 978-0-8090-9481-3.</li>
<li>Samuelson, Paul; and Nordhaus, William. <i>Economics.</i> McGraw-Hill International Editions: 1989.</li>
<li>Sutton, J. <i>Sunk Costs and Market Structure</i>. The MIT Press, Cambridge, Massachusetts, 1991 ISBN 0-262-19305-1.</li>
<li>Varian, Hal R. <i>Intermediate Microeconomics: A Modern Approach. Fifth Ed.</i> New York, 1999 ISBN 0-393-97830-3.</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Sunk_cost#Loss_aversion_and_the_sunk_cost_fallacy'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Irrational escalation</h2>
<a href='https://en.wikipedia.org/wiki/Escalation_of_commitment' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p><p>
<b>Escalation of commitment</b> is a human behavior pattern in which an individual or group facing increasingly negative outcomes from a decision, action, or investment nevertheless continue the behavior instead of altering course. The actor maintains behaviors that are irrational, but align with previous decisions and actions.
</p><p>Economists and behavioral scientists use a related term, <i>sunk-cost fallacy</i>, to describe the justification of increased investment of money or effort in a decision, based on the cumulative prior investment ("sunk cost") despite new evidence suggesting that the future cost of continuing the behavior outweighs the expected benefit.
</p><p>In sociology, <i>irrational escalation of commitment</i> or <i>commitment bias</i> describe similar behaviors. The phenomenon and the sentiment underlying them are reflected in such proverbial images as "throwing good money after bad", or "In for a penny, in for a pound", or "It's never the wrong time to make the right decision", or "If you find yourself in a hole, stop digging."
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Escalation_of_commitment'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Escalation of commitment</h2>
<a href='https://en.wikipedia.org/wiki/Escalation_of_commitment' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p><p>
<b>Escalation of commitment</b> is a human behavior pattern in which an individual or group facing increasingly negative outcomes from a decision, action, or investment nevertheless continue the behavior instead of altering course. The actor maintains behaviors that are irrational, but align with previous decisions and actions.
</p><p>Economists and behavioral scientists use a related term, <i>sunk-cost fallacy</i>, to describe the justification of increased investment of money or effort in a decision, based on the cumulative prior investment ("sunk cost") despite new evidence suggesting that the future cost of continuing the behavior outweighs the expected benefit.
</p><p>In sociology, <i>irrational escalation of commitment</i> or <i>commitment bias</i> describe similar behaviors. The phenomenon and the sentiment underlying them are reflected in such proverbial images as "throwing good money after bad", or "In for a penny, in for a pound", or "It's never the wrong time to make the right decision", or "If you find yourself in a hole, stop digging."
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Escalation_of_commitment'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Generation effect</h2>
<a href='https://en.wikipedia.org/wiki/Generation_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>generation effect</b> is a phenomenon whereby information is better remembered if it is generated from one's own mind rather than simply read. Researchers have struggled to fully explain why generated information is better recalled than read information, as no single explanation has been comprehensive.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Generation_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Loss aversion</h2>
<a href='https://en.wikipedia.org/wiki/Loss_aversion' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In cognitive science and behavioral economics, <b>loss aversion</b> refers to a cognitive bias in which the same situation is perceived as worse if it is framed as a loss, rather than a gain. It should not be confused with risk aversion, which describes the rational behavior of valuing an uncertain outcome at less than its expected value.
</p><p>When defined in terms of the pseudo-utility function as in cumulative prospect theory (CPT), the left-hand of the function increases much more steeply than gains, thus being more "painful" than the satisfaction from a comparable gain. Empirically, losses tend to be treated as if they were twice as large as an equivalent gain. Loss aversion was first proposed by Amos Tversky and Daniel Kahneman as an important component of prospect theory.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Loss_aversion'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>IKEA effect</h2>
<a href='https://en.wikipedia.org/wiki/IKEA_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>IKEA effect</b> is a cognitive bias in which consumers place a disproportionately high value on products they partially created. The name refers to Swedish manufacturer and furniture retailer IKEA, which sells many items of furniture that require assembly.
</p><p>A 2011 study found that subjects were willing to pay 63% more for furniture they had assembled themselves than for equivalent pre-assembled items.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/IKEA_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Unit bias</h2>
<a href='https://en.wikipedia.org/wiki/List_of_cognitive_biases' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>

<p>Cognitive biases are systematic patterns of deviation from norm and/or rationality in judgment.  They are often studied in psychology, sociology and behavioral economics.
</p><p>Although the reality of most of these biases is confirmed by reproducible research, there are often controversies about how to classify these biases or how to explain them. Several theoretical causes are known for some cognitive biases, which provides a classification of biases by their common generative mechanism (such as noisy information-processing). Gerd Gigerenzer has criticized the framing of cognitive biases as errors in judgment, and favors interpreting them as arising from rational deviations from logical thought.
</p><p>Explanations include information-processing rules (i.e., mental shortcuts), called <i>heuristics</i>, that the brain uses to produce decisions or judgments. Biases have a variety of forms and appear as cognitive ("cold") bias, such as mental noise, or motivational ("hot") bias, such as when beliefs are distorted by wishful thinking. Both effects can be present at the same time.
</p><p>There are also controversies over some of these biases as to whether they count as useless or irrational, or whether they result in useful attitudes or behavior. For example, when getting to know others, people tend to ask leading questions which seem biased towards confirming their assumptions about the person. However, this kind of confirmation bias has also been argued to be an example of social skill; a way to establish a connection with the other person.
</p><p>Although this research overwhelmingly involves human subjects, some studies have found bias in non-human animals as well. For example, loss aversion has been shown in monkeys and hyperbolic discounting has been observed in rats, pigeons, and monkeys.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/List_of_cognitive_biases'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Zero–risk bias</h2>
<a href='https://en.wikipedia.org/wiki/Zero-risk_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Zero-risk bias</b> is a tendency to prefer the complete elimination of risk in a sub-part over alternatives with greater <i>overall</i> risk reduction. It often manifests in cases where decision makers address problems concerning health, safety, and the environment. Its effect on decision making has been observed in surveys presenting hypothetical scenarios.
</p>
</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Zero-risk_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Disposition effect</h2>
<a href='https://en.wikipedia.org/wiki/Disposition_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>disposition effect</b> is an anomaly discovered in behavioral finance. It relates to the tendency of investors to sell assets that have increased in value, while keeping assets that have dropped in value.
</p><p>Hersh Shefrin and Meir Statman identified and named the effect in their 1985 paper, which found that people dislike losing significantly more than they enjoy winning. The disposition effect has been described as one of the foremost vigorous actualities around individual investors because investors will hold stocks that have lost value yet sell stocks that have gained value."
</p><p>In 1979, Daniel Kahneman and Amos Tversky traced the cause of the disposition effect to the so-called "prospect theory". The prospect theory proposes that when an individual is presented with two equal choices, one having possible gains and the other with possible losses, the individual is more likely to opt for the former choice even though both would yield the same economic result.
</p><p>The disposition effect can be minimized by a mental approach called hedonic framing, which refers to a concept in behavioral finance and psychology where people perceive and react differently to gains and losses based on how they are presented or "framed." For example, individuals might feel better about a net positive outcome if multiple smaller gains are presented separately rather than as one large gain, or they might prefer to combine losses to reduce the psychological impact.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Disposition_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Pseudocertainty effect</h2>
<a href='https://en.wikipedia.org/wiki/Pseudocertainty_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In prospect theory, the <b>pseudocertainty effect</b> is the tendency for people to perceive an outcome as certain while it is actually uncertain in multi-stage decision making. The evaluation of the certainty of the outcome in a previous stage of decisions is disregarded when selecting an option in subsequent stages. Not to be confused with certainty effect, the pseudocertainty effect was discovered from an attempt at providing a normative use of decision theory for the certainty effect by relaxing the cancellation rule.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Pseudocertainty_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Processing difficulty effect</h2>
<a href='https://en.wikipedia.org/wiki/List_of_cognitive_biases#Processing_difficulty_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>

<p>Cognitive biases are systematic patterns of deviation from norm and/or rationality in judgment.  They are often studied in psychology, sociology and behavioral economics.
</p><p>Although the reality of most of these biases is confirmed by reproducible research, there are often controversies about how to classify these biases or how to explain them. Several theoretical causes are known for some cognitive biases, which provides a classification of biases by their common generative mechanism (such as noisy information-processing). Gerd Gigerenzer has criticized the framing of cognitive biases as errors in judgment, and favors interpreting them as arising from rational deviations from logical thought.
</p><p>Explanations include information-processing rules (i.e., mental shortcuts), called <i>heuristics</i>, that the brain uses to produce decisions or judgments. Biases have a variety of forms and appear as cognitive ("cold") bias, such as mental noise, or motivational ("hot") bias, such as when beliefs are distorted by wishful thinking. Both effects can be present at the same time.
</p><p>There are also controversies over some of these biases as to whether they count as useless or irrational, or whether they result in useful attitudes or behavior. For example, when getting to know others, people tend to ask leading questions which seem biased towards confirming their assumptions about the person. However, this kind of confirmation bias has also been argued to be an example of social skill; a way to establish a connection with the other person.
</p><p>Although this research overwhelmingly involves human subjects, some studies have found bias in non-human animals as well. For example, loss aversion has been shown in monkeys and hyperbolic discounting has been observed in rats, pigeons, and monkeys.
</p>

<h2 data-mw-anchor="Belief,_decision-making_and_behavioral" data-mw-fallback-anchor="Belief.2C_decision-making_and_behavioral">Belief, decision-making and behavioral</h2>
<p>These biases affect belief formation, reasoning processes, business and economic decisions, and human behavior in general.
</p>
<h3 data-mw-anchor="Anchoring_bias">Anchoring bias</h3>

<p>The anchoring bias, or focalism, is the tendency to rely too heavily—to "anchor"—on one trait or piece of information when making decisions (usually the first piece of information acquired on that subject).
Anchoring bias includes or involves the following:
</p>
<ul><li>Common source bias, the tendency to combine or compare research studies from the same source, or from sources that use the same methodologies or data.</li>
<li>Conservatism bias, the tendency to insufficiently revise one's belief when presented with new evidence.</li>
<li>Functional fixedness, a tendency limiting a person to using an object only in the way it is traditionally used.</li>
<li>Law of the instrument, an over-reliance on a familiar tool or methods, ignoring or under-valuing alternative approaches. "If all you have is a hammer, everything looks like a nail."</li></ul>
<h3 data-mw-anchor="Apophenia">Apophenia</h3>

<p>The tendency to perceive meaningful connections between unrelated things.
The following are types of apophenia:
</p>
<ul><li>Clustering illusion, the tendency to overestimate the importance of small runs, streaks, or clusters in large samples of random data (that is, seeing phantom patterns).</li>
<li>Illusory correlation, a tendency to inaccurately perceive a relationship between two unrelated events.</li>
<li>Pareidolia, a tendency to perceive a vague and random stimulus (often an image or sound) as significant, e.g., seeing images of animals or faces in clouds, the man in the Moon, and hearing non-existent hidden messages on records played in reverse.</li></ul>
<h3 data-mw-anchor="Availability_heuristic">Availability heuristic</h3>

<p>The availability heuristic (also known as the availability bias) is the tendency to overestimate the likelihood of events with greater "availability" in memory, which can be influenced by how recent the memories are or how unusual or emotionally charged they may be. The availability heuristic includes or involves the following:
</p>
<ul><li>Anthropocentric thinking, the tendency to use human analogies as a basis for reasoning about other, less familiar, biological phenomena.</li>
<li>Anthropomorphism is characterization of animals, objects, and abstract concepts as possessing human traits, emotions, or intentions. The opposite bias, of not attributing feelings or thoughts to another person, is dehumanised perception, a type of objectification.</li>
<li>Attentional bias, the tendency of perception to be affected by recurring thoughts.</li>
<li>Frequency illusion or Baader–Meinhof phenomenon. The frequency illusion is that once something has been noticed then every instance of that thing is noticed, leading to the belief it has a high frequency of occurrence (a form of selection bias). The Baader–Meinhof phenomenon is the illusion where something that has recently come to one's attention suddenly seems to appear with improbable frequency shortly afterwards. It was named after an incidence of frequency illusion in which the Baader–Meinhof Group was mentioned.</li>
<li>Implicit association, where the speed with which people can match words depends on how closely they are associated.</li>
<li>Salience bias, the tendency to focus on items that are more prominent or emotionally striking and ignore those that are unremarkable, even though this difference is often irrelevant by objective standards. See also von Restorff effect.</li>
<li>Selection bias, which happens when the members of a statistical sample are not chosen completely at random, which leads to the sample not being representative of the population.</li>
<li>Survivorship bias, which is concentrating on the people or things that "survived" some process and inadvertently overlooking those that did not because of their lack of visibility.</li>
<li>Quantification bias, the tendency to ascribe more weight to measured/quantified metrics than to unquantifiable values. See also: McNamara fallacy.</li>
<li>Well travelled road effect, the tendency to underestimate the duration taken to traverse oft-travelled routes and overestimate the duration taken to traverse less familiar routes.</li></ul>
<h3 data-mw-anchor="Cognitive_dissonance">Cognitive dissonance</h3>

<p>Cognitive dissonance is the perception of contradictory information and the mental toll of it.
</p>
<ul><li>Normalcy bias, a form of cognitive dissonance, is the refusal to plan for, or react to, a disaster which has never happened before.</li>
<li>Effort justification is a person's tendency to attribute greater value to an outcome if they had to put effort into achieving it. This can result in more value being applied to an outcome than it actually has. An example of this is the IKEA effect, the tendency for people to place a disproportionately high value on objects that they partially assembled themselves, such as furniture from IKEA, regardless of the quality of the end product.</li>
<li>Ben Franklin effect, where a person who has performed a favor for someone is more likely to do another favor for that person than they would be if they had <i>received</i> a favor from that person.</li></ul>
<h3 data-mw-anchor="Confirmation_bias">Confirmation bias</h3>

<p>Confirmation bias is the tendency to search for, interpret, focus on and remember information in a way that confirms one's preconceptions. There are multiple other cognitive biases which involve or are types of confirmation bias:
</p>
<ul><li>Backfire effect, a tendency to react to disconfirming evidence by strengthening one's previous beliefs.</li>
<li>Congruence bias, the tendency to test hypotheses exclusively through direct testing, instead of testing possible alternative hypotheses.</li>
<li>Experimenter's or expectation bias, the tendency for experimenters to believe, certify, and publish data that agree with their expectations for the outcome of an experiment, and to disbelieve, discard, or downgrade the corresponding weightings for data that appear to conflict with those expectations.</li>
<li>Observer-expectancy effect, when a researcher expects a given result and therefore unconsciously manipulates an experiment or misinterprets data in order to find it (see also subject-expectancy effect).</li>
<li>Selective perception, the tendency for expectations to affect perception.</li>
<li>Semmelweis reflex, the tendency to reject new evidence that contradicts a paradigm.</li></ul>
<h3 data-mw-anchor="Egocentric_bias">Egocentric bias</h3>

<p>Egocentric bias is the tendency to rely too heavily on one's own perspective and/or have a different perception of oneself relative to others. The following are forms of egocentric bias:
</p>
<ul><li>Bias blind spot, the tendency to see oneself as less biased than other people, or to be able to identify more cognitive biases in others than in oneself.</li>
<li>False consensus effect, the tendency for people to overestimate the degree to which others agree with them.</li>
<li>False uniqueness bias, the tendency of people to see their projects and themselves as more singular than they actually are.</li>
<li>Forer effect or Barnum effect, the tendency for individuals to give high accuracy ratings to descriptions of their personality that supposedly are tailored specifically for them, but are in fact vague and general enough to apply to a wide range of people. This effect can provide a partial explanation for the widespread acceptance of some beliefs and practices, such as astrology, fortune telling, graphology, and some types of personality tests.</li>
<li>Illusion of asymmetric insight, where people perceive their knowledge of their peers to surpass their peers' knowledge of them.</li>
<li>Illusion of control, the tendency to overestimate one's degree of influence over other external events.</li>
<li>Illusion of transparency, the tendency for people to overestimate the degree to which their personal mental state is known by others, and to overestimate how well they understand others' personal mental states.</li>
<li>Illusion of validity, the tendency to overestimate the accuracy of one's judgments, especially when available information is consistent or inter-correlated.</li>
<li>Illusory superiority, the tendency to overestimate one's desirable qualities, and underestimate undesirable qualities, relative to other people. (Also known as "Lake Wobegon effect", "better-than-average effect", or "superiority bias".)</li>
<li>Naïve cynicism, expecting more egocentric bias in others than in oneself.</li>
<li>Naïve realism, the belief that we see reality as it really is—objectively and without bias; that the facts are plain for all to see; that rational people will agree with us; and that those who do not are either uninformed, lazy, irrational, or biased.</li>
<li>Overconfidence effect, a tendency to have excessive confidence in one's own answers to questions. For example, for certain types of questions, answers that people rate as "99% certain" turn out to be wrong 40% of the time.</li>
<li>Planning fallacy, the tendency for people to underestimate the time it will take them to complete a given task.</li>
<li>Restraint bias, the tendency to overestimate one's ability to show restraint in the face of temptation.</li>
<li>Trait ascription bias, the tendency for people to view themselves as relatively variable in terms of personality, behavior, and mood while viewing others as much more predictable.</li>
<li>Third-person effect, a tendency to believe that mass-communicated media messages have a greater effect on others than on themselves.</li></ul>
<h3 data-mw-anchor="Extension_neglect">Extension neglect</h3>

<p>Extension neglect occurs where the quantity of the sample size is not sufficiently taken into consideration when assessing the outcome, relevance or judgement. The following are forms of extension neglect:
</p>
<ul><li>Base rate fallacy or base rate neglect, the tendency to ignore general information and focus on information only pertaining to the specific case, even when the general information is more important.</li>
<li>Compassion fade, the tendency to behave more compassionately towards a small number of identifiable victims than to a large number of anonymous ones.</li>
<li>Conjunction fallacy, the tendency to assume that specific conditions are more probable than a more general version of those same conditions.</li>
<li>Duration neglect, the neglect of the duration of an episode in determining its value.</li>
<li>Hyperbolic discounting, where discounting is the tendency for people to have a stronger preference for more immediate payoffs relative to later payoffs. Hyperbolic discounting leads to choices that are inconsistent over time—people make choices today that their future selves would prefer not to have made, despite using the same reasoning. Also known as current moment bias or present bias, and related to Dynamic inconsistency. A good example of this is a study showed that when making food choices for the coming week, 74% of participants chose fruit, whereas when the food choice was for the current day, 70% chose chocolate.</li>
<li>Insensitivity to sample size, the tendency to under-expect variation in small samples.</li>
<li>Less-is-better effect, the tendency to prefer a smaller set to a larger set judged separately, but not jointly.</li>
<li>Neglect of probability, the tendency to completely disregard probability when making a decision under uncertainty.</li>
<li>Scope neglect or scope insensitivity, the tendency to be insensitive to the size of a problem when evaluating it. For example, being willing to pay as much to save 2,000 children or 20,000 children.</li>
<li>Zero-risk bias, the preference for reducing a small risk to zero over a greater reduction in a larger risk.</li></ul>
<h3 data-mw-anchor="False_priors">False priors</h3>

<p>False priors are initial beliefs and knowledge which interfere with the unbiased evaluation of factual evidence and lead to incorrect conclusions. Biases based on false priors include:
</p>
<ul><li>Agent detection bias, the inclination to presume the purposeful intervention of a sentient or intelligent agent.</li>
<li>Automation bias, the tendency to depend excessively on automated systems which can lead to erroneous automated information overriding correct decisions.</li>
<li>Gender bias, a widespread set of implicit biases that discriminate against a gender. For example, the assumption that women are less suited to jobs requiring high intellectual ability. Or the assumption that people or animals are male in the absence of any indicators of gender.</li>
<li>Sexual overperception bias, the tendency to overestimate sexual interest of another person in oneself, and sexual underperception bias, the tendency to underestimate it.</li>
<li>Stereotyping, expecting a member of a group to have certain characteristics without having actual information about that individual.</li></ul>
<h3 data-mw-anchor="Framing_effect">Framing effect</h3>

<p>The framing effect is the tendency to draw different conclusions from the same information, depending on how that information is presented. Forms of the framing effect include:
</p>
<ul><li>Contrast effect, the enhancement or reduction of a certain stimulus's perception when compared with a recently observed, contrasting object.</li>
<li>Decoy effect, where preferences for either option A or B change in favor of option B when option C is presented, which is completely dominated by option B (inferior in all respects) and partially dominated by option A.</li>
<li>Default effect, the tendency to favor the default option when given a choice between several options.</li>
<li>Denomination effect, the tendency to spend more money when it is denominated in small amounts (e.g., coins) rather than large amounts (e.g., bills).</li>
<li>Distinction bias, the tendency to view two options as more dissimilar when evaluating them simultaneously than when evaluating them separately.</li>
<li>Domain neglect bias, the tendency to neglect relevant domain knowledge while solving interdisciplinary problems.</li>
<li>Context neglect bias, the tendency to neglect the human context of technological challenges.</li></ul>
<h3 data-mw-anchor="Logical_fallacy">Logical fallacy</h3>

<ul><li>Berkson's paradox, the tendency to misinterpret statistical experiments involving conditional probabilities.</li>
<li>Escalation of commitment, irrational escalation, or sunk cost fallacy, where people justify increased investment in a decision, based on the cumulative prior investment, despite new evidence suggesting that the decision was probably wrong.</li>
<li>G. I. Joe fallacy, the tendency to think that knowing about cognitive bias is enough to overcome it.</li>
<li>Gambler's fallacy, the tendency to think that future probabilities are altered by past events, when in reality they are unchanged. The fallacy arises from an erroneous conceptualization of the law of large numbers. For example, "I've flipped heads with this coin five times consecutively, so the chance of tails coming out on the sixth flip is much greater than heads."</li>
<li>Hot-hand fallacy (also known as "hot hand phenomenon" or "hot hand"), the belief that a person who has experienced success with a random event has a greater chance of further success in additional attempts.</li>
<li>Plan continuation bias, failure to recognize that the original plan of action is no longer appropriate for a changing situation or for a situation that is different from anticipated.</li>
<li>Subadditivity effect, the tendency to judge the probability of the whole to be less than the probabilities of the parts.</li>
<li>Time-saving bias, a tendency to underestimate the time that could be saved (or lost) when increasing (or decreasing) from a relatively low speed, and to overestimate the time that could be saved (or lost) when increasing (or decreasing) from a relatively high speed.</li>
<li>Zero-sum bias, where a situation is incorrectly perceived to be like a zero-sum game (i.e., to be a situation whereby one person gains at the expense of another).</li></ul>
<h3 data-mw-anchor="Prospect_theory">Prospect theory</h3>


<p>The following relate to prospect theory:
</p>
<ul><li>Ambiguity effect, the tendency to avoid options for which the probability of a favorable outcome is unknown.</li>
<li>Disposition effect, the tendency to sell an asset that has accumulated in value and resist selling an asset that has declined in value.</li>
<li>Dread aversion, just as losses yield double the emotional impact of gains, dread yields double the emotional impact of savouring.</li>
<li>Endowment effect, the tendency for people to demand much more to give up an object than they would be willing to pay to acquire it.</li>
<li>Loss aversion, where the perceived disutility of giving up an object is greater than the utility associated with acquiring it. (see also Sunk cost fallacy)</li>
<li>Pseudocertainty effect, the tendency to make risk-averse choices if the expected outcome is positive, but make risk-seeking choices to avoid negative outcomes.</li>
<li>Status quo bias, the tendency to prefer things to stay relatively the same.</li>
<li>System justification, the tendency to defend and bolster the status quo. Existing social, economic, and political arrangements tend to be preferred, and alternatives disparaged, sometimes even at the expense of individual and collective self-interest.</li></ul>
<h3 data-mw-anchor="Self-assessment">Self-assessment</h3>
<ul><li>Dunning–Kruger effect, the tendency for unskilled individuals to overestimate their own ability and the tendency for experts to underestimate their own ability.</li>
<li>Hot-cold empathy gap, the tendency to underestimate the influence of visceral drives on one's attitudes, preferences, and behaviors.</li>
<li>Hard–easy effect, the tendency to overestimate one's ability to accomplish hard tasks, and underestimate one's ability to accomplish easy tasks.</li>
<li>Illusion of explanatory depth, the tendency to believe that one understands a topic much better than one actually does. The effect is strongest for explanatory knowledge, whereas people tend to be better at self-assessments for procedural, narrative, or factual knowledge.</li>
<li>Impostor Syndrome, a psychological occurrence in which an individual doubts their skills, talents, or accomplishments and has a persistent internalized fear of being exposed as a fraud.  Also known as impostor phenomenon.</li>
<li>Objectivity illusion, the phenomena where people tend to believe that they are more objective and unbiased than others. This bias can apply to itself – where people are able to see when others are affected by the objectivity illusion, but unable to see it in themselves. See also <i>bias blind spot.</i></li></ul>
<h3 data-mw-anchor="Truth_judgment">Truth judgment</h3>
<ul><li>Belief bias, an effect where someone's evaluation of the logical strength of an argument is biased by the believability of the conclusion.</li>
<li>Illusory truth effect, the tendency to believe that a statement is true if it is easier to process, or if it has been stated multiple times, regardless of its actual veracity. These are specific cases of truthiness.</li>
<li>Rhyme as reason effect, where rhyming statements are perceived as more truthful.</li>
<li>Subjective validation, where statements are perceived as true if a subject's belief demands it to be true. Also assigns perceived connections between coincidences. (Compare confirmation bias.)</li></ul>
<h3 data-mw-anchor="Other">Other</h3>

<h3 data-mw-anchor="Social">Social</h3>
<h4 data-mw-anchor="Association_fallacy">Association fallacy</h4>

<p>Association fallacies include:
</p>
<ul><li>Authority bias, the tendency to attribute greater accuracy to the opinion of an authority figure (unrelated to its content) and be more influenced by that opinion.</li>
<li>Cheerleader effect, the tendency for people to appear more attractive in a group than in isolation.</li>
<li>Halo effect, the tendency for a person's positive or negative traits to "spill over" from one personality area to another in others' perceptions of them (see also physical attractiveness stereotype).</li></ul>
<h4 data-mw-anchor="Attribution_bias">Attribution bias</h4>

<p>Attribution bias includes:
</p>
<ul><li>Actor-observer bias, the tendency for explanations of other individuals' behaviors to overemphasize the influence of their personality and underemphasize the influence of their situation (see also Fundamental attribution error), and for explanations of one's own behaviors to do the opposite (that is, to overemphasize the influence of our situation and underemphasize the influence of our own personality).</li>
<li>Defensive attribution hypothesis, a tendency to attribute more blame to a harm-doer as the outcome becomes more severe or as personal or situational similarity to the victim decreases.</li>
<li>Extrinsic incentives bias, an exception to the <i>fundamental attribution error</i>, where people view others as having (situational) extrinsic motivations and (dispositional) intrinsic motivations for oneself</li>
<li>Fundamental attribution error, the tendency for people to overemphasize personality-based explanations for behaviors observed in others while under-emphasizing the role and power of situational influences on the same behavior (see also actor-observer bias, group attribution error, positivity effect, and negativity effect).</li>
<li>Group attribution error, the biased belief that the characteristics of an individual group member are reflective of the group as a whole or the tendency to assume that group decision outcomes reflect the preferences of group members, even when information is available that clearly suggests otherwise.</li>
<li>Hostile attribution bias, the tendency to interpret others' behaviors as having hostile intent, even when the behavior is ambiguous or benign.</li>
<li>Intentionality bias, the tendency to judge human action to be intentional rather than accidental.</li>
<li>Just-world fallacy, the tendency for people to want to believe that the world is fundamentally just, causing them to rationalize an otherwise inexplicable injustice as deserved by the victim(s).</li>
<li>Moral luck, the tendency for people to ascribe greater or lesser moral standing based on the outcome of an event.</li>
<li>Puritanical bias, the tendency to attribute cause of an undesirable outcome or wrongdoing by an individual to a moral deficiency or lack of self-control rather than taking into account the impact of broader societal determinants .</li>
<li>Self-serving bias, the tendency to claim more responsibility for successes than failures. It may also manifest itself as a tendency for people to evaluate ambiguous information in a way beneficial to their interests (see also group-serving bias).</li>
<li>Ultimate attribution error, similar to the fundamental attribution error, in this error a person is likely to make an internal attribution to an entire group instead of the individuals within the group.</li></ul>
<h4 data-mw-anchor="Conformity">Conformity</h4>

<p>Conformity is involved in the following:
</p>
<ul><li>Availability cascade, a self-reinforcing process in which a collective belief gains more and more plausibility through its increasing repetition in public discourse (or "repeat something long enough and it will become true"). See also availability heuristic.</li>
<li>Bandwagon effect, the tendency to do (or believe) things because many other people do (or believe) the same. Related to groupthink and herd behavior.</li>
<li><span><span id="Courtesy_bias"></span><span>Courtesy bias</span></span>, the tendency to give an opinion that is more socially correct than one's true opinion, so as to avoid offending anyone.</li>
<li>Groupthink, the psychological phenomenon that occurs within a group of people in which the desire for harmony or conformity in the group results in an irrational or dysfunctional decision-making outcome. Group members try to minimize conflict and reach a consensus decision without critical evaluation of alternative viewpoints by actively suppressing dissenting viewpoints, and by isolating themselves from outside influences.</li>
<li>Groupshift, the tendency for decisions to be more risk-seeking or risk-averse than the group as a whole, if the group is already biased in that direction</li>
<li>Social desirability bias, the tendency to over-report socially desirable characteristics or behaviours in oneself and under-report socially undesirable characteristics or behaviours. See also: § Courtesy bias.</li>
<li>Truth bias is people's inclination towards believing, to some degree, the communication of another person, regardless of whether or not that person is actually lying or being untruthful.</li></ul>
<h4 data-mw-anchor="Ingroup_bias">Ingroup bias</h4>

<p>Ingroup bias is the tendency for people to give preferential treatment to others they perceive to be members of their own groups. It is related to the following:
</p>
<ul><li>Not invented here, an aversion to contact with or use of products, research, standards, or knowledge developed outside a group.</li>
<li>Outgroup homogeneity bias, where individuals see members of other groups as being relatively less varied than members of their own group.</li></ul>
<h4 data-mw-anchor="Other_social_biases">Other social biases</h4>

<h2 data-mw-anchor="Memory">Memory <span id="Memory_biases"></span></h2>
<p>In psychology and cognitive science, a memory bias is a cognitive bias that either enhances or impairs the recall of a memory (either the chances that the memory will be recalled at all, or the amount of time it takes for it to be recalled, or both), or that alters the content of a reported memory. There are many types of memory bias, including:
</p>
<h3 data-mw-anchor="Misattribution_of_memory">Misattribution of memory</h3>


<p>The misattributions include:
</p>
<ul><li>Cryptomnesia, where a memory is mistaken for novel thought or imagination, because there is no subjective experience of it being a memory.</li>
<li>False memory, where imagination is mistaken for a memory.</li>
<li>Social cryptomnesia, a failure by people and society in general to remember the origin of a change, in which people know that a change has occurred in society, but forget how this change occurred; that is, the steps that were taken to bring this change about, and who took these steps. This has led to reduced social credit towards the minorities who made major sacrifices that led to a change in societal values.</li>
<li>Source confusion, episodic memories are confused with other information, creating distorted memories.</li>
<li>Suggestibility, where ideas suggested by a questioner are mistaken for memory.</li>
<li>The Perky effect, where real images can influence imagined images, or be misremembered as imagined rather than real</li></ul>
<h3 data-mw-anchor="Other_memory_biases">Other memory biases</h3>

<h2 data-mw-anchor="See_also">See also</h2>


<h2 data-mw-anchor="Footnotes">Footnotes</h2>

<h2 data-mw-anchor="References">References</h2>

<h2 data-mw-anchor="Further_reading">Further reading</h2>

<h2 data-mw-anchor="External_links">External links</h2>
<ul><li><span typeof="mw:File"></span> Media related to Memory biases at Wikimedia Commons</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/List_of_cognitive_biases#Processing_difficulty_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Endowment effect</h2>
<a href='https://en.wikipedia.org/wiki/Endowment_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In psychology and behavioral economics, the <b>endowment effect</b>, also known as <b>divestiture aversion</b>, is the finding that people are more likely to retain an object they own than acquire that same object when they do not own it. The endowment theory can be defined as "an application of prospect theory positing that loss aversion associated with ownership explains observed exchange asymmetries."
</p><p>This is typically illustrated in two ways. In a valuation paradigm, people's maximum willingness to pay (WTP) to acquire an object is typically lower than the least amount they are willing to accept (WTA) to give up that same object when they own it—even when there is no cause for attachment, or even if the item was only obtained minutes ago. In an exchange paradigm, people given a good are reluctant to trade it for another good of similar value. For example, participants first given a pen of equal expected value to that of a coffee mug were generally unwilling to trade, whilst participants first given the coffee mug were also unwilling to trade it for the pen.
</p><p>A more controversial third paradigm used to elicit the endowment effect is the mere ownership paradigm, primarily used in experiments in psychology, marketing, and organizational behavior. In this paradigm, people who are randomly assigned to receive a good ("owners") evaluate it more positively than people who are not randomly assigned to receive the good ("controls"). The distinction between this paradigm and the first two is that it is not incentive-compatible. In other words, participants are not explicitly incentivized to reveal the extent to which they truly like or value the good.
</p><p>The endowment effect can be equated to the behavioural model willingness to accept or pay (WTAP), a formula sometimes used to find out how much a consumer or person is willing to put up with or lose for different outcomes. However, this model has come under recent criticism as potentially inaccurate.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Endowment_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Backfire effect</h2>
<a href='https://en.wikipedia.org/wiki/Confirmation_bias#backfire_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>

<b>Confirmation bias</b> (also <b>confirmatory bias</b>, <b>myside bias</b> or <b>congeniality bias</b>) is the tendency to search for, interpret, favor and recall information in a way that confirms or supports one's prior beliefs or values. People display this bias when they select information that supports their views, ignoring contrary information or when they interpret ambiguous evidence as supporting their existing attitudes. The effect is strongest for desired outcomes, for emotionally charged issues and for deeply entrenched beliefs.
</p><p>Biased search for information, biased interpretation of this information and biased memory recall, have been invoked to explain four specific effects:
</p>
<ol><li><i>attitude polarization</i> (when a disagreement becomes more extreme even though the different parties are exposed to the same evidence)</li>
<li><i>belief perseverance</i> (when beliefs persist after the evidence for them is shown to be false)</li>
<li>the <i>irrational primacy effect</i> (a greater reliance on information encountered early in a series)</li>
<li><i>illusory correlation</i> (when people falsely perceive an association between two events or situations).</li></ol>
<p>A series of psychological experiments in the 1960s suggested that people are biased toward confirming their existing beliefs. Later work re-interpreted these results as a tendency to test ideas in a one-sided way, focusing on one possibility and ignoring alternatives. Explanations for the observed biases include wishful thinking and the limited human capacity to process information. Another proposal is that people show confirmation bias because they are pragmatically assessing the costs of being wrong rather than investigating in a neutral, scientific way.
</p><p>Flawed decisions due to confirmation bias have been found in a wide range of political, organizational, financial and scientific contexts. These biases contribute to overconfidence in personal beliefs and can maintain or strengthen beliefs in the face of contrary evidence. For example, confirmation bias produces systematic errors in scientific research based on inductive reasoning (the gradual accumulation of supportive evidence). Similarly, a police detective may identify a suspect early in an investigation but then may only seek confirming rather than disconfirming evidence. A medical practitioner may prematurely focus on a particular disorder early in a diagnostic session and then seek only confirming evidence. In social media, confirmation bias is amplified by the use of filter bubbles, or "algorithmic editing", which display to individuals only information they are likely to agree with, while excluding opposing views.
</p>

<h2 data-mw-anchor="Definition_and_context">Definition and context</h2>
<p>Confirmation bias, previously used as a "catch-all phrase", was refined by English psychologist Peter Wason, as "a preference for information that is consistent with a hypothesis rather than information which opposes it."
</p><p>Confirmation biases are effects in information processing. They differ from what is sometimes called the <i>behavioral confirmation effect</i>, commonly known as <i>self-fulfilling prophecy</i>, in which a person's expectations influence their own behavior, bringing about the expected result.
</p><p>Some psychologists restrict the term "confirmation bias" to selective collection of evidence that supports what one already believes while ignoring or rejecting evidence that supports a different conclusion. Others apply the term more broadly to the tendency to preserve one's existing beliefs when searching for evidence, interpreting it, or recalling it from memory. Confirmation bias is a result of automatic, unintentional strategies rather than deliberate deception.
</p>
<h2 data-mw-anchor="Types">Types</h2>
<h3 data-mw-anchor="Biased_search_for_information">Biased search for information</h3>

<p>Experiments have found repeatedly that people tend to test hypotheses in a one-sided way, by searching for evidence consistent with their current hypothesis.<sup class="reference nowrap"><span title="Page / location: 177–178">: 177–178 </span></sup> Rather than searching through all the relevant evidence, they phrase questions to receive an affirmative answer that supports their theory. They look for the consequences that they would expect if their hypothesis was true, rather than what would happen if it was false. For example, someone using yes/no questions to find a number they suspect to be the number 3 might ask, "Is it an odd number?" People prefer this type of question, called a "positive test", even when a negative test such as "Is it an even number?" would yield exactly the same information. However, this does not mean that people seek tests that guarantee a positive answer. In studies where subjects could select either such pseudo-tests or genuinely diagnostic ones, they favored the genuinely diagnostic.
</p><p>The preference for positive tests in itself is not a bias, since positive tests can be highly informative. However, in combination with other effects, this strategy can confirm existing beliefs or assumptions, independently of whether they are true. In real-world situations, evidence is often complex and mixed. For example, various contradictory ideas about someone could each be supported by concentrating on one aspect of his or her behavior. Thus any search for evidence in favor of a hypothesis is likely to succeed. One illustration of this is the way the phrasing of a question can significantly change the answer. For example, people who are asked, "Are you happy with your social life?" report greater satisfaction than those asked, "Are you <i>un</i>happy with your social life?"
</p><p>Even a small change in a question's wording can affect how people search through available information, and hence the conclusions they reach. This was shown using a fictional child custody case. Participants read that Parent A was moderately suitable to be the guardian in multiple ways. Parent B had a mix of salient positive and negative qualities: a close relationship with the child but a job that would take them away for long periods of time. When asked, "Which parent should have custody of the child?" the majority of participants chose Parent B, looking mainly for positive attributes. However, when asked, "Which parent should be denied custody of the child?" they looked for negative attributes and the majority answered that Parent B should be denied custody, implying that Parent A should have custody.
</p><p>Similar studies have demonstrated how people engage in a biased search for information, but also that this phenomenon may be limited by a preference for genuine diagnostic tests. In an initial experiment, participants rated another person on the introversion–extroversion personality dimension on the basis of an interview. They chose the interview questions from a given list. When the interviewee was introduced as an introvert, the participants chose questions that presumed introversion, such as, "What do you find unpleasant about noisy parties?" When the interviewee was described as extroverted, almost all the questions presumed extroversion, such as, "What would you do to liven up a dull party?" These loaded questions gave the interviewees little or no opportunity to falsify the hypothesis about them. A later version of the experiment gave the participants less presumptive questions to choose from, such as, "Do you shy away from social interactions?" Participants preferred to ask these more diagnostic questions, showing only a weak bias towards positive tests. This pattern, of a main preference for diagnostic tests and a weaker preference for positive tests, has been replicated in other studies.
</p><p>Personality traits influence and interact with biased search processes. Individuals vary in their abilities to defend their attitudes from external attacks in relation to selective exposure. Selective exposure occurs when individuals search for information that is consistent, rather than inconsistent, with their personal beliefs. An experiment examined the extent to which individuals could refute arguments that contradicted their personal beliefs. People with high confidence levels more readily seek out contradictory information to their personal position to form an argument. This can take the form of an <i>oppositional news consumption</i>, where individuals seek opposing partisan news in order to counterargue. Individuals with low confidence levels do not seek out contradictory information and prefer information that supports their personal position. People generate and evaluate evidence in arguments that are biased towards their own beliefs and opinions. Heightened confidence levels decrease preference for information that supports individuals' personal beliefs.
</p><p>Another experiment gave participants a complex rule-discovery task that involved moving objects simulated by a computer. Objects on the computer screen followed specific laws, which the participants had to figure out. So, participants could "fire" objects across the screen to test their hypotheses. Despite making many attempts over a ten-hour session, none of the participants figured out the rules of the system. They typically attempted to confirm rather than falsify their hypotheses, and were reluctant to consider alternatives. Even after seeing objective evidence that refuted their working hypotheses, they frequently continued doing the same tests. Some of the participants were taught proper hypothesis-testing, but these instructions had almost no effect.
</p>
<h3 data-mw-anchor="Biased_interpretation_of_information">Biased interpretation of information</h3>

<p>Confirmation biases are not limited to the collection of evidence. Even if two individuals have the same information, the way they interpret it can be biased.
</p><p>A team at Stanford University conducted an experiment involving participants who felt strongly about capital punishment, with half in favor and half against it. Each participant read descriptions of two studies: a comparison of U.S. states with and without the death penalty, and a comparison of murder rates in a state before and after the introduction of the death penalty. After reading a quick description of each study, the participants were asked whether their opinions had changed. Then, they read a more detailed account of each study's procedure and had to rate whether the research was well-conducted and convincing. In fact, the studies were fictional. Half the participants were told that one kind of study supported the deterrent effect and the other undermined it, while for other participants the conclusions were swapped.
</p><p>The participants, whether supporters or opponents, reported shifting their attitudes slightly in the direction of the first study they read. Once they read the more detailed descriptions of the two studies, they almost all returned to their original belief regardless of the evidence provided, pointing to details that supported their viewpoint and disregarding anything contrary. Participants described studies supporting their pre-existing view as superior to those that contradicted it, in detailed and specific ways. Writing about a study that seemed to undermine the deterrence effect, a death penalty proponent wrote, "The research didn't cover a long enough period of time," while an opponent's comment on the same study said, "No strong evidence to contradict the researchers has been presented." The results illustrated that people set higher standards of evidence for hypotheses that go against their current expectations. This effect, known as "disconfirmation bias", has been supported by other experiments.
</p><p>Another study of biased interpretation occurred during the 2004 U.S. presidential election and involved participants who reported having strong feelings about the candidates. They were shown apparently contradictory pairs of statements, either from Republican candidate George W. Bush, Democratic candidate John Kerry or a politically neutral public figure. They were also given further statements that made the apparent contradiction seem reasonable. From these three pieces of information, they had to decide whether each individual's statements were inconsistent.<sup class="reference nowrap"><span title="Page / location: 1948">: 1948 </span></sup> There were strong differences in these evaluations, with participants much more likely to interpret statements from the candidate they opposed as contradictory.<sup class="reference nowrap"><span title="Page / location: 1951">: 1951 </span></sup>
</p>

<p>In this experiment, the participants made their judgments while in a magnetic resonance imaging (MRI) scanner which monitored their brain activity. As participants evaluated contradictory statements by their favored candidate, emotional centers of their brains were aroused. This did not happen with the statements by the other figures. The experimenters inferred that the different responses to the statements were not due to passive reasoning errors. Instead, the participants were actively reducing the cognitive dissonance induced by reading about their favored candidate's irrational or hypocritical behavior.<sup class="reference nowrap"><span title="Page / location: 1956">: 1956 </span></sup>
</p><p>Biases in belief interpretation are persistent, regardless of intelligence level. Participants in an experiment took the SAT test (a college admissions test used in the United States) to assess their intelligence levels. They then read information regarding safety concerns for vehicles, and the experimenters manipulated the national origin of the car. American participants provided their opinion if the car should be banned on a six-point scale, where one indicated "definitely yes" and six indicated "definitely no". Participants firstly evaluated if they would allow a dangerous German car on American streets and a dangerous American car on German streets. Participants believed that the dangerous German car on American streets should be banned more quickly than the dangerous American car on German streets. There was no difference among intelligence levels at the rate participants would ban a car.
</p><p>Biased interpretation is not restricted to emotionally significant topics. In another experiment, participants were told a story about a theft. They had to rate the evidential importance of statements arguing either for or against a particular character being responsible. When they hypothesized that character's guilt, they rated statements supporting that hypothesis as more important than conflicting statements.
</p>
<h3 data-mw-anchor="Biased_recall_of_information">Biased recall of information</h3>
<p>People may remember evidence selectively to reinforce their expectations, even if they gather and interpret evidence in a neutral manner. This effect is called "selective recall", "confirmatory memory", or "access-biased memory". Psychological theories differ in their predictions about selective recall. Schema theory predicts that information matching prior expectations will be more easily stored and recalled than information that does not match. Some alternative approaches say that surprising information stands out and so is memorable. Predictions from both these theories have been confirmed in different experimental contexts, with no theory winning outright.
</p><p>In one study, participants read a profile of a woman which described a mix of introverted and extroverted behaviors. They later had to recall examples of her introversion and extroversion. One group was told this was to assess the woman for a job as a librarian, while a second group were told it was for a job in real estate sales. There was a significant difference between what these two groups recalled, with the "librarian" group recalling more examples of introversion and the "sales" groups recalling more extroverted behavior. A selective memory effect has also been shown in experiments that manipulate the desirability of personality types. In one of these, a group of participants were shown evidence that extroverted people are more successful than introverts. Another group were told the opposite. In a subsequent, apparently unrelated study, participants were asked to recall events from their lives in which they had been either introverted or extroverted. Each group of participants provided more memories connecting themselves with the more desirable personality type, and recalled those memories more quickly.
</p><p>Changes in emotional states can also influence memory recall. Participants rated how they felt when they had first learned that O. J. Simpson had been acquitted of murder charges. They described their emotional reactions and confidence regarding the verdict one week, two months, and one year after the trial. Results indicated that participants' assessments for Simpson's guilt changed over time. The more that participants' opinion of the verdict had changed, the less stable were the participant's memories regarding their initial emotional reactions. When participants recalled their initial emotional reactions two months and a year later, past appraisals closely resembled current appraisals of emotion. People demonstrate sizable myside bias when discussing their opinions on controversial topics. Memory recall and construction of experiences undergo revision in relation to corresponding emotional states.
</p><p>Myside bias has been shown to influence the accuracy of memory recall. In an experiment, widows and widowers rated the intensity of their experienced grief six months and five years after the deaths of their spouses. Participants noted a higher experience of grief at six months rather than at five years. Yet, when the participants were asked after five years how they had felt six months after the death of their significant other, the intensity of grief participants recalled was highly correlated with their current level of grief. Individuals appear to utilize their current emotional states to analyze how they must have felt when experiencing past events. Emotional memories are reconstructed by current emotional states.
</p><p>One study showed how selective memory can maintain belief in extrasensory perception (ESP). Believers and disbelievers were each shown descriptions of ESP experiments. Half of each group were told that the experimental results supported the existence of ESP, while the others were told they did not. In a subsequent test, participants recalled the material accurately, apart from believers who had read the non-supportive evidence. This group remembered significantly less information and some of them incorrectly remembered the results as supporting ESP.
</p>
<h2 data-mw-anchor="Individual_differences">Individual differences</h2>
<p>Myside bias was once believed to be correlated with intelligence; however, studies have shown that myside bias can be more influenced by ability to rationally think as opposed to level of intelligence. Myside bias can cause an inability to effectively and logically evaluate the opposite side of an argument. Studies have stated that myside bias is an absence of "active open-mindedness", meaning the active search for why an initial idea may be wrong. Typically, myside bias is operationalized in empirical studies as the quantity of evidence used in support of their side in comparison to the opposite side.
</p><p>A study has found individual differences in myside bias. This study investigates individual differences that are acquired through learning in a cultural context and are mutable. The researcher found important individual difference in argumentation. Studies have suggested that individual differences such as deductive reasoning ability, ability to overcome belief bias, epistemological understanding, and thinking disposition are significant predictors of the reasoning and generating arguments, counterarguments, and rebuttals.
</p><p>A study by Christopher Wolfe and Anne Britt also investigated how participants' views of "what makes a good argument?" can be a source of myside bias that influences the way a person formulates their own arguments. The study investigated individual differences of argumentation schema and asked participants to write essays. The participants were randomly assigned to write essays either for or against their preferred side of an argument and were given research instructions that took either a balanced or an unrestricted approach. The balanced-research instructions directed participants to create a "balanced" argument, i.e., that included both pros and cons; the unrestricted-research instructions included nothing on how to create the argument.
</p><p>Overall, the results revealed that the balanced-research instructions significantly increased the incidence of opposing information in arguments. These data also reveal that personal belief is not a <i>source</i> of myside bias; however, that those participants, who believe that a good argument is one that is based on facts, are more likely to exhibit myside bias than other participants. This evidence is consistent with the claims proposed in Baron's article—that people's opinions about what makes good thinking can influence how arguments are generated.
</p>
<h2 data-mw-anchor="Discovery">Discovery</h2>
<h3 data-mw-anchor="Informal_observations">Informal observations</h3>

<p>Before psychological research on confirmation bias, the phenomenon had been observed throughout history. Beginning with the Greek historian Thucydides (<abbr title="circa">c.</abbr><span> 460 BC</span> – <abbr title="circa">c.</abbr><span> 395 BC</span>), who wrote of misguided reason in <i>The Peloponnesian War</i>; "... for it is a habit of mankind to entrust to careless hope what they long for, and to use sovereign reason to thrust aside what they do not fancy". Italian poet Dante Alighieri (1265–1321) noted it in the <i>Divine Comedy</i>, in which St. Thomas Aquinas cautions Dante upon meeting in Paradise, "opinion—hasty—often can incline to the wrong side, and then affection for one's own opinion binds, confines the mind". Ibn Khaldun noticed the same effect in his <i>Muqaddimah</i>:
</p>
<blockquote class="templatequote"><p>Untruth naturally afflicts historical information. There are various reasons that make this unavoidable. One of them is partisanship for opinions and schools. ... if the soul is infected with partisanship for a particular opinion or sect, it accepts without a moment's hesitation the information that is agreeable to it. Prejudice and partisanship obscure the critical faculty and preclude critical investigation. The result is that falsehoods are accepted and transmitted.</p></blockquote><p> In the <i>Novum Organum</i>, English philosopher and scientist Francis Bacon (1561–1626) noted that biased assessment of evidence drove "all superstitions, whether in astrology, dreams, omens, divine judgments or the like". He wrote:
</p><blockquote class="templatequote"><p>The human understanding when it has once adopted an opinion ... draws all things else to support and agree with it. And though there be a greater number and weight of instances to be found on the other side, yet these it either neglects or despises, or else by some distinction sets aside or rejects[.]</p></blockquote>
<p>In the second volume of his <i>The World as Will and Representation</i> (1844), German philosopher Arthur Schopenhauer observed that "An adopted hypothesis gives us lynx-eyes for everything that confirms it and makes us blind to everything that contradicts it."
</p><p>In his essay (1897) <i>What Is Art?</i>, Russian novelist Leo Tolstoy wrote:
</p>
<blockquote class="templatequote"><p>I know that most men—not only those considered clever, but even those who are very clever, and capable of understanding most difficult scientific, mathematical, or philosophic problems—can very seldom discern even the simplest and most obvious truth if it be such as to oblige them to admit the falsity of conclusions they have formed, perhaps with much difficulty—conclusions of which they are proud, which they have taught to others, and on which they have built their lives.</p></blockquote><p> In his essay (1894) <i>The Kingdom of God Is Within You</i>, Tolstoy had earlier written:
</p><blockquote class="templatequote"><p>The most difficult subjects can be explained to the most slow-witted man if he has not formed any idea of them already; but the simplest thing cannot be made clear to the most intelligent man if he is firmly persuaded that he knows already, without a shadow of doubt, what is laid before him.</p></blockquote>
<h3 data-mw-anchor="Hypothesis-testing_(falsification)_explanation_(Wason)" data-mw-fallback-anchor="Hypothesis-testing_.28falsification.29_explanation_.28Wason.29">Hypothesis-testing (falsification) explanation (Wason)</h3>

<p>In Peter Wason's initial experiment published in 1960 (which does not mention the term "confirmation bias"), he repeatedly challenged participants to identify a rule applying to triples of numbers. They were told that (2,4,6) fits the rule. They generated triples, and the experimenter told them whether each triple conformed to the rule.<sup class="reference nowrap"><span title="Page / location: 179">: 179 </span></sup>
</p><p>The actual rule was simply "any ascending sequence", but participants had great difficulty in finding it, often announcing rules that were far more specific, such as "the middle number is the average of the first and last". The participants seemed to test only positive examples—triples that obeyed their hypothesized rule. For example, if they thought the rule was, "Each number is two greater than its predecessor," they would offer a triple that fitted (confirmed) this rule, such as (11,13,15) rather than a triple that violated (falsified) it, such as (11,12,19).
</p><p>Wason interpreted his results as showing a preference for confirmation over falsification, hence he coined the term "confirmation bias". Wason also used confirmation bias to explain the results of his selection task experiment. Participants repeatedly performed badly on various forms of this test, in most cases ignoring information that could potentially refute (falsify) the specified rule.
</p>
<h3 data-mw-anchor="Hypothesis_testing_(positive_test_strategy)_explanation_(Klayman_and_Ha)" data-mw-fallback-anchor="Hypothesis_testing_.28positive_test_strategy.29_explanation_.28Klayman_and_Ha.29">Hypothesis testing (positive test strategy) explanation (Klayman and Ha)</h3>
<p>Klayman and Ha's 1987 paper argues that the Wason experiments do not actually demonstrate a bias towards confirmation, but instead a tendency to make tests consistent with the working hypothesis. They called this the "positive test strategy". This strategy is an example of a heuristic: a reasoning shortcut that is imperfect but easy to compute. Klayman and Ha used Bayesian probability and information theory as their standard of hypothesis-testing, rather than the falsificationism used by Wason. According to these ideas, each answer to a question yields a different amount of information, which depends on the person's prior beliefs. Thus a scientific test of a hypothesis is one that is expected to produce the most information. Since the information content depends on initial probabilities, a positive test can either be highly informative or uninformative. Klayman and Ha argued that when people think about realistic problems, they are looking for a specific answer with a small initial probability. In this case, positive tests are usually more informative than negative tests. However, in Wason's rule discovery task the answer—three numbers in ascending order—is very broad, so positive tests are unlikely to yield informative answers. Klayman and Ha supported their analysis by citing an experiment that used the labels "DAX" and "MED" in place of "fits the rule" and "doesn't fit the rule". This avoided implying that the aim was to find a low-probability rule. Participants had much more success with this version of the experiment.
</p>

<p>In light of this and other critiques, the focus of research moved away from confirmation versus falsification of an hypothesis, to examining whether people test hypotheses in an informative way, or an uninformative but positive way. The search for "true" confirmation bias led psychologists to look at a wider range of effects in how people process information.
</p>
<h2 data-mw-anchor="Information_processing_explanations">Information processing explanations</h2>
<p>There are currently three main information processing explanations of confirmation bias, plus a recent addition.
</p>
<h3 data-mw-anchor="Cognitive_versus_motivational">Cognitive versus motivational</h3>

<p>According to Robert MacCoun, most biased evidence processing occurs through a combination of "cold" (cognitive) and "hot" (motivated) mechanisms.
</p><p>Cognitive explanations for confirmation bias are based on limitations in people's ability to handle complex tasks, and the shortcuts, called <i>heuristics</i>, that they use. For example, people may judge the reliability of evidence by using the <i>availability heuristic</i> that is, how readily a particular idea comes to mind. It is also possible that people can only focus on one thought at a time, so find it difficult to test alternative hypotheses in parallel.<sup class="reference nowrap"><span title="Page / location: 198–199">: 198–199 </span></sup> Another heuristic is the positive test strategy identified by Klayman and Ha, in which people test a hypothesis by examining cases where they expect a property or event to occur. This heuristic avoids the difficult or impossible task of working out how diagnostic each possible question will be. However, it is not universally reliable, so people can overlook challenges to their existing beliefs.<sup class="reference nowrap"><span title="Page / location: 200">: 200 </span></sup>
</p><p>Motivational explanations involve an effect of desire on belief.<sup class="reference nowrap"><span title="Page / location: 197">: 197 </span></sup> It is known that people prefer positive thoughts over negative ones in a number of ways: this is called the "Pollyanna principle". Applied to arguments or sources of evidence, this could explain why desired conclusions are more likely to be believed true. According to experiments that manipulate the desirability of the conclusion, people demand a high standard of evidence for unpalatable ideas and a low standard for preferred ideas. In other words, they ask, "Can I believe this?" for some suggestions and, "Must I believe this?" for others. Although consistency is a desirable feature of attitudes, an excessive drive for consistency is another potential source of bias because it may prevent people from neutrally evaluating new, surprising information. Social psychologist Ziva Kunda combines the cognitive and motivational theories, arguing that motivation creates the bias, but cognitive factors determine the size of the effect.<sup class="reference nowrap"><span title="Page / location: 198">: 198 </span></sup>
</p>
<h3 data-mw-anchor="Cost-benefit">Cost-benefit</h3>
<p>Explanations in terms of cost-benefit analysis assume that people do not just test hypotheses in a disinterested way, but assess the costs of different errors. Using ideas from evolutionary psychology, James Friedrich suggests that people do not primarily aim at truth in testing hypotheses, but try to avoid the most costly errors. For example, employers might ask one-sided questions in job interviews because they are focused on weeding out unsuitable candidates. Yaacov Trope and Akiva Liberman's refinement of this theory assumes that people compare the two different kinds of error: accepting a false hypothesis or rejecting a true hypothesis. For instance, someone who underestimates a friend's honesty might treat him or her suspiciously and so undermine the friendship. Overestimating the friend's honesty may also be costly, but less so. In this case, it would be rational to seek, evaluate or remember evidence of their honesty in a biased way. When someone gives an initial impression of being introverted or extroverted, questions that match that impression come across as more empathic. This suggests that when talking to someone who seems to be an introvert, it is a sign of better social skills to ask, "Do you feel awkward in social situations?" rather than, "Do you like noisy parties?" The connection between confirmation bias and social skills was corroborated by a study of how college students get to know other people. Highly self-monitoring students, who are more sensitive to their environment and to social norms, asked more matching questions when interviewing a high-status staff member than when getting to know fellow students.
</p>
<h3 data-mw-anchor="Exploratory_versus_confirmatory">Exploratory versus confirmatory</h3>
<p>Psychologists Jennifer Lerner and Philip Tetlock distinguish two different kinds of thinking process. <i>Exploratory thought</i> neutrally considers multiple points of view and tries to anticipate all possible objections to a particular position, while <i>confirmatory thought</i> seeks to justify a specific point of view. Lerner and Tetlock say that when people expect to justify their position to others whose views they already know, they will tend to adopt a similar position to those people, and then use confirmatory thought to bolster their own credibility. However, if the external parties are overly aggressive or critical, people will disengage from thought altogether, and simply assert their personal opinions without justification. Lerner and Tetlock say that people only push themselves to think critically and logically when they know in advance they will need to explain themselves to others who are well-informed, genuinely interested in the truth, and whose views they do not already know. Because those conditions rarely exist, they argue, most people are using confirmatory thought most of the time.
</p>
<h3 data-mw-anchor="Make-believe">Make-believe</h3>
<p>Developmental psychologist Eve Whitmore has argued that beliefs and biases involved in confirmation bias have their roots in childhood coping through make-believe, which becomes "the basis for more complex forms of self-deception and illusion into adulthood." The friction brought on by questioning as an adolescent with developing critical thinking can lead to the rationalization of false beliefs, and the habit of such rationalization can become unconscious over the years.
</p>
<h3 data-mw-anchor="Optimal_information_acquisition">Optimal information acquisition</h3>
<p>Recent research in economics has challenged the traditional view of confirmation bias as purely a cognitive flaw. Under conditions where acquiring and processing information is costly, seeking confirmatory evidence can actually be an optimal strategy. Instead of pursuing contrarian or disconfirming evidence, it may be more efficient to focus on sources likely to align with one's existing beliefs, given the constraints on time and resources.
</p><p>Economist Weijie Zhong has developed a model demonstrating that individuals who must make decisions under time pressure, and who face costs for obtaining more information, will often prefer confirmatory signals. According to this model, when individuals believe strongly in a certain hypothesis, they optimally seek information that confirms it, allowing them to build confidence more efficiently. If the expected confirmatory signals are not received, their confidence in the initial hypothesis will gradually decline, leading to belief updating. This approach shows that seeking confirmation is not necessarily biased but may be a rational allocation of limited attention and resources.
</p>
<h2 data-mw-anchor="Real-world_effects">Real-world effects</h2>
<h3 data-mw-anchor="Social_media">Social media</h3>
<p>In social media, confirmation bias is amplified by the use of filter bubbles, or "algorithmic editing", which displays to individuals only information they are likely to agree with, while excluding opposing views. Some have argued that confirmation bias is the reason why society can never escape from filter bubbles, because individuals are psychologically hardwired to seek information that agrees with their preexisting values and beliefs. Others have further argued that the mixture of the two is degrading democracy—claiming that this "algorithmic editing" removes diverse viewpoints and information—and that unless filter bubble algorithms are removed, voters will be unable to make fully informed political decisions.
</p><p>The rise of social media has contributed greatly to the rapid spread of fake news, that is, false and misleading information that is presented as credible news from a seemingly reliable source. Confirmation bias (selecting or reinterpreting evidence to support one's beliefs) is one of three main hurdles cited as to why critical thinking goes astray in these circumstances. The other two are shortcut heuristics (when overwhelmed or short of time, people rely on simple rules such as group consensus or trusting an expert or role model) and social goals (social motivation or peer pressure can interfere with objective analysis of facts at hand).
</p><p>In combating the spread of fake news, social media sites have considered turning toward "digital nudging". This can currently be done in two different forms of nudging. This includes nudging of information and nudging of presentation. Nudging of information entails social media sites providing a disclaimer or label questioning or warning users of the validity of the source while nudging of presentation includes exposing users to new information which they may not have sought out but could introduce them to viewpoints that may combat their own confirmation biases.
</p>
<h3 data-mw-anchor="Science_and_scientific_research">Science and scientific research</h3>

<p>A distinguishing feature of scientific thinking is the search for confirming or supportive evidence (inductive reasoning) as well as falsifying evidence (deductive reasoning).
</p><p>Many times in the history of science, scientists have resisted new discoveries by selectively interpreting or ignoring unfavorable data.<sup class="reference nowrap"><span title="Page / location: 192–194">: 192–194 </span></sup> Several studies have shown that scientists rate studies that report findings consistent with their prior beliefs more favorably than studies reporting findings inconsistent with their previous beliefs.
</p><p>However, assuming that the research question is relevant, the experimental design adequate and the data are clearly and comprehensively described, the empirical data obtained should be important to the scientific community and should not be viewed prejudicially, regardless of whether they conform to current theoretical predictions. In practice, researchers may misunderstand, misinterpret, or not read at all studies that contradict their preconceptions, or wrongly cite them anyway as if they actually supported their claims.
</p><p>Further, confirmation biases can sustain scientific theories or research programs in the face of inadequate or even contradictory evidence. The discipline of parapsychology is often cited as an example.
</p><p>An experimenter's confirmation bias can potentially affect which data are reported. Data that conflict with the experimenter's expectations may be more readily discarded as unreliable, producing the so-called file drawer effect. To combat this tendency, scientific training teaches ways to prevent bias. For example, experimental design of randomized controlled trials (coupled with their systematic review) aims to minimize sources of bias.
</p><p>The social process of peer review aims to mitigate the effect of individual scientists' biases, even though the peer review process itself may be susceptible to such biases Confirmation bias may thus be especially harmful to objective evaluations regarding nonconforming results since biased individuals may regard opposing evidence to be weak in principle and give little serious thought to revising their beliefs. Scientific innovators often meet with resistance from the scientific community, and research presenting controversial results frequently receives harsh peer review.
</p>
<h3 data-mw-anchor="Finance">Finance</h3>

<p>Confirmation bias can lead investors to be overconfident, ignoring evidence that their strategies will lose money. In studies of political stock markets, investors made more profit when they resisted bias. For example, participants who interpreted a candidate's debate performance in a neutral rather than partisan way were more likely to profit. To combat the effect of confirmation bias, investors can try to adopt a contrary viewpoint "for the sake of argument". In one technique, they imagine that their investments have collapsed and ask themselves why this might happen.
</p>
<h3 data-mw-anchor="Medicine_and_health">Medicine and health</h3>
<p>Cognitive biases are important variables in clinical decision-making by medical general practitioners (GPs) and medical specialists. Two important ones are confirmation bias and the overlapping availability bias. A GP may make a diagnosis early on during an examination, and then seek confirming evidence rather than falsifying evidence. This cognitive error is partly caused by the availability of evidence about the supposed disorder being diagnosed. For example, the client may have mentioned the disorder, or the GP may have recently read a much-discussed paper about the disorder. The basis of this cognitive shortcut or heuristic (termed anchoring) is that the doctor does not consider multiple possibilities based on evidence, but prematurely latches on (or anchors to) a single cause. In emergency medicine, because of time pressure, there is a high density of decision-making, and shortcuts are frequently applied. The potential failure rate of these cognitive decisions needs to be managed by education about the 30 or more cognitive biases that can occur, so as to set in place proper debiasing strategies. Confirmation bias may also cause doctors to perform unnecessary medical procedures due to pressure from adamant patients.
</p><p>Raymond Nickerson, a psychologist, blames confirmation bias for the ineffective medical procedures that were used for centuries before the arrival of scientific medicine.<sup class="reference nowrap"><span title="Page / location: 192">: 192 </span></sup> If a patient recovered, medical authorities counted the treatment as successful, rather than looking for alternative explanations such as that the disease had run its natural course. Biased assimilation is a factor in the modern appeal of alternative medicine, whose proponents are swayed by positive anecdotal evidence but treat scientific evidence hyper-critically.
</p><p>Cognitive therapy was developed by Aaron T. Beck in the early 1960s and has become a popular approach. According to Beck, biased information processing is a factor in depression. His approach teaches people to treat evidence impartially, rather than selectively reinforcing negative outlooks. Phobias and hypochondria have also been shown to involve confirmation bias for threatening information.
</p>
<h3 data-mw-anchor="Politics,_law_and_policing" data-mw-fallback-anchor="Politics.2C_law_and_policing">Politics, law and policing</h3>

<p>Nickerson argues that reasoning in judicial and political contexts is sometimes subconsciously biased, favoring conclusions that judges, juries or governments have already committed to.<sup class="reference nowrap"><span title="Page / location: 191–193">: 191–193 </span></sup> Since the evidence in a jury trial can be complex, and jurors often reach decisions about the verdict early on, it is reasonable to expect an attitude polarization effect. The prediction that jurors will become more extreme in their views as they see more evidence has been borne out in experiments with mock trials. Both inquisitorial and adversarial criminal justice systems are affected by confirmation bias.
</p><p>Confirmation bias can be a factor in creating or extending conflicts, from emotionally charged debates to wars: by interpreting the evidence in their favor, each opposing party can become overconfident that it is in the stronger position. On the other hand, confirmation bias can result in people ignoring or misinterpreting the signs of an imminent or incipient conflict. For example, psychologists Stuart Sutherland and Thomas Kida have each argued that U.S. Navy Admiral Husband E. Kimmel showed confirmation bias when playing down the first signs of the Japanese attack on Pearl Harbor.
</p><p>A two-decade study of political pundits by Philip E. Tetlock found that, on the whole, their predictions were not much better than chance. Tetlock divided experts into "foxes" who maintained multiple hypotheses, and "hedgehogs" who were more dogmatic. In general, the hedgehogs were much less accurate. Tetlock blamed their failure on confirmation bias, and specifically on their inability to make use of new information that contradicted their existing theories.
</p><p>In police investigations, a detective may identify a suspect early in an investigation, but then sometimes largely seek supporting or confirming evidence, ignoring or downplaying falsifying evidence.
</p>
<h3 data-mw-anchor="Social_psychology">Social psychology</h3>
<p>Social psychologists have identified two tendencies in the way people seek or interpret information about themselves. <i>Self-verification</i> is the drive to reinforce the existing self-image and <i>self-enhancement</i> is the drive to seek positive feedback. Both are served by confirmation biases. In experiments where people are given feedback that conflicts with their self-image, they are less likely to attend to it or remember it than when given self-verifying feedback. They reduce the impact of such information by interpreting it as unreliable. Similar experiments have found a preference for positive feedback, and the people who give it, over negative feedback.
</p>
<h3 data-mw-anchor="Mass_delusions">Mass delusions</h3>
<p>Confirmation bias can play a key role in the propagation of mass delusions. Witch trials are frequently cited as an example.
</p><p>For another example, in the Seattle windshield pitting epidemic, there seemed to be a "pitting epidemic" in which windshields were damaged due to an unknown cause. As news of the apparent wave of damage spread, more and more people checked their windshields, discovered that their windshields too had been damaged, thus confirming belief in the supposed epidemic. In fact, the windshields were previously damaged, but the damage went unnoticed until people checked their windshields as the delusion spread.
</p>
<h3 data-mw-anchor="Paranormal_beliefs">Paranormal beliefs</h3>
<p>One factor in the appeal of alleged psychic readings is that listeners apply a confirmation bias which fits the psychic's statements to their own lives. By making a large number of ambiguous statements in each sitting, the psychic gives the client more opportunities to find a match. This is one of the techniques of cold reading, with which a psychic can deliver a subjectively impressive reading without any prior information about the client. Investigator James Randi compared the transcript of a reading to the client's report of what the psychic had said, and found that the client showed a strong selective recall of the "hits".
</p><p>As a striking illustration of confirmation bias in the real world, Nickerson mentions numerological pyramidology: the practice of finding meaning in the proportions of the Egyptian pyramids.<sup class="reference nowrap"><span title="Page / location: 190">: 190 </span></sup> There are many different length measurements that can be made of, for example, the Great Pyramid of Giza and many ways to combine or manipulate them. Hence it is almost inevitable that people who look at these numbers selectively will find superficially impressive correspondences, for example with the dimensions of the Earth.<sup class="reference nowrap"><span title="Page / location: 190">: 190 </span></sup>
</p>
<h3 data-mw-anchor="Recruitment_and_selection">Recruitment and selection</h3>
<p>Unconscious cognitive bias (including confirmation bias) in job recruitment affects hiring decisions and can potentially prohibit a diverse and inclusive workplace. There are a variety of unconscious biases that affects recruitment decisions but confirmation bias is one of the major ones, especially during the interview stage. The interviewer will often select a candidate that confirms their own beliefs, even though other candidates are equally or better qualified.
</p>
<h2 data-mw-anchor="Associated_effects_and_outcomes">Associated effects and outcomes</h2>
<h3 data-mw-anchor="Polarization_of_opinion">Polarization of opinion</h3>

<p>When people with opposing views interpret new information in a biased way, their views can move even further apart. This is called "attitude polarization". The effect was demonstrated by an experiment that involved drawing a series of red and black balls from one of two concealed "bingo baskets". Participants knew that one basket contained 60 percent black and 40 percent red balls; the other, 40 percent black and 60 percent red. The experimenters looked at what happened when balls of alternating color were drawn in turn, a sequence that does not favor either basket. After each ball was drawn, participants in one group were asked to state out loud their judgments of the probability that the balls were being drawn from one or the other basket. These participants tended to grow more confident with each successive draw—whether they initially thought the basket with 60 percent black balls or the one with 60 percent red balls was the more likely source, their estimate of the probability increased. Another group of participants were asked to state probability estimates only at the end of a sequence of drawn balls, rather than after each ball. They did not show the polarization effect, suggesting that it does not necessarily occur when people simply hold opposing positions, but rather when they openly commit to them.
</p><p>A less abstract study was the Stanford biased interpretation experiment, in which participants with strong opinions about the death penalty read about mixed experimental evidence. Twenty-three percent of the participants reported that their views had become more extreme, and this self-reported shift correlated strongly with their initial attitudes. In later experiments, participants also reported their opinions becoming more extreme in response to ambiguous information. However, comparisons of their attitudes before and after the new evidence showed no significant change, suggesting that the self-reported changes might not be real. Based on these experiments, Deanna Kuhn and Joseph Lao concluded that polarization is a real phenomenon but far from inevitable, only happening in a small minority of cases, and it was prompted not only by considering mixed evidence, but by merely thinking about the topic.
</p><p>Charles Taber and Milton Lodge argued that the Stanford team's result had been hard to replicate because the arguments used in later experiments were too abstract or confusing to evoke an emotional response. The Taber and Lodge study used the emotionally charged topics of gun control and affirmative action. They measured the attitudes of their participants towards these issues before and after reading arguments on each side of the debate. Two groups of participants showed attitude polarization: those with strong prior opinions and those who were politically knowledgeable. In part of this study, participants chose which information sources to read, from a list prepared by the experimenters. For example, they could read arguments on gun control from the National Rifle Association of America and the Brady Anti-Handgun Coalition. Even when instructed to be even-handed, participants were more likely to read arguments that supported their existing attitudes than arguments that did not. This biased search for information correlated well with the polarization effect.
</p><p>The <b><span><span id="backfire_effect"></span><span>backfire effect</span></span></b> is a name for the finding that given evidence against their beliefs, people can reject the evidence and believe even more strongly. The phrase was coined by Brendan Nyhan and Jason Reifler in 2010. However, subsequent research has since failed to replicate findings supporting the backfire effect. One study conducted out of the Ohio State University and George Washington University studied 10,100 participants with 52 different issues expected to trigger a backfire effect. While the findings did conclude that individuals are reluctant to embrace facts that contradict their already held ideology, no cases of backfire were detected. The backfire effect has since been noted to be a rare phenomenon rather than a common occurrence (compare the boomerang effect).
</p>
<h3 data-mw-anchor="Persistence_of_discredited_beliefs">Persistence of discredited beliefs</h3>



<p>Confirmation biases provide one plausible explanation for the persistence of beliefs when the initial evidence for them is removed or when they have been sharply contradicted.<sup class="reference nowrap"><span title="Page / location: 187">: 187 </span></sup> This belief perseverance effect has been first demonstrated experimentally by Festinger, Riecken, and Schachter. These psychologists spent time with a cult whose members were convinced that the world would end on 21 December 1954. After the prediction failed, most believers still clung to their faith. Their book describing this research is aptly named <i>When Prophecy Fails</i>.
</p><p>The term <i>belief perseverance</i>, however, was coined in a series of experiments using what is called the "debriefing paradigm": participants read fake evidence for a hypothesis, their attitude change is measured, then the fakery is exposed in detail. Their attitudes are then measured once more to see if their belief returns to its previous level.
</p><p>A common finding is that at least some of the initial belief remains even after a full debriefing. In one experiment, participants had to distinguish between real and fake suicide notes. The feedback was random: some were told they had done well while others were told they had performed badly. Even after being fully debriefed, participants were still influenced by the feedback. They still thought they were better or worse than average at that kind of task, depending on what they had initially been told.
</p><p>In another study, participants read job performance ratings of two firefighters, along with their responses to a risk aversion test. This fictional data was arranged to show either a negative or positive association: some participants were told that a risk-taking firefighter did better, while others were told they did less well than a risk-averse colleague. Even if these two case studies were true, they would have been scientifically poor evidence for a conclusion about firefighters in general. However, the participants found them subjectively persuasive. When the case studies were shown to be fictional, participants' belief in a link diminished, but around half of the original effect remained. Follow-up interviews established that the participants had understood the debriefing and taken it seriously. Participants seemed to trust the debriefing, but regarded the discredited information as irrelevant to their personal belief.
</p><p>The continued influence effect is the tendency for misinformation to continue to influence memory and reasoning about an event, despite the misinformation having been retracted or corrected. This occurs even when the individual believes the correction.
</p>
<h3 data-mw-anchor="Preference_for_early_information">Preference for early information</h3>
<p>Experiments have shown that information is weighted more strongly when it appears early in a series, even when the order is unimportant. For example, people form a more positive impression of someone described as "intelligent, industrious, impulsive, critical, stubborn, envious" than when they are given the same words in reverse order. This <i>irrational primacy effect</i> is independent of the primacy effect in memory in which the earlier items in a series leave a stronger memory trace. Biased interpretation offers an explanation for this effect: seeing the initial evidence, people form a working hypothesis that affects how they interpret the rest of the information.<sup class="reference nowrap"><span title="Page / location: 187">: 187 </span></sup>
</p><p>One demonstration of irrational primacy used colored chips supposedly drawn from two urns. Participants were told the color distributions of the urns, and had to estimate the probability of a chip being drawn from one of them. In fact, the colors appeared in a prearranged order. The first thirty draws favored one urn and the next thirty favored the other.<sup class="reference nowrap"><span title="Page / location: 187">: 187 </span></sup> The series as a whole was neutral, so rationally, the two urns were equally likely. However, after sixty draws, participants favored the urn suggested by the initial thirty.
</p><p>Another experiment involved a slide show of a single object, seen as just a blur at first and in slightly better focus with each succeeding slide. After each slide, participants had to state their best guess of what the object was. Participants whose early guesses were wrong persisted with those guesses, even when the picture was sufficiently in focus that the object was readily recognizable to other people.<sup class="reference nowrap"><span title="Page / location: 187">: 187 </span></sup>
</p>
<h3 data-mw-anchor="Illusory_association_between_events">Illusory association between events</h3>

<p>Illusory correlation is the tendency to see non-existent correlations in a set of data. This tendency was first demonstrated in a series of experiments in the late 1960s. In one experiment, participants read a set of psychiatric case studies, including responses to the Rorschach inkblot test. The participants reported that the homosexual men in the set were more likely to report seeing buttocks, anuses or sexually ambiguous figures in the inkblots. In fact the fictional case studies had been constructed so that the homosexual men were no more likely to report this imagery or, in one version of the experiment, were less likely to report it than heterosexual men. In a survey, a group of experienced psychoanalysts reported the same set of illusory associations with homosexuality.
</p><p>Another study recorded the symptoms experienced by arthritic patients, along with weather conditions over a 15-month period. Nearly all the patients reported that their pains were correlated with weather conditions, although the real correlation was zero.
</p>

<p>This effect is a kind of biased interpretation, in that objectively neutral or unfavorable evidence is interpreted to support existing beliefs. It is also related to biases in hypothesis-testing behavior. In judging whether two events, such as illness and bad weather, are correlated, people rely heavily on the number of <i>positive-positive</i> cases: in this example, instances of both pain and bad weather. They pay relatively little attention to the other kinds of observation (of no pain or good weather). This parallels the reliance on positive tests in hypothesis testing. It may also reflect selective recall, in that people may have a sense that two events are correlated because it is easier to recall times when they happened together.
</p>
<h2 data-mw-anchor="See_also">See also</h2>


<h2 data-mw-anchor="Notes">Notes</h2>

<h2 data-mw-anchor="References">References</h2>
<h3 data-mw-anchor="Citations">Citations</h3>

<h3 data-mw-anchor="Sources">Sources</h3>

<h2 data-mw-anchor="Further_reading">Further reading</h2>
<ul><li><cite id="CITEREFLeavitt2015" class="citation cs2">Leavitt, Fred (2015), <i>Dancing with absurdity: Your most cherished beliefs (and all your others) are probably wrong</i>, Peter Lang Publishers, ISBN <bdi>9781453914908</bdi>, OCLC 908685982</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Dancing+with+absurdity%3A+Your+most+cherished+beliefs+%28and+all+your+others%29+are+probably+wrong&amp;rft.pub=Peter+Lang+Publishers&amp;rft.date=2015&amp;rft_id=info%3Aoclcnum%2F908685982&amp;rft.isbn=9781453914908&amp;rft.aulast=Leavitt&amp;rft.aufirst=Fred&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AConfirmation+bias"></span></li>
<li><cite id="CITEREFStanovich2009" class="citation cs2">Stanovich, Keith (2009), <i>What intelligence tests miss: The psychology of rational thought</i> (Lay), New Haven (CT): Yale University Press, ISBN <bdi>978-0-300-12385-2</bdi></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=What+intelligence+tests+miss%3A+The+psychology+of+rational+thought&amp;rft.place=New+Haven+%28CT%29&amp;rft.pub=Yale+University+Press&amp;rft.date=2009&amp;rft.isbn=978-0-300-12385-2&amp;rft.aulast=Stanovich&amp;rft.aufirst=Keith&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fwhatintelligence00stan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AConfirmation+bias"></span></li>
<li><cite id="CITEREFWesten2007" class="citation cs2">Westen, Drew (2007), <i>The political brain: The role of emotion in deciding the fate of the nation</i>, PublicAffairs, ISBN <bdi>978-1-58648-425-5</bdi>, OCLC 86117725</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+political+brain%3A+The+role+of+emotion+in+deciding+the+fate+of+the+nation&amp;rft.pub=PublicAffairs&amp;rft.date=2007&amp;rft_id=info%3Aoclcnum%2F86117725&amp;rft.isbn=978-1-58648-425-5&amp;rft.aulast=Westen&amp;rft.aufirst=Drew&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fpoliticalbrainro00west&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AConfirmation+bias"></span></li>
<li>Meppelink, Corine S., Edith G. Smit, Marieke L. Fransen, and Nicola Diviani. “‘I Was Right about Vaccination’: Confirmation Bias and Health Literacy in Online Health Information Seeking.” Journal of Health Communication 24, no. 2 (2019): 129–40. https://doi.org/10.1080/10810730.2019.1583701.</li></ul>
<ul><li>Pearson, George David Hooke, and Silvia Knobloch-Westerwick. “Is the Confirmation Bias Bubble Larger Online? Pre-Election Confirmation Bias in Selective Exposure to Online versus Print Political Information.” Mass Communication &amp; Society 22, no. 4 (2019): 466–86. https://doi.org/10.1080/15205436.2019.1599956.</li></ul>
<h2 data-mw-anchor="External_links">External links</h2>

<ul><li>Skeptic's Dictionary: confirmation bias – Robert T. Carroll</li>
<li>Teaching about confirmation bias – class handout and instructor's notes by K.H. Grobman</li>
<li>Confirmation bias at You Are Not So Smart</li>
<li>Confirmation bias learning object – interactive number triples exercise by Rod McFarland for Simon Fraser University</li>
<li>Brief summary of the 1979 Stanford assimilation bias study – Keith Rollag, Babson College</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Confirmation_bias#backfire_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>System justification</h2>
<a href='https://en.wikipedia.org/wiki/System_justification' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>System justification theory</b> is a theory within social psychology that system-justifying beliefs serve a psychologically palliative function. It proposes that people have several underlying needs, which vary from individual to individual, that can be satisfied by the defense and justification of the status quo, even when the system may be disadvantageous to certain people. People have epistemic, existential, and relational needs that are met by and manifest as ideological support for the prevailing structure of social, economic, and political norms. Need for order and stability, and thus resistance to change or alternatives, for example, can be a motivator for individuals to see the status quo as good, legitimate, and even desirable.
</p><p>According to system justification theory, people desire not only to hold favorable attitudes about themselves (ego-justification) and the groups to which they belong (group-justification), but also to hold positive attitudes about the overarching social structure in which they are entwined and find themselves obligated to (system-justification). This system-justifying motive sometimes produces the phenomenon known as out-group favoritism, an acceptance of inferiority among low-status groups and a positive image of relatively higher status groups. Thus, the notion that individuals are simultaneously supporters and victims of the system-instilled norms is a central idea in system justification theory. Additionally, the passive ease of supporting the current structure, when compared to the potential price (material, social, psychological) of acting out against the status quo, leads to a shared environment in which the existing social, economic, and political arrangements tend to be preferred. Alternatives to the status quo tend to be disparaged, and inequality tends to perpetuate.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/System_justification'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Reverse psychology</h2>
<a href='https://en.wikipedia.org/wiki/Reverse_psychology' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Reverse psychology</b> is a technique involving the assertion of a belief or behavior that is opposite to the one desired, with the expectation that this approach will encourage the subject of the persuasion to do what is actually desired. This technique relies on the psychological phenomenon of reactance, in which a person has a negative emotional reaction to being persuaded, and thus chooses the option which is being advocated against. This may work especially well on a person who is resistant by nature, while direct requests work best for people who are compliant. The one being manipulated is usually unaware of what is really going on.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Reverse_psychology'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Reactance</h2>
<a href='https://en.wikipedia.org/wiki/Reactance_(psychology)' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In psychology, <b>reactance</b> is an unpleasant motivational reaction to offers, persons, rules, regulations, advice, recommendations, information, and messages that are perceived to threaten or eliminate specific behavioral freedoms. Reactance occurs when an individual feels that an agent is attempting to limit one's choice of response and/or range of alternatives.
</p><p>Reactance can occur when someone is heavily pressured into accepting a certain view or attitude. Reactance can encourage an individual to adopt or strengthen a view or attitude which is indeed contrary to that which was <span>intended<span> </span>—</span><span> </span>which is to say, to a response of <span>noncompliance<span> </span>—</span><span> </span>and can also increase resistance to persuasion. Some individuals might employ reverse psychology in a bid to exploit reactance for their benefit, in an attempt to influence someone to choose the opposite of what is being requested. Reactance can occur when an individual senses that someone is trying to compel them to do something; often the individual will offer resistance and attempt to extricate themselves from the situation.
</p><p>Some individuals are naturally high in reactance, a personality characteristic called <i>trait reactance</i>.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Reactance_(psychology)'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Decoy effect</h2>
<a href='https://en.wikipedia.org/wiki/Decoy_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In marketing, the <b>decoy effect</b> (or <b>attraction effect</b> or <b>asymmetric dominance effect</b>) is the phenomenon whereby consumers will tend to have a specific change in preference between two options when also presented with a third option that is <i>asymmetrically dominated</i>. An option is asymmetrically dominated when it is inferior in all respects to one option; but, in comparison to the other option, it is inferior in some respects and superior in others. In other words, in terms of specific attributes determining preferences, it is completely dominated by (i.e., inferior to) one option and only partially dominated by the other. When the asymmetrically dominated option is present, a higher percentage of consumers will prefer the dominating option than when the asymmetrically dominated option is absent. The asymmetrically dominated option is therefore a decoy serving to increase preference for the dominating option. The decoy effect is also an example of the violation of the independence of irrelevant alternatives axiom of decision theory.  More simply, when deciding between two options, an unattractive third option can change the perceived preference between the other two.
</p><p>The decoy effect is considered particularly important in choice theory because it is a violation of the assumption of "regularity" present in all axiomatic choice models, for example in a Luce model of choice.  Regularity means that it should not be possible for the market share of any alternative to increase when another alternative is added to the choice set. The new alternative should reduce, or at best leave unchanged, the choice share of existing alternatives. Regularity is violated in the example shown below where a new alternative C not only changes the relative shares of A and B but actually increases the share of A in absolute terms.  Similarly, the introduction of a new alternative D increases the share of B in absolute terms.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Decoy_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Social comparison effect</h2>
<a href='https://en.wikipedia.org/wiki/Social_comparison_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Social comparison bias</b> is a cognitive bias in which individuals exhibit feelings of dislike and competitiveness toward others perceived as superior in physical, social, or intellectual aspects. Social comparison bias is closely associated with <b>social comparison theory</b>, which suggests that individuals assess their own value by comparing themselves to others. This theory was developed in 1954 by psychologist Leon Festinger. It is believed to play a significant role in achievement motivation, feelings of injustice, depression, jealousy, and individuals' willingness to remain in relationships or jobs.
</p><p>The theory posits that individuals strive to achieve favorable outcomes relative to their peers. For example, a person may compare the affordability of their frequent shopping locations to the designer stores visited by their peers. Such comparisons may lead to emotions such as resentment, anger, and envy. The bias predominantly revolves around wealth and social status and often operates unconsciously, with individuals largely unaware of their engagement in such comparisons. In most cases, individuals compare themselves with members of their peer group or others perceived as similar.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Social_comparison_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Status quo bias</h2>
<a href='https://en.wikipedia.org/wiki/Status_quo_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p>A <b>status quo bias</b> or <b>default bias</b> is a cognitive bias which results from a preference for the maintenance of one's existing state of affairs. The current baseline (or status quo) is taken as a reference point, and any change from that baseline is perceived as a loss or gain. Corresponding to different alternatives, this current baseline or default option is perceived and evaluated by individuals as a positive.
</p><p>Status quo bias should be distinguished from a rational preference for the status quo, as when the current state of affairs is objectively superior to the available alternatives, or when imperfect information is a significant problem. A large body of evidence, however, shows that status quo bias frequently affects human decision-making. Status quo bias should also be distinguished from psychological inertia, which refers to a lack of intervention in the current course of affairs.
</p><p>The bias intersects with other non-rational cognitive processes such as loss aversion, in which losses comparative to gains are weighed to a greater extent. Further non-rational cognitive processes include existence bias, endowment effect, longevity, mere exposure, and regret avoidance.  Experimental evidence for the detection of status quo bias is seen through the use of the reversal test. A vast amount of experimental and field examples exist. Behaviour in regard to economics, retirement plans, health, and ethical choices show evidence of the status quo bias.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Status_quo_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Ambiguity bias</h2>
<a href='https://en.wikipedia.org/wiki/Ambiguity_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>ambiguity effect</b> is a cognitive tendency where decision making is affected by a lack of information, or "ambiguity". The effect implies that people tend to select options for which the probability of a favorable outcome is known, over an option for which the probability of a favorable outcome is unknown. The effect was first described by Daniel Ellsberg in 1961.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Ambiguity_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Information bias</h2>
<a href='https://en.wikipedia.org/wiki/Information_bias_(psychology)' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Information bias</b> is a cognitive bias to seek information when it does not affect action. An example of information bias is believing that the more information that can be acquired to make a decision, the better, even if that extra information is irrelevant for the decision.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Information_bias_(psychology)'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Belief bias</h2>
<a href='https://en.wikipedia.org/wiki/Belief_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Belief bias</b> is the tendency to judge the strength of arguments based on the plausibility of their conclusion rather than how strongly they justify that conclusion. A person is more likely to accept an argument that supports a conclusion that aligns with their values, beliefs and prior knowledge, while rejecting counter arguments to the conclusion.  Belief bias is an extremely common and therefore significant form of error; we can easily be blinded by our beliefs and reach the wrong conclusion. Belief bias has been found to influence various reasoning tasks, including conditional reasoning, relation reasoning and transitive reasoning.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Belief_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Rhyme–as–reason effect</h2>
<a href='https://en.wikipedia.org/wiki/Rhyme-as-reason_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>rhyme-as-reason effect</b>, also known as the <b>Eaton–Rosen phenomenon</b>, is a cognitive bias where sayings or aphorisms are perceived as more accurate or truthful when they rhyme.
</p><p>In experiments, participants evaluated variations of sayings that either rhymed or did not rhyme. Those that rhymed were consistently judged as more truthful, even when the meaning was controlled for. For instance, the rhyming saying "What sobriety conceals, alcohol reveals" was rated as more accurate on average than its non-rhyming counterpart, "What sobriety conceals, alcohol unmasks," across different groups of subjects (each group assessed the accuracy of only one version of the statement).
</p><p>This effect may be explained by the Keats heuristic, which suggests that people assess a statement's truth based on its aesthetic qualities. Another explanation is the fluency heuristic, which posits that statements are preferred due to their ease of cognitive processing.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Rhyme-as-reason_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Bike–shedding effect</h2>
<a href='https://en.wikipedia.org/wiki/Law_of_triviality' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">

</p><p>The <b>law of triviality</b> is C. Northcote Parkinson's 1957 argument that people within an organization commonly give disproportionate weight to trivial issues. Parkinson provides the example of a fictional committee whose job was to approve the plans for a nuclear power plant spending the majority of its time on discussions about relatively minor but easy-to-grasp issues, such as what materials to use for the staff bicycle shed, while neglecting the proposed design of the plant itself, which is far more important and a far more difficult and complex task.
</p><p>The law has been applied to software development and other activities. The terms <b>bicycle-shed effect</b>, <b>bike-shed effect</b>, and <b>bike-shedding</b> were coined based on Parkinson's example; it was popularized in the Berkeley Software Distribution community by the Danish software developer Poul-Henning Kamp in 1999 and, due to that, has since become popular within the field of software development generally.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Law_of_triviality'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Law of Triviality</h2>
<a href='https://en.wikipedia.org/wiki/Law_of_triviality' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">

</p><p>The <b>law of triviality</b> is C. Northcote Parkinson's 1957 argument that people within an organization commonly give disproportionate weight to trivial issues. Parkinson provides the example of a fictional committee whose job was to approve the plans for a nuclear power plant spending the majority of its time on discussions about relatively minor but easy-to-grasp issues, such as what materials to use for the staff bicycle shed, while neglecting the proposed design of the plant itself, which is far more important and a far more difficult and complex task.
</p><p>The law has been applied to software development and other activities. The terms <b>bicycle-shed effect</b>, <b>bike-shed effect</b>, and <b>bike-shedding</b> were coined based on Parkinson's example; it was popularized in the Berkeley Software Distribution community by the Danish software developer Poul-Henning Kamp in 1999 and, due to that, has since become popular within the field of software development generally.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Law_of_triviality'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Conjunction fallacy</h2>
<a href='https://en.wikipedia.org/wiki/Conjunction_fallacy' target='_blank'>Wikipedia Link</a>
<div class='content'><p>A <b>conjunction effect</b> or <b>Linda problem</b> is a bias or mistake in reasoning where adding extra details (an "and" statement or logical conjunction; mathematical shorthand: <span><span><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle \land }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo>∧<!-- ∧ --></mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \land }</annotation>
  </semantics>
</math></span></span>) to a sentence makes it appear more likely. Logically, this is not possible, because adding more claims can make a true statement false, but cannot make false statements true: If <i>A</i> is true, then <i><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A\land B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
        <mo>∧<!-- ∧ --></mo>
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A\land B}</annotation>
  </semantics>
</math></span></span></i> might be false (if <i>B</i> is false). However, if <i>A</i> is false, then <i><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A\land B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
        <mo>∧<!-- ∧ --></mo>
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A\land B}</annotation>
  </semantics>
</math></span></span></i> will always be false, regardless of what <i>B</i> is. Therefore, <i><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle A\land B}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>A</mi>
        <mo>∧<!-- ∧ --></mo>
        <mi>B</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A\land B}</annotation>
  </semantics>
</math></span></span></i> cannot be more likely than <i>A</i>.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Conjunction_fallacy'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Occam's razor</h2>
<a href='https://en.wikipedia.org/wiki/Occam's_razor' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p><p>In philosophy, <b>Occam's razor</b> (also spelled <b>Ockham's razor</b> or <b>Ocham's razor</b>; Latin: <i lang="la">novacula Occami</i>) is the problem-solving principle that recommends searching for explanations constructed with the smallest possible set of elements. It is also known as the <b>principle of parsimony</b> or the <b>law of parsimony</b> (Latin: <i lang="la">lex parsimoniae</i>). Attributed to William of Ockham, a 14th-century English philosopher and theologian, it is frequently cited as <span title="Latin-language text"><i lang="la">Entia non sunt multiplicanda praeter necessitatem</i></span>, which translates as "Entities must not be multiplied beyond necessity", although Occam never used these exact words. Popularly, the principle is sometimes paraphrased as "of two competing theories, the simpler explanation of an entity is to be preferred."
</p><p>This philosophical razor advocates that when presented with competing hypotheses about the same prediction and both hypotheses have equal explanatory power, one should prefer the hypothesis that requires the fewest assumptions, and that this is not meant to be a way of choosing between hypotheses that make different predictions. Similarly, in science, Occam's razor is used as an abductive heuristic in the development of theoretical models rather than as a rigorous arbiter between candidate models.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Occam's_razor'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Less–is–better effect</h2>
<a href='https://en.wikipedia.org/wiki/Less-is-better_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>less-is-better effect</b> is a cognitive bias that causes people to favor a lesser option when it is presented separately, but to prefer the better option when both are presented together. The term was first proposed by Christopher Hsee.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Less-is-better_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Misattribution of memory</h2>
<a href='https://en.wikipedia.org/wiki/Misattribution_of_memory' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In psychology, the <b>misattribution of memory</b> or <b>source misattribution</b> is the misidentification of the origin of a memory by the person making the memory recall. Misattribution is likely to occur when individuals are unable to monitor and control the influence of their attitudes, toward their judgments, at the time of retrieval. Misattribution is divided into three components: cryptomnesia, false memories, and source confusion. It was originally noted as one of Daniel Schacter's seven sins of memory.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Misattribution_of_memory'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Source confusion</h2>
<a href='https://en.wikipedia.org/wiki/Misattribution_of_memory#Source_confusion' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In psychology, the <b>misattribution of memory</b> or <b>source misattribution</b> is the misidentification of the origin of a memory by the person making the memory recall. Misattribution is likely to occur when individuals are unable to monitor and control the influence of their attitudes, toward their judgments, at the time of retrieval. Misattribution is divided into three components: cryptomnesia, false memories, and source confusion. It was originally noted as one of Daniel Schacter's seven sins of memory.
</p>

<h2 data-mw-anchor="Components_of_misattribution">Components of misattribution</h2>
<h3 data-mw-anchor="Cryptomnesia">Cryptomnesia</h3>

<p>Cryptomnesia is a form of misattribution. It involves the unconscious influence of memory that causes current thoughts to be wrongfully attributed as novel. In other words, individuals mistakenly believe that they are the original generators of the thought. When cryptomnesia arises in literature or scholarly ideas it is often termed 'inadvertent plagiarism', inadvertent because the subject genuinely believes the idea to be their own creation. Inadvertent plagiarism takes two forms. The first involves the plagiarizer regenerating a previously seen idea, but believing the idea to be novel. In the second form, the plagiarizer recalls the ideas of other author's as their own. For example, a person may falsely recall creating an idea, thought, or joke, not intentionally engaging in plagiarism, but nevertheless believing to be the original source of memory.
</p>
<h3 data-mw-anchor="False_memory">False memory</h3>

<p>False memories are memories that individuals believe and recall as true that, in fact, never occurred. Often, people form false memories for details of events after hearing others mistakenly report information about an event. For example, participants who watch a video of a crime featuring a blue car but hear the car misleadingly referred to as white after the fact may create a false memory of a white car present at the scene of the crime, rather than a blue one. False memories can range from small details about an event to entire events that never happened, such as being lost in a crowded shopping mall as a child.
</p>
<h3 data-mw-anchor="Source_confusion">Source confusion</h3>

<p>Source confusion is an attribute seen in different people's accounts of the same event after hearing people speak about the situation. An example of this would be, a witness who heard a police officer say he had a gun and then that witness later says they saw the gun. Understanding the source of one's memories is important to memory processes necessary for every day living. Memories arise both from perceptual experiences and from one's thoughts, feelings, inferences, and imagination. Source monitoring theory postulates that memory errors occur when perceptual information is incorrectly attributed as being the source of a past experience. This may take place because one event shares the characteristics of another source. When a person has many sources of perceptual information about an event, their brain is easily able to evoke a memory of that event, even if they did not experience it, thus creating a misattributed memory.
</p><p>In one particular case of source confusion, a female rape survivor falsely accused a memory doctor of being her rapist. In this case, the doctor had made a television appearance seen by the female survivor prior to her attack. The woman misattributed the doctor's face with that of her attacker. An additional example of source confusion involves Ronald Reagan. In this instance, Ronald Reagan tells a story about a heroic pilot to whom he personally awarded a medal. However, he was actually recalling the story line from a theatrical production entitled "Wing and a Prayer". However, he strongly believed that he was involved in the medal process to this war hero.
</p>
<h2 data-mw-anchor="Causes">Causes</h2>

<h3 data-mw-anchor="Cognitive_causes">Cognitive causes</h3>
<h4 data-mw-anchor="Causes_of_cryptomnesia">Causes of cryptomnesia</h4>

<p>Cryptomnesia is a source-monitoring error in which people often have difficulty determining whether a concept was internally generated or experienced externally. People occasionally misattribute the creation of a novel thought or idea as their own, when in fact they are retrieving it from a previous experience. Some individuals fail to establish memories with enough detail to generate a source attribution, causing a misattribution of memory to the wrong source. People often truly believe that the information they plagiarized was actually that of their own.
</p><p>Unintentional plagiarism is greater for information generated by others than ourselves. Researchers believe this may due to having better memory and associations for words we generate, as self-generated information is better remembered later. Moreover, cryptomnesia increases when information is generated by others before a self-generated idea. This may be due to the likelihood that people were thinking of their next response, rather than processing the source of the information.
</p>
<h4 data-mw-anchor="Causes_of_false_memories">Causes of false memories</h4>
<p>False recognition can occur as the result of making an implicit associative response, an automatic association between two concepts in memory. It is believed that associative responses never come to conscious attention, thus the activation of the concept is assumed to be implicit. An implicit associative response has shown to arise when seeing a word such as "car", might cause people to unconsciously think of an associative such as "truck". If the word truck is later presented to them, they may state they recognize seeing the item when they had actually generated it themselves. It is believed that the activation from the shown word may also activate the associative word, allowing the information to be easily accessible to the mind. Research has also shown that the more similar the presented and associative words are, or the more similar list items there are, the more likely it is that a false recognition error will be made.
</p><p>Gist-based similarity, the robust encoding of semantic information rather than distinctive encoding, is another cause of false recognition. When studying a list of numerous related words, there is a high level of semantic overlap between memory items. The inability to keep each concepts separate and distinct from one another makes it difficult to recollect specific details, subsequently causing people to make responses based on memory gist's rather than specific details. People may form a well-organized idea of what the semantic gist is, and anything that is semantically similar to that idea may be falsely recognized. Gist-based similarity has also been shown to occur in circumstances in which implicit associative responses are an unlikely source of misattribution. The false recognition error also becomes evident when a time pressure is presented during a recognition decision. Processes that work to discover a source for the basis of recognition take time to execute, as a result of a lack of time, false recognitions errors are made more often.
</p><p>Fuzzy-trace theory, an opposing theory to source monitoring error, stipulates that memories are composed of two components; gist and verbatim traces. Verbatim traces are the surface details of physical stimuli, which encompass the clear visual images and source information of an experience. Though both traces are encoded simultaneously, they are stored in separate regions of the brain, allowing for each trace to posse a distinct lifespan. Verbatim traces, though readily available when a memory is first encoded, deteriorate quickly. Fuzzy-trace theory thus proposes that misattributed memories arise due to the short lifespan of verbatim traces, being that the quality of source information is rapidly declining. The misattribution of memory is therefore more likely to occur as the time between the encoding of an experience and the recall of the subsequent memory increases.
</p><p>It has also been noted that misattribution may be a product of adaptive features of memory, rather than a product of a flaw in the memory system. The misattribution error often leads to conclusions of an inefficient memory system, however some researchers believe that the error is a cost associated with the benefits of a functioning and adequate memory system. The misattribution error reflects an adaptive memory system in which information that does not require people to remember all the specific details is lost. Specific details would only be preserved in situations where the specific details need to be remembered, such as memories of a highly emotional experience. The use of semantic gists may be a fundamental mechanism of memory, allowing people to categorize information and generalize across situations, a function associated with higher intelligence.
</p>
<h3 data-mw-anchor="Neurological_causes">Neurological causes</h3>
<h4 data-mw-anchor="Neurological_basis_of_false_recognition">Neurological basis of false recognition</h4>
<p>Brain-damaged patients have provided useful insights into the underlying biological mechanisms involved in false recognition. Results from studies comparing levels of false recognition between patients with frontal lobe damage and age-matched controls, showed a significantly higher level of false recognition amongst the frontal lobe damaged individuals. The damage is believed to have caused disruptions in the adequate encoding of item-specific details or caused defective retrieval monitoring processes. These types of processes are needed to accurately recall the origins of memory representations, and without them, errors of origin can be made. Studies of false recognition in amnesic patients with damage to either the medial temporal lobe or other diencephalon structures, have demonstrated that the same processes involved in accurate recognition, are also involved in false recognition. These cortices play a role in strategic monitoring processing, as they attempt to examine other cortical outputs. If these cortices were damaged, there would be no control over the cortical outputs, increasingly the likelihood of a false recognition error. Additionally, patients with amnesia or Alzheimer's disease have a reduced level of false recognition, believed to be caused by taking too many trials to create the semantic gist information needed for the attribution error.
</p>
<h4 data-mw-anchor="False_memories_and_PET_scans">False memories and PET scans</h4>
<p>A follow-up to the previous research was conducted by Daniel L. Schacter and colleagues. Similar to the study by Henry L. Roediger and Kathleen McDermott, subjects were read a list of associated words before they went into the PET scanner. During the first scan, subjects would make recognition judgments to determine what were the previous presented words. During the second scan, subjects had to make judgments about words that were not presented. For example: bed, rest, dream, tired, and awake would be in the list but not the word "sleep". As with the study by Henry L. Roediger and Kathleen McDermott, subjects claimed to remember similar amounts of non-presented words as they did the words that were actually presented. The researchers noted that brain activity during the true and false recognition tasks were very similar. Monitoring the blood flow in the brain revealed there were in the left medial temporal lobe for both veridical and illusory recognition.
</p><p>That is not to say that there were not differences. While monitoring blood flow in the brain during false recognition, a part of the frontal lobe that is thought to be a key monitor of memories actually showed greater activity when presented with a false recognition than with a true one. There seemed to be some discrepancy as subjects attempted to scrutinize the out-placed words, but were overcome by powerful memory illusion. This study demonstrates the ability of technology to help researchers understand to a greater extent the power of false memories.
</p>
<h4 data-mw-anchor="Source_confusion_and_FMRI_scans">Source confusion and FMRI scans</h4>
<p>T. Awipi and L. Davachi sought to provide evidence of competing subregions in the medial temporal lobe (MTL) that differed on the type of content they encoded. The researchers conducted a study in which subjects were asked to perform an encoding task in a functional magnetic resonance imaging (FMRI) scanner, where they were presented with 192 full colour photographs of scenes (containing a centrally presented novel scene and a smaller image of one of six objects). Participants were also instructed to imagine using the presented object in each scene, and were asked to report whether they were successful. A memory test was administered after participants were removed from the scanner. The test consisted of all previously viewed scenes (old) and an equal number of novel scenes (new). They were asked to make an old/new judgement, and if the scene was responded as being old, they were asked to report it as being "remembered" or "familiar". They were then asked to pick an object that was paired with that scene. The researchers were trying to determine the levels of activation for source recollection for the objects paired with the scene during encoding.
</p><p>The researchers found that perirhinal cortex activation was greater for objects recalled, and parahippocampal cortex activation was greater when scenes were recalled. The results provide evidence of distinct encoding activation in the subregions of the medial temporal lobe. The first subregion is the perirhinal cortex, which encodes item information. The second subregion, the parahippocampal cortex, is involved in source information. The evidence provides support for the role of the right perirhinal cortex in attributing an object to the right source. As decreased activation was associated with poorer performance, decreased activation of the right perirhinal cortex could be a possible mechanism for source confusion.
</p>
<h2 data-mw-anchor="Experimental_research">Experimental research</h2>
<h3 data-mw-anchor="Misattribution">Misattribution</h3>
<p>In one of the earliest studies involving misattribution, the Canadian cognitive psychologist Bruce Whittlesea presented subjects with a list of common words. Each word was briefly displayed to the subject. The task required the subject to judge whether a target word was semantically related to any word in the list. Unlike Whittlesea's first experiment involving the recognition of target words, this study involved the manipulation of processing fluency through the conceptual context of the target word, rather than the physical context. After the subjects were given a brief moment to study the list of words, the subjects were presented with sentences that would contain a word that was capitalized at the end of the sentence that would have either been, or not been, from the previously presented list. The word at the end of the sentence was either highly predictable given the context of the sentence, for example: "The stormy seas tossed the BOAT", or the end word was less predictable such as: "She saved her money and bought a LAMP". The subjects were then required to state whether the capitalized end word had appeared, or not, on the previous list of words. If not, they were to respond by saying that the word was "new" versus it being "old".
</p><p>The study revealed that the new words that were highly predictable were more likely to be incorrectly identified as being previously seen, whereas the new words that were less predictable were not so identified. In fact, subjects actually named predictable words faster than they did unpredictable words. Whittlesea was able to conclude from this study that subjects misattributed their fast responses for highly predictable words as an indication that they had previously experienced the word whereas in fact that was incorrect. As a result, the fluency of processing caused the subjects to misinterpret their quickness as a case of familiarity.
</p>
<h3 data-mw-anchor="Cryptomnesia_2">Cryptomnesia</h3>

<p>Some of the most common experimental designs in the study of cryptomnesia involve solving word puzzles. One such study from Stanford University in 1993 monitored subjects' memory for solutions found to a word puzzle game when paired against a computer opponent. After several rounds of generating solutions in turn, participants were asked to generate a list of solutions they provided themselves, or a list of new solutions and rate their confidence in the source of each solution listed. Subjects were more likely to plagiarize solutions given by the computer opponent than their own solutions after indicating that they were very confident that the solution was truly novel; when subjects indicated that they were "guessing" whether the solution had been seen before, they were more likely to duplicate solutions they had found during the first round of the test.
</p><p>In an extension of this test, after each puzzle solution was generated, participants were asked one of two questions: is this word greater than 3 letters long? (physical judgement) or does this word have a positive connotation? (semantic judgement). Participants then generated lists of solutions as in the first test. While the same correlation of confidence level and error type were seen, participants were much more likely to plagiarize answers after making a physical judgement as compared to a semantic one.
</p>
<h3 data-mw-anchor="False_memories">False memories</h3>
<h4 data-mw-anchor="Deese—Roediger—McDermott_Paradigm" data-mw-fallback-anchor="Deese.E2.80.94Roediger.E2.80.94McDermott_Paradigm">Deese—Roediger—McDermott Paradigm</h4>
<p>Researchers Henry L. Roediger and Kathleen McDermott conducted an experiment in 1995 that dealt with a procedure developed by James Deese. This procedure, known as the Deese–Roediger–McDermott paradigm, invites subjects to believe they have experienced a particular word in a given list. The subjects are read a list of associated words by the experimenter. These associated words could be for example: bed, rest, dream, tried, awake, etc. After the subjects have heard these words, they are required to engage in a free recall task in which they must list the words they have heard. The researchers carried out two experiments. The first one involved six lists of associated words. The second experiment involved a wider set of materials, in which twenty-four 15-item lists were read to the subjects.
</p><p>The results of both experiments demonstrated that the subjects were confident about their incorrect answers regarding words heard in the list. For example, given the list; bed, rest, dream, tired, awake. Many of the subjects heard "sleep" which was not one of the words presented. This false memory effect occurs because the words associated with sleep are in the list leading subjects to believe that the words associated with the words provided in the list have to be right. In fact, with the second experiment the results were 55% false recall rate compared to 40% for the first experiment. This indicated that the more words and lists available the harder it is to actually recall words correctly. This experiment illustrates how subjects can provide false recall without noticing their errors. Even after the researchers indicate that they did not say the mistaken words, subjects still felt very convinced that the researcher had said the word.
</p>
<h4 data-mw-anchor="Implanting_a_false_memory">Implanting a false memory</h4>
<p>False memories can also be created through leading questioning and simple use of imagination. In 1996, Ira Hyman Jr. and Joel Petland published a study showing that subjects can falsely 'remember' anecdotes from their childhood, based on suggestions from the researcher and corroboration of these fictitious events from family members. Subjects' parents were interviewed to create a list of memorable childhood events (vacations, instances of being lost, etc.), to which one false event was added, namely spilling a bowl of punch at wedding reception. For each event, subjects were provided with several cues to aid in memory (age at the time, location, nature of the event, etc.) and asked to describe the situation in as much detail as possible. If a participant was unable to recall any event, they were asked either to quietly think about the event for about a minute and then provide any additional information remembered (control condition) or imagine the event happening and describe the people who would have been involved, what the location would have looked like and how the event might have occurred (imagery condition).
</p><p>After three interviews in this fashion, 25% of participants from the imagery condition reported remembering the false situation of spilling the punch bowl, as compared to fewer than 10% of subjects in the control condition. An overall improvement in the detail of responses given and the confidence of those responses was observed for both true and false memories in the imagery condition, while those in the control condition showed much less improvement. While participants who 'remembered' the false situation rated this event as being less emotionally intense than the other remembered true events, participants rated their confidence in accurately remembering the false scenario higher than any of the true events.
</p><p>In a similar study, researchers convinced participants that they had played a prank on a first grade teacher involving toy slime. In the experimental condition, researchers added self-relevant details to the story (obtained from the participants' parents), such as the name of the participant's first grade teacher and childhood best friend; in other conditions, the participants were told a more generic version of the story. When interviewed, 68.2% of participants in the self-relevant details condition reported mental images and memories of the false event, compared to only 36.4% of participants in the more generic condition. Thus, the presence of specific personal details from a participant's life greatly increase the chance that a false memory is successfully implanted.
</p>
<h3 data-mw-anchor="False_memories_and_flashbulb_memories">False memories and flashbulb memories</h3>
<p>False memories are also related to flashbulb memories, which are memories of one's circumstances during an emotionally charged event. Examples of flashbulb memories include how one remembers learning about the explosion of the Challenger shuttle, the attacks on the World Trade Center on September 11, or any other severely traumatic or outstanding event in a person's life.
</p><p>Early research done by Brown and Kulik (1977) found that flashbulb memories were similar to photographs because they could be described in accurate, vivid detail. In this study, participants described their circumstances about the moment they learned of the assassination of President John F. Kennedy as well as other similar traumatic events. Participants were able to describe what they were doing, things around them, and other details. However, this data was collected just once, years after the event, and Brown and Kulik were not able to compare the accuracy of those recollections to previous descriptions to see if their memories were indeed comparable to photographs.
</p><p>Later studies used a research technique called repeated recall to gauge the accuracy of repeated descriptions of traumatic events. Neiser and Harsh (1992) gave participants a questionnaire about the 1986 Challenger explosion at two periods of time: 1) The day after the incident, and 2) Three years later. They found that there were often large discrepancies between the first and second descriptions. For example, many initially reported that they heard the news while sitting in class, but later said that they remember seeing the news on a television broadcast. While the participants were confident in their reports, it became evident that their memories of these emotionally charged events were prone to being manipulated with time, and that false memories of details make their way into memory. One explanation of why false details exist in memories is that people are influenced by life experiences, and they therefore recall memories with insights from other non-related events.
</p>
<h2 data-mw-anchor="Applications">Applications</h2>
<h3 data-mw-anchor="Eyewitness_testimony_in_children">Eyewitness testimony in children</h3>
<p>In legal testimony, the fact that witnesses are under oath does not preclude the occurrence of unintentional false reports: false memory and cryptomnesia present a significant problem in cases of alleged child abuse, in which the principal witness is already at a memory disadvantage. While individual differences exist, it is widely accepted that young children are highly susceptible to leading questioning and biased interviewing techniques, due to their insufficient cognitive development. A wide variety of studies on the subject have revealed that children become more accurate in their recollections with increasing age and their ability to ignore biased questioning practices increases substantially until age 12. As a result, neutral wording is encouraged where a young child's testimony must be relied upon.
</p><p>However, the fallibility of children's memories is a complicated issue: memory does not strictly improve over time, but varies in the number of errors made as different skills are developed. Young children are very prone to suggestibility and false memories, even for false story-situations which they provided themselves. This is likely due to memory compensation strategies of imagery and imagination employed at an early age. As children age, other memory strategies such as auditory rehearsal or use of schemas and semantic relationships replace the reliance on imagery, leading to more reliable memories for events, but also presenting greater opportunity for memory errors. By the time children reach high school, memory strategies such as audial rehearsal, schema formation and semantic relatedness become more common; this presents an increased likelihood for memory errors, such as those seen in the Deese–Roediger–McDermott paradigm.
</p>
<h3 data-mw-anchor="Eyewitness_testimony_in_adults">Eyewitness testimony in adults</h3>
<p>As noted, misattribution is likely to occur when individuals are unable to monitor and control the influence of their attitudes at the time of retrieval. Hence, researchers have applied techniques to minimize misattribution by encouraging individuals to focus on distinctive characteristics, rather than on properties that may elicit the influence of personal attitudes. One important question under consideration, is whether people confuse misleading suggestions and personal attitudes for their real memories of a witnessed event. Moreover, misattribution of memory has been especially well investigated in terms of its application to cases of potential eyewitness suggestibility. Currently, researchers have focused on determining the circumstances under which misattribution might occur, and the factors that could increase or decrease these errors, in an eyewitness situation.
</p><p>In terms of eyewitness testimony, judgements of memory credibility are particularly important in their persuasive impact. At any stage of a legal case, the success or failure of eyewitness persuasion can have consequences. Generally speaking, people assume the testimony of an adult to be more credible and accurate, based on the assumption that adults are better memory reporters. In this context, children are assumed to have poor memory capabilities. Eyewitness testimony in adults differs from that of children in a few other ways. Firstly, adults tend to provide more recalled information, whether accurate or inaccurate, to a legal case. Although, the general pattern is to have an increase the amount of correctly recalled information with age. Lastly, objective questions are more accurately answered with less influence of suggestibility in adults.
</p>
<h3 data-mw-anchor="Source_confusion_in_later_life">Source confusion in later life</h3>

<p>Successful remembering involves recognition that something is familiar and recall of the context in which it was previously experienced. With age, the ability to discriminate between new and previous events begins to fail, and errors in recalling experiences become more common. Larry Jacoby of New York University (1999) demonstrated how common these errors can become, lending a better understanding to why recognition errors are particularly common in Alzheimer's disease. In Jacoby's study, participants were given two lists of words: one to read and one which they would hear read aloud. All subjects were then given a "test" list which contained some words they had read, some they had heard, and some novel words; the subjects had to determine which words were which. Jacoby found that university students and 75-year-olds were equally likely to correctly recognize whether or not the word had been presented, but 75-year-olds were much more likely to mistake whether the word was spoken or read. In other words, while recognition of familiar versus novel words remained relatively stable across age groups, source confusion increased dramatically with age.
</p><p>Cohen and Faulkner discovered similar age-related source confusion errors ten years earlier when studying short events rather than word lists. Participants were asked to carry out, imagine, or watch a series of short events (placing a fork on top of a plate, putting a pen inside a mug, etc.). They were later asked whether specific events were familiar and how they happened. The study revealed that elderly subjects were more likely than younger subjects to claim that they recognized events that never happened. Additionally, these participants were more likely to say that they watched specific actions occurring when they had actually either imagined them occurring or had never experienced the actions.
</p><p>These studies show that simply rehearsing material may not always work to improve memory. In the Jacoby study, older adults who read a word several times were likely to accurately judge it as familiar but were then more likely to think they had heard the word read aloud, rather than reading it themselves. Jacoby explains that— because repetition of a word caused recognition to go up but ability to correctly remember the source to go down— recognition and source monitoring are likely separate neurological processes. This may shed some light on the common phenomenon of Alzheimer's patients mistaking frequently presented non-famous faces as being those of celebrities or asking the same question repeatedly. Patients may recognize faces or identify that the subject of the question is important and was discussed recently, but they have no memory for the meaning attached to these common stimuli and so will misattribute this familiarity or simply ask again.
</p>
<h2 data-mw-anchor="References">References</h2></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Misattribution_of_memory#Source_confusion'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Cryptomnesia</h2>
<a href='https://en.wikipedia.org/wiki/Cryptomnesia' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Cryptomnesia</b> occurs when a forgotten memory returns without its being recognized as such by the subject, who believes it is something new and original. It is a memory bias whereby a person may falsely recall generating a thought, an idea, a tune, a name, or a joke; they are not deliberately engaging in plagiarism, but are experiencing a memory as if it were a new inspiration.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Cryptomnesia'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>False memory</h2>
<a href='https://en.wikipedia.org/wiki/False_memory' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>

<p class="mw-empty-elt">
</p><p>In psychology,  a <b>false memory</b> is a phenomenon where someone recalls something that did not actually happen or recalls it differently from the way it actually happened. Suggestibility, activation of associated information, the incorporation of misinformation, and source misattribution have been suggested to be several mechanisms underlying a variety of types of false memory.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/False_memory'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Suggestibility</h2>
<a href='https://en.wikipedia.org/wiki/Suggestibility' target='_blank'>Wikipedia Link</a>
<div class='content'><p>
<b>Suggestibility</b> is the quality of being inclined to accept and act on the suggestions of others. One may fill in gaps in certain memories with false information given by another when recalling a scenario or moment. Suggestibility uses cues to distort recollection: when the subject has been persistently told something about a past event, his or her memory of the event conforms to the repeated message.
</p><p>A person experiencing intense emotions tends to be more receptive to ideas and therefore more suggestible. Generally, suggestibility decreases as age increases. However, psychologists have found that individual levels of self-esteem and assertiveness can make some people more suggestible than others; this finding led to the concept of a spectrum of suggestibility.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Suggestibility'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Spacing effect</h2>
<a href='https://en.wikipedia.org/wiki/Spacing_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">

</p>

<p>The <b>spacing effect</b> demonstrates that learning is more effective when study sessions are spaced out.  This effect shows that more information is encoded into long-term memory by spaced study sessions, also known as <i>spaced repetition</i> or <i>spaced presentation</i>, than by massed presentation ("cramming").
</p><p>The phenomenon was first identified by Hermann Ebbinghaus, and his detailed study of it was published in the 1885 book <span title="German-language text"><i lang="de">Über das Gedächtnis. Untersuchungen zur experimentellen Psychologie</i></span> (<i>Memory: A Contribution to Experimental Psychology</i>), which suggests that active recall with increasing time intervals reduces the probability of forgetting information. This robust finding has been supported by studies of many explicit memory tasks such as free recall, recognition, cued-recall, and frequency estimation (for reviews see Crowder 1976; Greene, 1989).
</p><p>Researchers have offered several possible explanations of the spacing effect, and much research has been conducted that supports its impact on recall.  In spite of these findings, the robustness of this phenomenon and its resistance to experimental manipulation have made empirical testing of its parameters difficult.
</p><p>While many others have contributed important research regarding the spacing effect, Robert Bjork and his associates in the Bjork Learning and Forgetting Lab and Cogfog group at UCLA have performed much research into various aspects of this phenomenon as well as into its practical application for education.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Spacing_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Implicit association</h2>
<a href='https://en.wikipedia.org/wiki/Implicit_stereotype' target='_blank'>Wikipedia Link</a>
<div class='content'><p>An <b>implicit bias</b> or <b>implicit stereotype</b> is the pre-reflective attribution of particular qualities by an individual to a member of some social out group.
</p><p>Implicit stereotypes are thought to be shaped by experience and based on learned associations between particular qualities and social categories, including race and/or gender. Individuals' perceptions and behaviors can be influenced by the implicit stereotypes they hold, even if they are <i>sometimes</i> unaware they hold such stereotypes. Implicit bias is an aspect of implicit social cognition: the phenomenon that perceptions, attitudes, and stereotypes can operate prior to conscious intention or endorsement. The existence of implicit bias is supported by a variety of scientific articles in psychological literature. Implicit stereotype was first defined by psychologists Mahzarin Banaji and Anthony Greenwald in 1995.
</p><p><b>Explicit stereotypes</b>, by contrast, are consciously endorsed, intentional, and sometimes controllable thoughts and beliefs.
</p><p>Implicit biases, however, are thought to be the product of associations that were learned through <i>past</i> experiences. Implicit biases can be activated by the environment and operate prior to a person's intentional, conscious endorsement. Implicit bias can persist even when an individual rejects the bias explicitly.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Implicit_stereotype'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Implicit stereotypes</h2>
<a href='https://en.wikipedia.org/wiki/Implicit_stereotype' target='_blank'>Wikipedia Link</a>
<div class='content'><p>An <b>implicit bias</b> or <b>implicit stereotype</b> is the pre-reflective attribution of particular qualities by an individual to a member of some social out group.
</p><p>Implicit stereotypes are thought to be shaped by experience and based on learned associations between particular qualities and social categories, including race and/or gender. Individuals' perceptions and behaviors can be influenced by the implicit stereotypes they hold, even if they are <i>sometimes</i> unaware they hold such stereotypes. Implicit bias is an aspect of implicit social cognition: the phenomenon that perceptions, attitudes, and stereotypes can operate prior to conscious intention or endorsement. The existence of implicit bias is supported by a variety of scientific articles in psychological literature. Implicit stereotype was first defined by psychologists Mahzarin Banaji and Anthony Greenwald in 1995.
</p><p><b>Explicit stereotypes</b>, by contrast, are consciously endorsed, intentional, and sometimes controllable thoughts and beliefs.
</p><p>Implicit biases, however, are thought to be the product of associations that were learned through <i>past</i> experiences. Implicit biases can be activated by the environment and operate prior to a person's intentional, conscious endorsement. Implicit bias can persist even when an individual rejects the bias explicitly.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Implicit_stereotype'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Stereotypical bias</h2>
<a href='https://en.wikipedia.org/wiki/Implicit_stereotype' target='_blank'>Wikipedia Link</a>
<div class='content'><p>An <b>implicit bias</b> or <b>implicit stereotype</b> is the pre-reflective attribution of particular qualities by an individual to a member of some social out group.
</p><p>Implicit stereotypes are thought to be shaped by experience and based on learned associations between particular qualities and social categories, including race and/or gender. Individuals' perceptions and behaviors can be influenced by the implicit stereotypes they hold, even if they are <i>sometimes</i> unaware they hold such stereotypes. Implicit bias is an aspect of implicit social cognition: the phenomenon that perceptions, attitudes, and stereotypes can operate prior to conscious intention or endorsement. The existence of implicit bias is supported by a variety of scientific articles in psychological literature. Implicit stereotype was first defined by psychologists Mahzarin Banaji and Anthony Greenwald in 1995.
</p><p><b>Explicit stereotypes</b>, by contrast, are consciously endorsed, intentional, and sometimes controllable thoughts and beliefs.
</p><p>Implicit biases, however, are thought to be the product of associations that were learned through <i>past</i> experiences. Implicit biases can be activated by the environment and operate prior to a person's intentional, conscious endorsement. Implicit bias can persist even when an individual rejects the bias explicitly.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Implicit_stereotype'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Prejudice</h2>
<a href='https://en.wikipedia.org/wiki/Prejudice' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Prejudice</b> can be an affective feeling towards a person based on their perceived social group membership. The word is often used to refer to a preconceived (usually unfavourable) evaluation or classification of another person based on that person's perceived personal characteristics, such as political affiliation, sex, gender, gender identity, beliefs, values, social class, friendship, age, disability, religion, sexuality, race, ethnicity, language, nationality, culture, complexion, beauty, height, body weight, occupation, wealth, education, criminality, sport-team affiliation, music tastes or other perceived characteristics.
</p><p>The word "prejudice" can also refer to unfounded or pigeonholed beliefs and it may apply to "any unreasonable attitude that is unusually resistant to rational influence". Gordon Allport defined prejudice as a "feeling, favorable or unfavorable, toward a person or thing, prior to, or not based on, actual experience". Auestad (2015) defines prejudice as characterized by "symbolic transfer", transfer of a value-laden meaning content onto a socially-formed category and then on to individuals who are taken to belong to that category, resistance to change, and overgeneralization.
</p><p>The United Nations Institute on Globalization, Culture and Mobility has highlighted research considering prejudice as a  global security threat due to its use in scapegoating some populations and inciting others to commit  violent acts towards them and how this can endanger individuals, countries, and the international community.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Prejudice'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Negativity bias</h2>
<a href='https://en.wikipedia.org/wiki/Negativity_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>negativity bias</b>, also known as the <b>negativity effect</b>, is a cognitive bias that, even when positive or neutral things of equal intensity occur, things of a more negative nature (e.g. unpleasant thoughts, emotions, or social interactions; harmful/traumatic events) have a greater effect on one's psychological state and processes than neutral or positive things.  In other words, something very positive will generally have less of an impact on a person's behavior and cognition than something equally emotional but negative.  The negativity bias has been investigated within many different domains, including the formation of impressions and general evaluations; attention, learning, and memory; and decision-making and risk considerations.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Negativity_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Fading affect bias</h2>
<a href='https://en.wikipedia.org/wiki/Fading_affect_bias' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>fading affect bias</b>, more commonly known as <b>FAB</b>, is a psychological phenomenon in which memories associated with negative emotions tend to be forgotten more quickly than those associated with positive emotions. FAB only refers to the feelings one has associated with the memories and not the content of the memories themselves. Early research studied FAB retrospectively, or through personal reflection, which brought about some criticism because retrospective analysis can be affected by subjective retrospective biases. However, new research using non-retrospective recall studies have found evidence for FAB, and the phenomenon has become largely accepted.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Fading_affect_bias'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Peak–end rule</h2>
<a href='https://en.wikipedia.org/wiki/Peak–end_rule' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>peak–end rule</b> is a psychological heuristic in which people judge an experience largely based on how they felt at its peak (i.e., its most intense point) and at its end, rather than based on the total sum or average of every moment of the experience. The effect occurs regardless of whether the experience is pleasant or unpleasant. To the heuristic, other information aside from that of the peak and end of the experience is not lost, but it is not used. This includes net pleasantness or unpleasantness and how long the experience lasted. The peak–end rule is thereby a specific form of the more general extension neglect and duration neglect.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Peak–end_rule'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Leveling and sharpening</h2>
<a href='https://en.wikipedia.org/wiki/Leveling_and_sharpening' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Leveling and sharpening</b> are two functions that are automatic and exist within memory. <i>Sharpening</i> is usually the way people remember small details in the retelling of stories they have experienced or are retelling those stories. <i>Leveling</i> is when people keep out parts of stories and try to tone those stories down so that some parts are excluded. Therefore, it makes it easier to fill in the memory gaps that exist.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Leveling_and_sharpening'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Misinformation effect</h2>
<a href='https://en.wikipedia.org/wiki/Misinformation_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>misinformation effect </b>occurs when a person's recall of episodic memories becomes less accurate because of post-event information. The misinformation effect has been studied since the mid-1970s. Elizabeth Loftus is one of the most influential researchers in the field. One theory is that original information and the misleading information that was presented after the fact become blended together. Another theory is that the misleading information overwrites the original information. Scientists suggest that because the misleading information is the most recent, it is more easily retrieved.
</p>

<p>The misinformation effect is an example of retroactive interference which occurs when information presented later interferes with the ability to retain previously encoded information. Individuals have also been shown to be susceptible to incorporating misleading information into their memory when it is presented within a question. Essentially, the new information that a person receives works backward in time to distort memory of the original event. One mechanism through which the misinformation effect occurs is source misattribution, in which the false information given after the event becomes incorporated into people's memory of the actual event. The misinformation effect also appears to stem from memory impairment, meaning that post-event misinformation makes it harder for people to remember the event. The misinformation reflects two of the cardinal sins of memory: <i>suggestibility</i>, the influence of others' expectations on our memory; and <i>misattribution,</i> information attributed to an incorrect source.
</p><p>Research on the misinformation effect has uncovered concerns about the permanence and reliability of memory. Understanding the misinformation effect is also important given its implications for the accuracy of eyewitness testimony, as there are many chances for misinformation to be incorporated into witnesses' memories through conversations with other witnesses, police questioning, and court appearances.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Misinformation_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Serial recall effect</h2>
<a href='https://en.wikipedia.org/wiki/Recall_(memory)#Serial_recall' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Recall</b> in memory refers to the mental process of retrieving information from the past. Along with encoding and storage, it is one of the three core processes of memory. There are three main types of recall: free recall, cued recall and serial recall. Psychologists test these forms of recall as a way to study the memory processes of humans and animals.
Two main theories of the process of recall are the two-stage theory and the theory of encoding specificity.
</p>

<h2 data-mw-anchor="Theories">Theories</h2>
<h3 data-mw-anchor="Two-stage_theory">Two-stage theory</h3>
<p>The <i>two-stage theory</i> states that the process of recall begins with a search and retrieval process, and then a decision or recognition process where the correct information is chosen from what has been retrieved. In this theory, recognition only involves the latter of these two stages, or processes, and this is thought to account for the superiority of the recognition process over recall. Recognition only involves one process in which error or failure may occur, while recall involves two. However, recall has been found to be superior to recognition in some cases, such as a failure to recognize words that can later be recalled.
</p><p>Another two stage theory holds that free recall of a list of items begins with the content in working memory and then moves to an associative search.
</p>
<h3 data-mw-anchor="Encoding_specificity">Encoding specificity</h3>
<p>The theory of <i>encoding specificity</i> finds similarities between the process of recognition and that of recall. The <i>encoding specificity principle</i> states that memory utilizes information from the memory trace, or the situation in which it was learned, and from the environment in which it is retrieved. In other words, memory is improved when information available at encoding is also available at retrieval. For example, if one is to learn about a topic and study it in a specific location, but take their exam in a different setting, they would not have had as much of a successful memory recall as if they were in the location that they learned and studied the topic in. Encoding specificity helps to take into account context cues because of its focus on the retrieval environment, and it also accounts for the fact recognition may not always be superior to recall.
</p>
<h2 data-mw-anchor="History">History</h2>
<p>Philosophical questions regarding how people acquire knowledge about their world spurred the study of memory and learning. Recall is a major part of memory so the history of the study of memory in general also provides a history of the study of recall.
</p>

<p>In 1885, Hermann Ebbinghaus created nonsense syllables, combinations of letters that do not follow grammatical rules and have no meaning, to test his own memory. He would memorize a list of nonsense syllables and then test his recall of that list over varying time periods. He discovered that memory loss occurred rapidly over the first few hours or days, but showed a more steady, gradual decline over subsequent days, weeks, and months. Furthermore, Ebbinghaus discovered that multiple learning, over-learning, and spacing study times increased retention of information. Ebbinghaus' research influenced much of the research conducted on memory and recall throughout the twentieth century.
</p><p>Frederic Bartlett was a prominent researcher in the field of memory during the mid-twentieth century. He was a British experimental psychologist who focused on the mistakes people made when recalling new information. One of his well-known works was <i>Remembering: A Study in Experimental and Social Psychology</i>, which he published in 1932. He is well known for his use of North American Native folk tales, including <i>The War of the Ghosts</i>. He would provide participants in his study with an excerpt from a story and then asked them to recall it as accurately as they could. Retention intervals would vary from directly after reading the story to days later. Bartlett found that people try to understand the overall meaning of the story. Since the folk tale included supernatural elements, people would rationalize them to make them fit better with their own culture. Ultimately, Bartlett argued that the mistakes that the participants made could be attributed to "schematic intrusions" - current knowledge interfering with recall.
</p><p>In the 1950s there was a change in the overall study of memory that has come to be known as the cognitive revolution. This included new theories on how to view memory, often likening it to a computer processing model. Two important books influenced the revolution: <i>Plans and Structures of Behavior</i> by George Miller, Eugene Galanter, and Karl H. Pribram in 1960 and <i>Cognitive Psychology</i> by Ulric Neisser in 1967. Both provided arguments for an information-processing view of the human mind. Allen Newell and Herbert A. Simon constructed computer programs that simulated the thought processes people go through when solving different kinds of problems.
</p><p>In the 1960s, interest in short-term memory (STM) increased. Before the 1960s, there was very little research that studied the workings of short-term memory and rapid memory loss. Lloyd and Margaret Peterson observed that when people are given a short list of words or letters and then are distracted and occupied with another task for few seconds, their memory for the list is greatly decreased.
Atkinson and Shiffrin (1973) created the short-term memory model, which became the popular model for studying short-term memory.
</p><p>The next major development in the study of memory recall was Endel Tulving's proposition of two kinds of memory: episodic and semantic. Tulving described episodic memory as a memory about a specific event that occurred at a particular time and place, for example what you got for your 10th birthday. Semantic memories are abstract words, concepts, and rules stored in long-term memory. Furthermore, Endel Tulving devised the encoding specificity principle in 1983, which explains the importance of the relation between the encoding of information and then recalling that information. To explain further, the encoding specificity principle means that a person is more likely to recall information if the recall cues match or are similar to the encoding cues.
</p><p>The 1960s also saw a development in the study of visual imagery and how it is recalled. This research was led by Allan Paivio, who found that the more image-arousing a word was the more likely it would be recalled in either free recall or paired associates.
</p><p>There has been a considerable amount of research into the workings of memory, and specifically recall since the 1980s. The previously mentioned research was developed and improved upon, and new research was and still is being conducted.
</p>
<h2 data-mw-anchor="Types">Types</h2>
<h3 data-mw-anchor="Free_recall">Free recall</h3>

<p>Free recall describes the process in which a person is given a list of items to remember and then is tested by being asked to recall them in any order. Free recall often displays evidence of primacy and recency effects. Primacy effects are displayed when the person recalls items presented at the beginning of the list earlier and more often. The recency effect is when the person recalls items presented at the end of the list earlier and more often. Free recall often begins with the end of the list and then moves to the beginning and middle of the list.
</p>
<h3 data-mw-anchor="Cued_recall">Cued recall</h3>
<p>Cued recall is when a person is given a list of items to remember and is then tested with cues to remember material. Researchers have used this procedure to test memory. Participants are given pairs, usually of words, A1-B1, A2-B2...An-Bn (n is the number of pairs in a list) to study. Then the experimenter gives the participant a word to cue the participant to recall the word with which it was originally paired. The word presentation can either be visual or auditory.
</p><p>There are two basic experimental methods used to conduct cued recall, the study-test method and the anticipation method. In the study-test method participants study a list of word pairs presented individually. Immediately after or after a time delay, participants are tested in the study phase of the experiment on the word pairs just previously studied. One word of each pair is presented in a random order and the participant is asked to recall the item with which it was originally paired. The participant can be tested for either forward recall, Ai is presented as a cue for Bi, or backward recall, Bi is presented as a cue for Ai. In the anticipation method, participants are shown Ai and are asked to anticipate the word paired with it, Bi. If the participant cannot recall the word, the answer is revealed. During an experiment using the anticipation method, the list of words is repeated until a certain percentage of Bi words are recalled.
</p><p>The learning curve for cued recall increases systematically with the number of trials completed. This result has caused a debate about whether or not learning is all-or-none. One theory is that learning is incremental and that the recall of each word pair is strengthened with repetition. Another theory suggests that learning is all-or-none, that is one learns the word pair in a single trial and memory performance is due to the average learned pairs, some of which are learned on earlier trials and some on later trials. To examine the validity of these theories researchers have performed memory experiments. In one experiment published in 1959, experimental psychologist Irvin Rock and colleague Walter Heimer of the University of Illinois had both a control group and an experimental group learn pairs of words. The control group studied word pairs that were repeated until the participants learned all the word pairs. In the experimental group, the learned pairs remained in the list while unlearned pairs were substituted with recombinations of previous words. Rock believed that associations between two items would be strengthened if learning were incremental even when pairs are not correctly recalled. His hypothesis was that the control group would have a higher correct recall probability than the experimental group. He thought that repetition would increase the strength of the word pair until the strength reaches a threshold needed to produce an overt response. If learning were all or none, then the control group and the experimental group should learn the word pairs at the same rate. Rock found experimentally there was little difference in learning rates between the two groups. However, Rock's work did not settle the controversy because in his experiment he rearranged replaced word pairs that could be either easier or harder to learn than the original words in the word- digit pair. In further experiments that addressed the question, there were mixed results. The incremental learning hypothesis is supported by the notion that awhile after Ai-Bi pairs are learned, the recall time to recall Bi decreases with continued learning trails.
</p><p>Another theory that can be tested using cued recall is symmetry of forward and backward recall. Forward recall is generally assumed to be easier than backward recall, i.e. forward recall is stronger than backward recall. This is generally true for long sequences of word or letters such as the alphabet. In one view, the independent associations hypothesis, the strength of forward and backward recall are hypothesized to be independent of each other. To confirm this hypothesis, Dr. George Wolford tested participants' forward and backward recall and found that forward and backward recall are independent of each other. The probability of correct forward recall was .47 for word pair associations and the probability of correct backward recall of word pair associations was .25. However, in another view, the associative symmetry hypothesis, the strengths of forward and backward recall are about equal and highly correlated. In S.E Asch from Swarthmore College and S. M Ebenholtz's experiment, participants learned pairs of nonsense syllables by anticipation recall. After reaching a certain threshold of learning, the participants were tested by free recall to determine all pairs and single items they could remember. These researchers found that backward association was greatly weaker than forward association. However, when the availability of forward and backward recall were basically the same, there was little difference between forward and backward recall. Some scientists including Asch and Ebenholtz believe in the independent association hypothesis think that the equal strengths of forward and backward recall are compatible with their hypothesis because forward and backward recall could be independent but with equal strengths. However associative symmetry theorists interpreted the data to mean that the results fit their hypothesis.
</p><p>Another study done using cued recall found that learning occurs during test trials. Mark Carrier and Pashler (1992) found that the group with a study-only phase makes 10% more errors than the group with a test-study phase. In the study-only phase, participants were given Ai-Bi, where Ai was an English word and Bi was a Siberian Eskimo Yupik word. In the test study phase, participants first attempted to recall Bi given Ai as a cue then they were shown Ai-Bi pair together. This result suggests that after participants learn something, testing their memory with mental operations helps later recall. The act of recalling instead of restudying creates new and longer lasting connection between Ai and Bi. This phenomenon is commonly referred to as the testing effect.
</p><p>Another study showed that when lists are tested immediately after study, the last couple of pairs are remembered best. After a five-second delay, the recall of recently studied words diminishes. However, word pairs at the beginning of a list still show better recall. Moreover, in a longer list, the absolute number of word pairs recalled is greater but in a shorter list of word pairs, the percentage of word pairs recalled is greater.
</p><p>Sometimes, when recalling word pairs, there is an intrusion. An intrusion is an error that participants make when they attempt to recall a word based on a cue of that word pair. Intrusions tend to have either semantic attributes in common with the correct word not recalled or have been previously studied in another word pair on the current list or a previously studied list or were close in time to the cue item. When two items are similar, an intrusion may occur. Professor Kahana and Marieke Vugt at the University of Pennsylvania examined the effects of face similarity for face-name associations. In the first experiment, they wanted to determine if performance of recall would vary with the number of faces in the study set that were similar to the cue face. Faces were similar if the radius of the faces were within a range. The number of faces within a radius is called a neighborhood density. They found that the recall of a name to face exhibited a lower accuracy and slower reaction time for faces with a greater neighborhood density. The more similarity that two faces have, the greater the probability for interference between the two faces. When cued with face A, name B may be recalled if face A and B are similar, which would signify that an intrusion has occurred. The probability of correct recall came from the number of faces that had other similar faces.
</p><p>Cues act as guides to what the person is supposed to remember. A cue can be virtually anything that may act as a reminder, e.g. a smell, song, color, place etc. In contrast to free recall, the subject is prompted to remember a certain item on the list or remember the list in a certain order. Cued recall also plays into free recall because when cues are provided to a subject, they will remember items on the list that they did not originally recall without a cue. Tulving explained this phenomenon in his research. When he gave participants associative cues to items that they did not originally recall and that were thought to be lost to memory, the participants were able to recall the item.
</p>
<h3 data-mw-anchor="Serial_recall">Serial recall</h3>
<p>Serial recall is the ability to recall items or events in the order in which they occurred. The ability of humans to store items in memory and recall them is important to the use of language. Imagine recalling the different parts of a sentence, but in the wrong order. The ability to recall in serial order has been found not only in humans, but in a number of non-human primate species and some non-primates. Imagine mixing up the order of phonemes, or meaningful units of sound, in a word so that "slight" becomes "style." Serial-order also helps us remember the order of events in our lives, our autobiographical memories. Our memory of our past appears to exist on a continuum on which more recent events are more easily remembered in order.
</p><p>Serial recall in long-term memory (LTM) differs from serial recall in short-term memory (STM). To store a sequence in LTM, the sequence is repeated over time until it is represented in memory as a whole, rather than as a series of items. In this way, there is no need to remember the relationships between the items and their original positions. In STM, immediate serial recall (ISR) has been thought to result from one of two mechanisms. The first refers to ISR as a result of associations between the items and their positions in a sequence, while the second refers to associations between items. These associations between items are referred to as chaining, and is an unlikely mechanism, according to research.  Position-item relationships do not account for recency and primacy effects, or the phonological similarity effect. The Primacy Model moves away from these two assumptions, suggesting that ISR results from a gradient of activation levels where each item has a particular level of activation that corresponds to its position. Research has supported the fact that immediate serial recall performance is much better when the list is homogenous (of the same semantic category) than when they are heterogeneous (of different semantic category). This suggests that semantic representations are beneficial to immediate serial recall performance. Short-term serial recall is also affected by similar-sounding items, as recall is lower (remembered more poorly) than items that do not sound alike. This is true when lists are tested independently (when comparing two separate lists of similar-sounding and not similar-sounding items) as well as when tested using a mixed list. Alan Baddeley first reported such an experiment in which items within a list were either mutually dissimilar or highly similar.
</p><p>There is evidence indicating that rhythm is highly sensitive to competing motor production. Actions such as paced finger tapping can have an effect on recall as the disruptive impact of paced finger tapping, but lack of consistent effect of paced irrelevant sound, is indicative of motor feedback from the tapping task disrupting rehearsal and storage.
</p><p>Eight different effects are generally seen in serial recall studies with humans:
</p>
<dl><dt>1. List length effect</dt>
<dd>Serial recall ability decreases as the length of the list or sequence increases.</dd></dl>
<dl><dt>2. Primacy and recency effects</dt>
<dd>Primacy effects refer to better recall of items earlier in the sequence, while recency effects refer to better recall of the last few items. Recency effects are seen more with auditory stimuli rather than verbal stimuli as auditory presentation seems to protect the end of lists from output interference.</dd></dl>
<dl><dt>3. Transposition gradients</dt>
<dd>Transposition gradients refer to the fact that recall tends to be better to recognize what an item is rather than the order of items in a sequence.</dd></dl>
<dl><dt>4. Item confusion errors</dt>
<dd>When an item is incorrectly recalled, there is a tendency to respond with an item that resembles the original item in that position.</dd></dl>
<dl><dt>5. Repetition errors</dt>
<dd>These occur during the recall of a sequence when an item from an earlier position in the sequence is given again in another position. This effect is fairly rare in humans.</dd></dl>
<dl><dt>6. Fill-in effects</dt>
<dd>If an item is recalled incorrectly at an earlier position than its original place, there is a tendency for the next item recalled to be the item that was displaced by this error. For example, if the sequence is '1234' and recall began '124', then the next item is likely to be '3'.</dd></dl>
<dl><dt>7. Protrusion effects</dt>
<dd>These occur when an item from a previous list or test is accidentally recalled on a new list or test. This item is likely to be recalled at its position from the original trial.</dd></dl>
<dl><dt>8. Word-length effects</dt>
<dd>Short words are recalled more accurately than longer words.</dd></dl>
<h2 data-mw-anchor="Neuroanatomy">Neuroanatomy</h2>
<p>The anterior cingulate cortex, globus pallidus, thalamus, and cerebellum show higher activation during recall than during recognition which suggests that these components of the cerebello-frontal pathway play a role in recall processes that they do not in recognition. Although recall and recognition are considered separate processes, they are both most likely constitute components of distributed networks of brain regions.
</p>
 

<p>According to neuroimaging data, PET studies on recall and recognition have consistently found increases in regional cerebral blood flow (RCBF) in the following six brain regions: (1) the prefrontal cortex, particularly on the right hemisphere; (2) the hippocampal and parahippocampal regions of the medial temporal lobe; (3) the anterior cingulate cortex; (4) the posterior midline area that includes posterior cingulate, retrosplenial (see retrosplenial region), precuneus, and cuneus regions; (5) the inferior parietal cortex, especially on the right hemisphere; and (6) the cerebellum, particularly on the left.
</p>

<p>The specific role of each of the six main regions in episodic retrieval is still unclear, but some ideas have been suggested. The right prefrontal cortex has been related to retrieval attempt; the medial temporal lobes to conscious recollection; the anterior cingulate to response selection; the posterior midline region to imagery; the inferior parietal to awareness of space; and the cerebellum to self-initiated retrieval .
</p>

<p>In recent research, a group of subjects was faced with remembering a list of items and then measured when trying to recall said items. The evoked potentials and hemodynamic activity measured during encoding were found to exhibit reliable differences between subsequently recalled and not recalled items. This effect has been termed the subsequent memory effect (SME). This difference in these specific brain regions determines whether or not an item is recalled. A study by Fernandez et al. has shown that the differences that predict recall appear both as a negative deflection in the rhinal cortex of an event-related potential (ERP) 400 ms after stimulus exposure, and as a positive hippocampal ERP beginning 800 ms after stimulus onset. This means that recall only occurs if these two brain regions (rhinal cortex and hippocampus) are activated in synchrony.
</p>
<h2 data-mw-anchor="Factors_that_affect_recall">Factors that affect recall</h2>
<h3 data-mw-anchor="Attention">Attention</h3>
<p>The effect of attention on memory recall has surprising results. It seems that the only time attention largely affects memory is during the encoding phase. During this phase, performing a parallel task can severely impair retrieval success. It is believed that this phase requires much attention to properly encode the information at hand, and thus a distractor task does not allow proper input and reduces the amount of information learned.
</p><p>One's attention to words is impacted by emotion grasping vocabulary. Negative and positive words are better recalled than neutral words that are spoken. Many different ways that attention is focused on hearing what the speaker has to say are the inflection of the presenter's voice in a sad, content, or frustrated sound or in the use of words that are close to the heart. A study was conducted to observe if the use of emotional vocabulary was a key receptor of recall memory. The groups were put into the same lecture halls and given the same speakers, but the results came back to determine that the inflection and word choice recalled by the listeners concluded that emotional words, phrases, and sounds are more memorable than neutral speakers.
</p><p>Recall memory is linked with instincts and mechanisms. In order to remember how an event happened, to learn from it or avoid an agitator, connections are made with emotions. For instance, if a speaker is very calm and neutral, the effectiveness of encoding memory is very low and listeners get the gist of what the speaker is discussing. On the other hand, if a speaker is shouting and/or using emotionally driven words, listeners tend to remember key phrases and the meaning of the speech. This is full access of the fight or flight mechanism all people have functioning in the brain, but based on what triggers this mechanism will lead to better recall of it. People tend to focus their attention on cues that are loud, very soft, or something unusual. This makes the auditory system pick up the differences in regular speaking and meaningful speech, when something significant is spoken in the discussion people home in on the message at that part of the speech but tend to lose the other part of the discussion. Our brains sense differences in speech and when those differences occur the brain encodes that part of speech into memory and the information can be recalled for future reference.
</p>
<h3 data-mw-anchor="Motivation">Motivation</h3>
<p>Motivation is a factor that encourages a person to perform and succeed at the task at hand. In an experiment done by Roebers, Moga and Schneider (2001), participants were placed in either forced report, free report or free report plus incentive groups. In each group, they found that the amount of correct information recalled did not differ, yet in the group where participants were given an incentive they had higher accuracy results. This means that presenting participants with an encouragement to provide correct information motivates them to be more precise. However, this is only true if the perception is that success is providing correct information. When it is believed that success is the completion of the task rather than the accuracy of that completion, the number of responses is higher, yet its accuracy is lowered. This shows that the results are dependent on how success is defined to the participant. In the referred experiment, the participants that were placed in the forced response group had the lowest overall accuracy; they had no motivation to provide accurate responses and were forced to respond even when they were unsure of the answer. Another study done by Hill RD, Storandt M, and Simeone C tested the impact of memory skills training and external reward on free recall of serial word lists. Effects similar to those reported in the previous study were seen in children—in contrast to older learners.
</p>
<h3 data-mw-anchor="Interference">Interference</h3>
<p>In the absence of interference, there are two factors at play when recalling a list of items: the recency and the primacy effects. The recency effect occurs when the short-term memory is used to remember the most recent items, and the primacy effect occurs when the long-term memory has encoded the earlier items. The recency effect can be eliminated if there is a period of interference between the input and the output of information extending longer than the holding time of short-term memory (15–30 seconds). This occurs when a person is given subsequent information to recall preceding the recall of the initial information. The primacy effect, however, is not affected by the interference of recall. The elimination of the last few items from memory is due to the displacement of these items from short-term memory, by the distracting task. As they have not been recited and rehearsed, they are not moved into long-term memory and are thus lost. A task as simple as counting backwards can change memory recall; however an empty delay interval has no effect. This is because the person can continue to rehearse the items in their working memory to be remembered without interference. Cohen (1989) found that there is better recall for an action in the presence of interference if that action is physically performed during the encoding phase. It has also been found that recalling some items can interfere and inhibit the recall of other items. Another stream of thought and evidence suggests that the effects of interference on recency and primacy are relative, determined by the ratio rule (retention interval to inter item presentation distractor rate) and they exhibit time-scale invariance.
</p>
<h3 data-mw-anchor="Context">Context</h3>
<p>Context-dependency effects on recall are typically interpreted as evidence that the characteristics of the environment are encoded as part of the memory trace and can be used to enhance retrieval of the other information in the trace. In other words, you can recall more when the environments are similar in both the learning and recall phases. Context cues appear to be important in the retrieval of newly learned meaningful information. In a classic study by Godden and Baddeley (1975), using free recall of wordlist demonstrated that deep-sea divers had better recall when there was a match between the learning and recalling environment. Lists learned underwater were recalled best underwater and lists learned on land were recalled best on land." An academic application would be that students may perform better on exams by studying in silence, because exams are usually done in silence.
</p>
<h3 data-mw-anchor="State-dependent_memory">State-dependent memory</h3>
<p>State-dependent retrieval is demonstrated when material learned under one State is best recalled in that same state. A study by Carter and Cassady (1998) showed this effect with antihistamine. In other words, if you study while on hay fever tablets, then you will recall more of what you studied if you test yourself while on antihistamines in comparison to testing yourself while not on antihistamines after having studied on antihistamines.
</p><p>A study by Block and Ghoneim (2000) found that, relative to a matched group of healthy, non-drug-using controls, heavy marijuana use is associated with small but significant impairments in memory retrieval.cannabis induces loss of internal control and cognitive impairment, especially impairment of attention and memory, for the duration of the intoxication period.
</p><p>Stimulants, such as cocaine, amphetamines or caffeine are known to improve recall in humans. However, the effect of prolonged use of stimulants on cognitive functioning is very different from the impact on one-time users. Some researchers have found stimulant use to lower recall rates in humans after prolonged usage. The axons, dendrites, and neurons wear out in many cases. Current research illustrates a paradoxical effect. The few exceptions undergo mental hypertrophy. Methylenedioxymethamphetamine (MDMA) users are found to exhibit difficulties encoding information into long-term memory, display impaired verbal learning, are more easily distracted, and are less efficient at focusing attention on complex tasks. The degree of executive impairment increases with the severity of use, and the impairments are relatively long-lasting. Chronic cocaine users display impaired attention, learning, memory, reaction time and cognitive flexibility. Whether or not stimulants have a positive or negative effect on recall depends on how much is used and for how long.
</p>
<h3 data-mw-anchor="Gender">Gender</h3>
<p>Consistently, females perform better than males on episodic memory tasks including delayed recall and recognition. However, males and females do not differ on working, immediate and semantic memory tasks. Neuro-psychological observations suggest that, in general, previous injuries cause greater deficits in females than in males. It has been proposed that the gender differences in memory performance reflect underlying differences in the strategies used to process information, rather than anatomical differences. However, gender differences in cerebral asymmetry received support from morphometric studies showing a greater leftward asymmetry in males than in females, meaning that men and women use each side of their brain to a different extent. There is also evidence for a negative recall bias in women, which means females in general are more likely than males to recall their mistakes. In an eyewitness study by Dan Yarmey in 1991, he found that women were significantly more accurate than men in accuracy of recall for weight of suspects.
</p><p>Studies have tested the difference between what men and women can recall after a presentation. Three speakers were involved, one being female and two being male. Men and women were put into the same lecture hall and had the same speaker talk to them. The results suggested that information presented by the women speaker was more easily recalled by all the members of the study. Researchers believe this to be a significant difference between genders because women's voices have better acoustics, ranging from low tones to high tones. Since their voices have this range, semantic encoding is increased for the pitches that stimulate the auditory component of the brain; this resonates better in the ear function. Since pitch ranges from low tones to high tones, it draws people's attention to the words attributed with the tone. As the tone changes, words stand out and from these differences memories can be stored. Recall is made easier since the association the brain can make is between words and sounds spoken.
</p><p>A distinguishing feature is how males and females process information and then recall what was presented to them. Females tend to remember nonverbal cues and associate the meaning of a discussion with gestures. Since males follow verbal cues they react more to the facts and actual words within a discussion to recall what was said, but fluctuations in the speaker's voice helps them maintain the memories. Another difference that sets males and females apart is recalling someone's voice. They tend to recall information they have read, for instance, lists of objects are better recalled for men than women. The only similarity they have is that when emotional words are used or an emotional tone is produced, males and females tend to recall those changes.
</p>
<h3 data-mw-anchor="Food_consumption">Food consumption</h3>

<p>There has been much research on whether eating prior to a cognitive recall test can affect cognitive functioning. One example was a study of the effect of breakfast timing on selected cognitive functions of elementary school students. Their results found that children who ate breakfast at school scored notably higher on most of the cognitive tests than did students who ate breakfast at home and also children who did not eat breakfast at all.
</p><p>In a study of women experiencing Premenstrual Syndrome, they were either given a placebo beverage or a carbohydrate-rich one. The patients were tested at home; their moods, cognitive performance, and food craving were measured before the consumption of the beverage and 30, 90, and 180 minutes after consumption. The results showed that the carbohydrate-rich beverage significantly decreased self-reported depression, anger, confusion, and carbohydrate craving 90 to 180 minutes after consumption. Memory word recognition also improved significantly.
</p>
<h3 data-mw-anchor="Physical_activity">Physical activity</h3>

<p>Studies have indicated that children who are inactive have poor health, but they also have poor cognitive health also. With low fitness there is a relationship to decreased cognitive functioning; for instance there are different types of cognitive problems like perception, memory, cognitive control, and there is lower academic achievement. Many tests have been conducted to identify what exactly is the reduction when children do not have physical activity. One test selected children to be in two different groups, one group was physically active the other group was not. After a while of monitoring the children the researchers tested the children in learning and recall memory to see what they were retaining and to observe the difference if available of low physical activity versus high physical activity. The results came back indicating that the children without physical activity have a later recall process than the children with physical activity. The learning part of the experiment was equally distributed on both spectrums for each group, but recall memory was the only variable that did not match both of the groups. 
Physical activity has a significant influence on the hippocampus, since this is the part of the brain that is responsible for encoding information into memory. With physical activity having such an impact on the hippocampus this can regulate other parts of the body as well like weight, memory, daily function, and many more processes that are necessary for the body to work. Since physical activity impacts all of these important parts of the brain, this form of exercise keeps the neural networks functioning well. Neural networks allow information to process and pass to the hippocampus in order to retain memory. This lets the brain be more efficient in processing and more memories are stored this way.
</p>
<h3 data-mw-anchor="Trauma_and_brain_exposure">Trauma and brain exposure</h3>

<p>There is barely any recalled memory in cases of fear and trauma exposure, brain injury, post-traumatic stress disorder, pain, or anxiety. Recall memory is very limited, since the only memory people with these problems have is the flash backs of what happened when the event took place. People can only recall the memory that happened on that day when they hear or see something that brings the memory into existence. They cannot recall how they felt or what they saw, but through images or audio people can recall that tragic event. For example, the day of September 11, 2001, first responders remember the day and what it was like; but the feelings they could not recall. The only way to recall the feelings they had were when sirens of police vehicles, fire trucks, and ambulances drove by their house they feel the exact feelings that were in effect on that day. 
Recall memory is active when a familiar sound triggers a feeling of pain from a past event, but most of the recall is shut out from traumatic event. It is similar to classical conditioning, when a dog hears a bell it begins to react to the noise rather than an exterior variable like food or an electric shock. The use of therapy is constructed for a person with this problem to help avoid the fear associated with sounds or objects, and be able to then recall other pieces of information that happened during the event.
</p>
<h2 data-mw-anchor="Phenomena">Phenomena</h2>
<p>The phenomenological account of recall is referred to as metacognition, or "knowing about knowing". This includes many states of conscious awareness known as feeling-of-knowing states, such as the tip-of-the-tongue state. It has been suggested that metacognition serves a self-regulatory purpose whereby the brain can observe errors in processing and actively devote resources to resolving the problem. It is considered an important aspect of cognition that can aid in the development of successful learning strategies that can also be generalized to other situations.
</p>
<h3 data-mw-anchor="Mnemonics_and_cognitive_strategies">Mnemonics and cognitive strategies</h3>
<p>A key technique in improving and helping recall memory is to take advantage of Mnemonic devices and other cognitive strategies. Mnemonic devices are a type of cognitive strategy that enables individuals to memorize and recall new information in an easier fashion, rather than just having to remember a list of information that is not related to one another. An example of mnemonic devices are PEMDAS or Please Excuse My Dear Aunt Sally; this is a device for arithmetic when solving equations that have parenthesis, exponents, multiplication, division, addition, or subtraction and what order to do each calculation. Words or an acronym can stand for a process that individuals need to recall. The benefits of using these types of strategies to perform tasks are that encoding becomes more organized and it is easier to remember and process information. Also this device reduces the need of intentional resources at the point of retrieval, which means that recall does not need outside sources helping an individual remember what happened yesterday. Cognitive strategies can leverage semantic connections that will allow the brain to process and work more efficiently than just having to process the information as whole parts. By using the strategies the information becomes related to each other and the information sticks. 
Another type of device people use to help their recall memory become efficient is chunking. Chunking is the process of breaking down numbers into smaller units to remember the information or data, this helps recall numbers and math facts. An example of this chunking process is a telephone number; this is chunked with three digits, three digits, then four digits. People read them off as such when reciting a phone number to another person. There has been research done about these techniques and an institution tested two groups of people to see if these types of devices work well for real people, the results came back determining a significant performance difference between the group who did not use cognitive strategies and the group who did. The group using the techniques immediately performed better than the other group and when taking a pre-test and post-test the results indicated that the group using the techniques improved while the other group did not.
</p><p>The Method of Loci (MOL) refers to an individual visualizing a spatial environment to improve later recall of information. Instead of merely reading a list of items, individuals mentally walk along a path, placing things that subsequently need to be remembered. This elaborate rehearsal provides the opportunity to manipulate information during the encoding process. For example, from the store, you need peanut butter, toothpaste, dog food, and laundry detergent. Instead of repeating the list, imagine yourself eating a peanut butter sandwich, afterwards walking to the bathroom to brush your teeth, then walking by your dog on the way to the laundry room. This improving recall method does not appear to be limited to merely recalling a list of items. Research demonstrated that this cognitive strategy improved student performance on assessments. Participants were divided into two groups, each receiving the same medical lectures, followed by either self-learning or using the Method of Loci. Each group was subsequently given the same assessment on the learned information and the Method of Loci group performed better, as measured by the number of correct responses.
</p>
<h3 data-mw-anchor="Tip-of-the-tongue">Tip-of-the-tongue</h3>

<p>A tip-of-the-tongue (TOT) state refers to the perception of a large gap between the identification or knowledge of a specific subject and being able to recall descriptors or names involving said subject. This phenomenon is also referred to as 'presque vu', a French term meaning "almost seen". There are two prevalent perspectives of TOT states: the psycholinguistic perspective and the metacognitive perspective.
</p><p>Psycholinguistics views TOT states as a failure of retrieval from lexical memory (see Cohort Model) being cued by semantic memory (facts). Since there is an observed increase in the frequency of TOT states with age, there are two mechanisms within psycholinguistics that could account for the TOT phenomenon. The first is the degradation of lexical networks with age, where degrading connections between the priming of knowledge and vocabulary increases difficulty of successfully retrieving a word from memory. The second suggests that the culmination of knowledge, experience, and vocabulary with age results in a similar situation where many connections between a diverse vocabulary and diverse knowledge also increases the difficulty of successful retrieval of a word from memory.
</p><p>The metacognitive perspective views TOT states simply as the awareness felt when such an event occurs and the perception of the experience involved. Mainly being aware of a TOT state can result in the rapid devotion of cognitive resources to resolving the state and successfully retrieving the word from memory. Such an explanation leaves much to be desired; however, the psycholinguistic perspective and the metacognitive perspective on TOT states are not mutually exclusive and both are used to observe TOT states in a laboratory setting.
</p><p>An incubation effect can be observed in TOT states, where the passage of time alone can influence the resolution of the state and result in successful recall. Also, the presence of a TOT state is a good predictor that the problem can be resolved correctly, although this has been shown to occur more frequently with older-young-adults than young-adults or seniors. This is evidence for both the metacognitive perspective as well as the psycholinguistic perspective. It demonstrates the devotion of resources to searching memory, a source of cumulative information, for the desired correct information, and it also shows that we are aware of what information we know or do not know. This is why the current debate between the psycholinguistic view of TOTs as retrieval failure and the metacognitive view of TOTs as a tool for learning continues.
</p><p>Similar phenomena include déjà vu (already seen), jamais vu (never Seen), and déjà entendu (already heard).
These occur rarely and are more prevalent in patients with traumatic head injuries, and brain disorders including epilepsy.
</p>
<h3 data-mw-anchor="Involuntary_memory_retrieval">Involuntary memory retrieval</h3>
<blockquote class="templatequote"><p>Often, even after years, mental states once present in consciousness return to it with apparent spontaneity and without any act of the will; that is, they are reproduced involuntarily. Here, also, in the majority of cases we at once recognise the returned mental state as one that has already been experienced; that is, we remember it. Under certain conditions, however, this accompanying consciousness is lacking, and we know only indirectly that the "now" must be identical with the "then"; yet we receive in this way a no less valid proof for its existence during the intervening time. As more exact observation teaches us, the occurrence of these involuntary reproductions is not an entirely random and accidental one. On the contrary they are brought about through the instrumentality of other immediately present mental images. Moreover they occur in certain regular ways which in general terms are described under the so-called 'laws of association'.
</p></blockquote>
<p>Until recently, research on this phenomenon has been relatively rare, with only two types of involuntary memory retrieval identified: involuntary autobiographical memory retrieval, and involuntary semantic memory retrieval. Both of these phenomena can be considered emergent aspects of otherwise normal and quite efficient cognitive processes.
</p>

<p><i>Involuntary autobiographical memory</i> (IAM) retrieval occurs spontaneously as the result of sensory cues as well as internal cues, such as thought or intention. These cues influence us in our day-to-day lives by constantly and automatically activating unconscious memories through priming. It has been demonstrated in many studies that our specific goals and intentions will most frequently result in the retrieval of related IAM, while the second most frequent IAM retrievals result from physical cues in the surrounding context. Autobiographical memories that are unrelated to any specific cues, whether internal or external, are the least frequent to occur. It has been suggested that in this case, an error in self-regulation of memory has occurred that results in an unrelated autobiographical memory reaching the conscious mind. These findings are consistent with metacognition as the third type of experience is often identified as the most salient one.
</p><p><b>Involuntary semantic memory retrieval</b> (ISM), or "semantic-popping", occurs in the same fashion as IAM retrieval. However, the elicited memory is devoid of personal grounding and often considered trivial, such as a random word, image, or phrase. ISM retrieval can occur as a result of spreading activation, where words, thoughts, and concepts activate related semantic memories continually. When enough related memories are primed that an interrelated concept, word, thought, or image "pops" into consciousness and you are unaware of the extent of its relatedness within your memory. Spreading activation is thought to build over a period of many hours, days, or even weeks before a random semantic memory "pops".
</p>
<h3 data-mw-anchor="False_memories">False memories</h3>

<p>False memories result from persistent beliefs, suggestions via authority figures, or statements of false information. Repeated exposure to these stimuli influence the reorganization of a person's memory, affecting its details, or implanting vivid false accounts of an event. This is usually accounted for by source-monitoring error, where a person can recall specific facts, but cannot correctly identify the source of that knowledge because of apparent loss of the association between the episodic (specific experience, or source) and semantic (concept-based, or gist) accounts of the stored knowledge. An example of this is cryptomnesia, or inadvertent plagiarism, where one duplicates a work that they have previously encountered believing it to be their original idea. False memories can also be accounted for by the generation effect, which is an observable phenomenon where repeated exposure to a belief, suggestion, or false information is better remembered with each subsequent generation. This can be seen with the misinformation effect, where an eye-witness account of an event can be influenced by a bystander account of the same event, or by suggestion via an authority figure. It is also believed to influence the recovery of repressed shocking or abusive memories in patients under hypnosis, where the recovered memory, although possibly a vivid account, could be entirely false, or have specific details influenced as the result of persistent suggestion by the therapist.
</p>
<h3 data-mw-anchor="Focal_retrograde_amnesia">Focal retrograde amnesia</h3>
<p>Retrograde amnesia is typically the result of physical or psychological trauma which manifests itself as the inability to remember information preceding the traumatic event. It is usually accompanied by some type of anterograde amnesia, or inability to acquire new knowledge. <b>Focal retrograde amnesia</b> (FRA), sometimes known as functional amnesia, refers to the presence of retrograde amnesia while knowledge acquisition remains intact (no anterograde amnesia). Memory for how to use objects and perform skills (implicit memory) may remain intact while specific knowledge of personal events or previously learned facts (explicit memory) become inaccessible or lost. Amnesia can result from a number of different causes, including encephalitis, severe traumatic brain injury, vitamin B<sub>1</sub> deficiency as seen in Korsakoff's Syndrome, and psychotic episodes, or by witnessing an emotionally traumatic event (Dissociative amnesia). Dysfunction of the temporal and frontal lobes have been observed in many cases of focal retrograde amnesia, whether metabolic or the result of lesions. However, this evidence only appears to correlate with the symptoms of retrograde amnesia as cases have been observed where patients with minor concussions, showing no visible brain damage, develop FRA. It has been suggested that FRA could represent a variety of different disorders, cognitive deficits, or conditions that result in disproportionate loss of explicit memory, hence Disproportionate Retrograde Amnesia.
</p>
<h3 data-mw-anchor="The_Face_Advantage">The Face Advantage</h3>
<p>The Face Advantage allows information and memories to be recalled easier through the presentation of a person's face rather than a person's voice. Faces and voices are very similar stimuli that reveal similar information and result in similar processes of memory recall. During face perception, there are three stages of memory recall that include recognition, followed by the remembering of semantic memory and episodic memory, and finally name recall. The Face Advantage is shown through an experiment where participants are presented with faces and voices of unfamiliar faces and recognizable celebrity faces. The stimuli are presented with a between-group design. The participants are asked to say if the face or voice is familiar. If the answer is yes, they are asked to recall semantic and episodic memories and finally the name of the face or voice. It was much easier for those presented with a celebrity's face to recall information than for those presented with a voice. The results show that in the second stage of face perception when memories are recalled, information is recalled faster and more accurate after a face is perceived, and slower, less accurate and with less detail after a voice is perceived. A possible explanation is that the connections between face representations and semantic and episodic memory are stronger than that of voices.
</p>
<h2 data-mw-anchor="In_popular_culture">In popular culture</h2>
<p>Memory phenomena are rich sources of storylines and novel situations in popular media. Two phenomena that appear regularly are total recall abilities and amnesia.
</p>
<h3 data-mw-anchor="Total_recall">Total recall</h3>

<p>The Argentinean author, Jorge Luis Borges wrote the short story <i>Funes the Memorious</i> in 1944. It depicts the life of Ireneo Funes, a fictional character who falls off his horse and experiences a head injury. After this accident, Funes has total recall abilities. He is said to recall an entire day with no mistakes, but this feat of recall takes him an entire day to accomplish. It is said that Borges was ahead of his time in his description of memory processes in this story, as it was not until the 1950s and research on the patient HM that some of what the author describes began to be understood. A more recent instance of total recall in literature is found in 
is in Stieg Larsson's books <i>The Girl with the Dragon Tattoo</i>, in which the lead character, Lisbeth Salander remembers anything she reads, indicating she has total recall ability. Another example is in Dan Brown's books <i>The Da Vinci Code</i> and <i>Angels &amp; Demons</i>, in which the main character, Dr. Robert Langdon, a religious iconography and symbology professor at Harvard University, has almost total recall ability. In <i>The Curious Incident of the Dog in the Nighttime</i> by Mark Haddon, the main character, Christopher Boone, is a 15-year-old autistic boy with total recall abilities.
</p><p>Total recall is also popular in television. It can be seen in Season 4 of the television show "Criminal Minds", in which the character Dr. Spencer Reid claims to have total recall ability. Agent Fox Mulder from the television show "The X-Files" has a photographic memory, a popular term for total recall. Also, the character of hospital resident Lexie Grey on the television show "Grey's Anatomy" has total recall ability.
</p>
<h3 data-mw-anchor="Amnesia">Amnesia</h3>
<p>Amnesia which is the damage or disruption of memory processes, has been a very popular subject in movies since 1915. Although its portrayal is usually inaccurate, there are some exceptions. <i>Memento</i> (2000) is said to be inspired by the condition of the famous amnesic patient known as HM. The main character Leonard has anterograde amnesia after a traumatic attack in which his wife dies. He maintains his identity and shows very little retrograde amnesia. He also displays some of the daily memory problems that are experiences by most amnesics, such as forgetting names or where he is going. Another fairly accurate portrayal of memory disturbances is the non-human character Dory in <i>Finding Nemo</i> (2003). This fish, like Leonard, shows memory problems faced by most amnesics where she forgets names, has difficulty storing and recalling information, and often forgets what she is doing, or why she is doing something.
</p><p>Movies tend to show amnesia as a result of head injury from accidents or attacks. The loss of identity and autobiographical memory shown in <i>Santa Who?</i> (2000) in which Santa has amnesia that destroys his identity and memory of himself is very unlikely in the real world. This is also portrayed in <i>The Bourne Identity</i> (2002) and <i>The Bourne Supremacy</i> (2004) where the main character forgets he is a trained assassin. Another misrepresentation of the reality of memory loss in the movies can be seen in Clean Slate (1994) and 50 First Dates (2004) where the characters are able to encode memory during the day but lose all memory of that day at night, while sleeping.
</p><p>Movies often restore affected person's memory through a second trauma, or through a kind of cued recall when they revisit familiar places or see familiar objects. The phenomenon of the second trauma can be seen in <i>Singing in the Dark</i> (1956) where the affected individual experiences the onset of amnesia because of the trauma of the Holocaust, but memory is restored with a blow to the head. Although neurosurgery is often the cause of amnesia, it is seen as a solution in some movies, including <i>Deluxe Annie</i> (1918) and <i>Rascals</i> (1938).
</p><p>Memory erasure is portrayed in <i>Eternal Sunshine of the Spotless Mind</i> (2004) and in the <i>Men in Black</i> movies. <i>Men in Black</i> features a device to erase the potentially harmful memories of extraterrestrial interactions in members of the general public. <i>Eternal Sunshine of the Spotless Mind</i> describes a process that targets and erases memories of interpersonal relationships the patients would rather forget so that they are no longer able to recall the experience. In <i>Paycheck</i> (2003) and <i>Total Recall</i> (1990) memory suppression is used to control and the characters are able to overcome the attempts and recall pieces of their memory.
</p>
<h2 data-mw-anchor="Consequences">Consequences</h2>
<h3 data-mw-anchor="Improving_subsequent_memory">Improving subsequent memory</h3>
<p>By repeating (or recalling [?]) an item over and over again, memory can improve. This process is also known as rehearsal.
</p>
<h3 data-mw-anchor="Impairing_subsequent_memory">Impairing subsequent memory</h3>
<p><b>Retrieval-induced forgetting</b> is a process by which retrieving an item from long-term memory impairs subsequent recall of related items.
</p>
<h2 data-mw-anchor="See_also">See also</h2>
<ul><li>Memory and retention in learning</li>
<li>List of language disorders</li></ul>
<h2 data-mw-anchor="References">References</h2>

<h2 data-mw-anchor="External_links">External links</h2>
<ul><li><span typeof="mw:File"></span> Media related to Recall (memory) at Wikimedia Commons</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Recall_(memory)#Serial_recall'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>List–length effect</h2>
<a href='https://en.wikipedia.org/wiki/Recall_(memory)#Serial_recall' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Recall</b> in memory refers to the mental process of retrieving information from the past. Along with encoding and storage, it is one of the three core processes of memory. There are three main types of recall: free recall, cued recall and serial recall. Psychologists test these forms of recall as a way to study the memory processes of humans and animals.
Two main theories of the process of recall are the two-stage theory and the theory of encoding specificity.
</p>

<h2 data-mw-anchor="Theories">Theories</h2>
<h3 data-mw-anchor="Two-stage_theory">Two-stage theory</h3>
<p>The <i>two-stage theory</i> states that the process of recall begins with a search and retrieval process, and then a decision or recognition process where the correct information is chosen from what has been retrieved. In this theory, recognition only involves the latter of these two stages, or processes, and this is thought to account for the superiority of the recognition process over recall. Recognition only involves one process in which error or failure may occur, while recall involves two. However, recall has been found to be superior to recognition in some cases, such as a failure to recognize words that can later be recalled.
</p><p>Another two stage theory holds that free recall of a list of items begins with the content in working memory and then moves to an associative search.
</p>
<h3 data-mw-anchor="Encoding_specificity">Encoding specificity</h3>
<p>The theory of <i>encoding specificity</i> finds similarities between the process of recognition and that of recall. The <i>encoding specificity principle</i> states that memory utilizes information from the memory trace, or the situation in which it was learned, and from the environment in which it is retrieved. In other words, memory is improved when information available at encoding is also available at retrieval. For example, if one is to learn about a topic and study it in a specific location, but take their exam in a different setting, they would not have had as much of a successful memory recall as if they were in the location that they learned and studied the topic in. Encoding specificity helps to take into account context cues because of its focus on the retrieval environment, and it also accounts for the fact recognition may not always be superior to recall.
</p>
<h2 data-mw-anchor="History">History</h2>
<p>Philosophical questions regarding how people acquire knowledge about their world spurred the study of memory and learning. Recall is a major part of memory so the history of the study of memory in general also provides a history of the study of recall.
</p>

<p>In 1885, Hermann Ebbinghaus created nonsense syllables, combinations of letters that do not follow grammatical rules and have no meaning, to test his own memory. He would memorize a list of nonsense syllables and then test his recall of that list over varying time periods. He discovered that memory loss occurred rapidly over the first few hours or days, but showed a more steady, gradual decline over subsequent days, weeks, and months. Furthermore, Ebbinghaus discovered that multiple learning, over-learning, and spacing study times increased retention of information. Ebbinghaus' research influenced much of the research conducted on memory and recall throughout the twentieth century.
</p><p>Frederic Bartlett was a prominent researcher in the field of memory during the mid-twentieth century. He was a British experimental psychologist who focused on the mistakes people made when recalling new information. One of his well-known works was <i>Remembering: A Study in Experimental and Social Psychology</i>, which he published in 1932. He is well known for his use of North American Native folk tales, including <i>The War of the Ghosts</i>. He would provide participants in his study with an excerpt from a story and then asked them to recall it as accurately as they could. Retention intervals would vary from directly after reading the story to days later. Bartlett found that people try to understand the overall meaning of the story. Since the folk tale included supernatural elements, people would rationalize them to make them fit better with their own culture. Ultimately, Bartlett argued that the mistakes that the participants made could be attributed to "schematic intrusions" - current knowledge interfering with recall.
</p><p>In the 1950s there was a change in the overall study of memory that has come to be known as the cognitive revolution. This included new theories on how to view memory, often likening it to a computer processing model. Two important books influenced the revolution: <i>Plans and Structures of Behavior</i> by George Miller, Eugene Galanter, and Karl H. Pribram in 1960 and <i>Cognitive Psychology</i> by Ulric Neisser in 1967. Both provided arguments for an information-processing view of the human mind. Allen Newell and Herbert A. Simon constructed computer programs that simulated the thought processes people go through when solving different kinds of problems.
</p><p>In the 1960s, interest in short-term memory (STM) increased. Before the 1960s, there was very little research that studied the workings of short-term memory and rapid memory loss. Lloyd and Margaret Peterson observed that when people are given a short list of words or letters and then are distracted and occupied with another task for few seconds, their memory for the list is greatly decreased.
Atkinson and Shiffrin (1973) created the short-term memory model, which became the popular model for studying short-term memory.
</p><p>The next major development in the study of memory recall was Endel Tulving's proposition of two kinds of memory: episodic and semantic. Tulving described episodic memory as a memory about a specific event that occurred at a particular time and place, for example what you got for your 10th birthday. Semantic memories are abstract words, concepts, and rules stored in long-term memory. Furthermore, Endel Tulving devised the encoding specificity principle in 1983, which explains the importance of the relation between the encoding of information and then recalling that information. To explain further, the encoding specificity principle means that a person is more likely to recall information if the recall cues match or are similar to the encoding cues.
</p><p>The 1960s also saw a development in the study of visual imagery and how it is recalled. This research was led by Allan Paivio, who found that the more image-arousing a word was the more likely it would be recalled in either free recall or paired associates.
</p><p>There has been a considerable amount of research into the workings of memory, and specifically recall since the 1980s. The previously mentioned research was developed and improved upon, and new research was and still is being conducted.
</p>
<h2 data-mw-anchor="Types">Types</h2>
<h3 data-mw-anchor="Free_recall">Free recall</h3>

<p>Free recall describes the process in which a person is given a list of items to remember and then is tested by being asked to recall them in any order. Free recall often displays evidence of primacy and recency effects. Primacy effects are displayed when the person recalls items presented at the beginning of the list earlier and more often. The recency effect is when the person recalls items presented at the end of the list earlier and more often. Free recall often begins with the end of the list and then moves to the beginning and middle of the list.
</p>
<h3 data-mw-anchor="Cued_recall">Cued recall</h3>
<p>Cued recall is when a person is given a list of items to remember and is then tested with cues to remember material. Researchers have used this procedure to test memory. Participants are given pairs, usually of words, A1-B1, A2-B2...An-Bn (n is the number of pairs in a list) to study. Then the experimenter gives the participant a word to cue the participant to recall the word with which it was originally paired. The word presentation can either be visual or auditory.
</p><p>There are two basic experimental methods used to conduct cued recall, the study-test method and the anticipation method. In the study-test method participants study a list of word pairs presented individually. Immediately after or after a time delay, participants are tested in the study phase of the experiment on the word pairs just previously studied. One word of each pair is presented in a random order and the participant is asked to recall the item with which it was originally paired. The participant can be tested for either forward recall, Ai is presented as a cue for Bi, or backward recall, Bi is presented as a cue for Ai. In the anticipation method, participants are shown Ai and are asked to anticipate the word paired with it, Bi. If the participant cannot recall the word, the answer is revealed. During an experiment using the anticipation method, the list of words is repeated until a certain percentage of Bi words are recalled.
</p><p>The learning curve for cued recall increases systematically with the number of trials completed. This result has caused a debate about whether or not learning is all-or-none. One theory is that learning is incremental and that the recall of each word pair is strengthened with repetition. Another theory suggests that learning is all-or-none, that is one learns the word pair in a single trial and memory performance is due to the average learned pairs, some of which are learned on earlier trials and some on later trials. To examine the validity of these theories researchers have performed memory experiments. In one experiment published in 1959, experimental psychologist Irvin Rock and colleague Walter Heimer of the University of Illinois had both a control group and an experimental group learn pairs of words. The control group studied word pairs that were repeated until the participants learned all the word pairs. In the experimental group, the learned pairs remained in the list while unlearned pairs were substituted with recombinations of previous words. Rock believed that associations between two items would be strengthened if learning were incremental even when pairs are not correctly recalled. His hypothesis was that the control group would have a higher correct recall probability than the experimental group. He thought that repetition would increase the strength of the word pair until the strength reaches a threshold needed to produce an overt response. If learning were all or none, then the control group and the experimental group should learn the word pairs at the same rate. Rock found experimentally there was little difference in learning rates between the two groups. However, Rock's work did not settle the controversy because in his experiment he rearranged replaced word pairs that could be either easier or harder to learn than the original words in the word- digit pair. In further experiments that addressed the question, there were mixed results. The incremental learning hypothesis is supported by the notion that awhile after Ai-Bi pairs are learned, the recall time to recall Bi decreases with continued learning trails.
</p><p>Another theory that can be tested using cued recall is symmetry of forward and backward recall. Forward recall is generally assumed to be easier than backward recall, i.e. forward recall is stronger than backward recall. This is generally true for long sequences of word or letters such as the alphabet. In one view, the independent associations hypothesis, the strength of forward and backward recall are hypothesized to be independent of each other. To confirm this hypothesis, Dr. George Wolford tested participants' forward and backward recall and found that forward and backward recall are independent of each other. The probability of correct forward recall was .47 for word pair associations and the probability of correct backward recall of word pair associations was .25. However, in another view, the associative symmetry hypothesis, the strengths of forward and backward recall are about equal and highly correlated. In S.E Asch from Swarthmore College and S. M Ebenholtz's experiment, participants learned pairs of nonsense syllables by anticipation recall. After reaching a certain threshold of learning, the participants were tested by free recall to determine all pairs and single items they could remember. These researchers found that backward association was greatly weaker than forward association. However, when the availability of forward and backward recall were basically the same, there was little difference between forward and backward recall. Some scientists including Asch and Ebenholtz believe in the independent association hypothesis think that the equal strengths of forward and backward recall are compatible with their hypothesis because forward and backward recall could be independent but with equal strengths. However associative symmetry theorists interpreted the data to mean that the results fit their hypothesis.
</p><p>Another study done using cued recall found that learning occurs during test trials. Mark Carrier and Pashler (1992) found that the group with a study-only phase makes 10% more errors than the group with a test-study phase. In the study-only phase, participants were given Ai-Bi, where Ai was an English word and Bi was a Siberian Eskimo Yupik word. In the test study phase, participants first attempted to recall Bi given Ai as a cue then they were shown Ai-Bi pair together. This result suggests that after participants learn something, testing their memory with mental operations helps later recall. The act of recalling instead of restudying creates new and longer lasting connection between Ai and Bi. This phenomenon is commonly referred to as the testing effect.
</p><p>Another study showed that when lists are tested immediately after study, the last couple of pairs are remembered best. After a five-second delay, the recall of recently studied words diminishes. However, word pairs at the beginning of a list still show better recall. Moreover, in a longer list, the absolute number of word pairs recalled is greater but in a shorter list of word pairs, the percentage of word pairs recalled is greater.
</p><p>Sometimes, when recalling word pairs, there is an intrusion. An intrusion is an error that participants make when they attempt to recall a word based on a cue of that word pair. Intrusions tend to have either semantic attributes in common with the correct word not recalled or have been previously studied in another word pair on the current list or a previously studied list or were close in time to the cue item. When two items are similar, an intrusion may occur. Professor Kahana and Marieke Vugt at the University of Pennsylvania examined the effects of face similarity for face-name associations. In the first experiment, they wanted to determine if performance of recall would vary with the number of faces in the study set that were similar to the cue face. Faces were similar if the radius of the faces were within a range. The number of faces within a radius is called a neighborhood density. They found that the recall of a name to face exhibited a lower accuracy and slower reaction time for faces with a greater neighborhood density. The more similarity that two faces have, the greater the probability for interference between the two faces. When cued with face A, name B may be recalled if face A and B are similar, which would signify that an intrusion has occurred. The probability of correct recall came from the number of faces that had other similar faces.
</p><p>Cues act as guides to what the person is supposed to remember. A cue can be virtually anything that may act as a reminder, e.g. a smell, song, color, place etc. In contrast to free recall, the subject is prompted to remember a certain item on the list or remember the list in a certain order. Cued recall also plays into free recall because when cues are provided to a subject, they will remember items on the list that they did not originally recall without a cue. Tulving explained this phenomenon in his research. When he gave participants associative cues to items that they did not originally recall and that were thought to be lost to memory, the participants were able to recall the item.
</p>
<h3 data-mw-anchor="Serial_recall">Serial recall</h3>
<p>Serial recall is the ability to recall items or events in the order in which they occurred. The ability of humans to store items in memory and recall them is important to the use of language. Imagine recalling the different parts of a sentence, but in the wrong order. The ability to recall in serial order has been found not only in humans, but in a number of non-human primate species and some non-primates. Imagine mixing up the order of phonemes, or meaningful units of sound, in a word so that "slight" becomes "style." Serial-order also helps us remember the order of events in our lives, our autobiographical memories. Our memory of our past appears to exist on a continuum on which more recent events are more easily remembered in order.
</p><p>Serial recall in long-term memory (LTM) differs from serial recall in short-term memory (STM). To store a sequence in LTM, the sequence is repeated over time until it is represented in memory as a whole, rather than as a series of items. In this way, there is no need to remember the relationships between the items and their original positions. In STM, immediate serial recall (ISR) has been thought to result from one of two mechanisms. The first refers to ISR as a result of associations between the items and their positions in a sequence, while the second refers to associations between items. These associations between items are referred to as chaining, and is an unlikely mechanism, according to research.  Position-item relationships do not account for recency and primacy effects, or the phonological similarity effect. The Primacy Model moves away from these two assumptions, suggesting that ISR results from a gradient of activation levels where each item has a particular level of activation that corresponds to its position. Research has supported the fact that immediate serial recall performance is much better when the list is homogenous (of the same semantic category) than when they are heterogeneous (of different semantic category). This suggests that semantic representations are beneficial to immediate serial recall performance. Short-term serial recall is also affected by similar-sounding items, as recall is lower (remembered more poorly) than items that do not sound alike. This is true when lists are tested independently (when comparing two separate lists of similar-sounding and not similar-sounding items) as well as when tested using a mixed list. Alan Baddeley first reported such an experiment in which items within a list were either mutually dissimilar or highly similar.
</p><p>There is evidence indicating that rhythm is highly sensitive to competing motor production. Actions such as paced finger tapping can have an effect on recall as the disruptive impact of paced finger tapping, but lack of consistent effect of paced irrelevant sound, is indicative of motor feedback from the tapping task disrupting rehearsal and storage.
</p><p>Eight different effects are generally seen in serial recall studies with humans:
</p>
<dl><dt>1. List length effect</dt>
<dd>Serial recall ability decreases as the length of the list or sequence increases.</dd></dl>
<dl><dt>2. Primacy and recency effects</dt>
<dd>Primacy effects refer to better recall of items earlier in the sequence, while recency effects refer to better recall of the last few items. Recency effects are seen more with auditory stimuli rather than verbal stimuli as auditory presentation seems to protect the end of lists from output interference.</dd></dl>
<dl><dt>3. Transposition gradients</dt>
<dd>Transposition gradients refer to the fact that recall tends to be better to recognize what an item is rather than the order of items in a sequence.</dd></dl>
<dl><dt>4. Item confusion errors</dt>
<dd>When an item is incorrectly recalled, there is a tendency to respond with an item that resembles the original item in that position.</dd></dl>
<dl><dt>5. Repetition errors</dt>
<dd>These occur during the recall of a sequence when an item from an earlier position in the sequence is given again in another position. This effect is fairly rare in humans.</dd></dl>
<dl><dt>6. Fill-in effects</dt>
<dd>If an item is recalled incorrectly at an earlier position than its original place, there is a tendency for the next item recalled to be the item that was displaced by this error. For example, if the sequence is '1234' and recall began '124', then the next item is likely to be '3'.</dd></dl>
<dl><dt>7. Protrusion effects</dt>
<dd>These occur when an item from a previous list or test is accidentally recalled on a new list or test. This item is likely to be recalled at its position from the original trial.</dd></dl>
<dl><dt>8. Word-length effects</dt>
<dd>Short words are recalled more accurately than longer words.</dd></dl>
<h2 data-mw-anchor="Neuroanatomy">Neuroanatomy</h2>
<p>The anterior cingulate cortex, globus pallidus, thalamus, and cerebellum show higher activation during recall than during recognition which suggests that these components of the cerebello-frontal pathway play a role in recall processes that they do not in recognition. Although recall and recognition are considered separate processes, they are both most likely constitute components of distributed networks of brain regions.
</p>
 

<p>According to neuroimaging data, PET studies on recall and recognition have consistently found increases in regional cerebral blood flow (RCBF) in the following six brain regions: (1) the prefrontal cortex, particularly on the right hemisphere; (2) the hippocampal and parahippocampal regions of the medial temporal lobe; (3) the anterior cingulate cortex; (4) the posterior midline area that includes posterior cingulate, retrosplenial (see retrosplenial region), precuneus, and cuneus regions; (5) the inferior parietal cortex, especially on the right hemisphere; and (6) the cerebellum, particularly on the left.
</p>

<p>The specific role of each of the six main regions in episodic retrieval is still unclear, but some ideas have been suggested. The right prefrontal cortex has been related to retrieval attempt; the medial temporal lobes to conscious recollection; the anterior cingulate to response selection; the posterior midline region to imagery; the inferior parietal to awareness of space; and the cerebellum to self-initiated retrieval .
</p>

<p>In recent research, a group of subjects was faced with remembering a list of items and then measured when trying to recall said items. The evoked potentials and hemodynamic activity measured during encoding were found to exhibit reliable differences between subsequently recalled and not recalled items. This effect has been termed the subsequent memory effect (SME). This difference in these specific brain regions determines whether or not an item is recalled. A study by Fernandez et al. has shown that the differences that predict recall appear both as a negative deflection in the rhinal cortex of an event-related potential (ERP) 400 ms after stimulus exposure, and as a positive hippocampal ERP beginning 800 ms after stimulus onset. This means that recall only occurs if these two brain regions (rhinal cortex and hippocampus) are activated in synchrony.
</p>
<h2 data-mw-anchor="Factors_that_affect_recall">Factors that affect recall</h2>
<h3 data-mw-anchor="Attention">Attention</h3>
<p>The effect of attention on memory recall has surprising results. It seems that the only time attention largely affects memory is during the encoding phase. During this phase, performing a parallel task can severely impair retrieval success. It is believed that this phase requires much attention to properly encode the information at hand, and thus a distractor task does not allow proper input and reduces the amount of information learned.
</p><p>One's attention to words is impacted by emotion grasping vocabulary. Negative and positive words are better recalled than neutral words that are spoken. Many different ways that attention is focused on hearing what the speaker has to say are the inflection of the presenter's voice in a sad, content, or frustrated sound or in the use of words that are close to the heart. A study was conducted to observe if the use of emotional vocabulary was a key receptor of recall memory. The groups were put into the same lecture halls and given the same speakers, but the results came back to determine that the inflection and word choice recalled by the listeners concluded that emotional words, phrases, and sounds are more memorable than neutral speakers.
</p><p>Recall memory is linked with instincts and mechanisms. In order to remember how an event happened, to learn from it or avoid an agitator, connections are made with emotions. For instance, if a speaker is very calm and neutral, the effectiveness of encoding memory is very low and listeners get the gist of what the speaker is discussing. On the other hand, if a speaker is shouting and/or using emotionally driven words, listeners tend to remember key phrases and the meaning of the speech. This is full access of the fight or flight mechanism all people have functioning in the brain, but based on what triggers this mechanism will lead to better recall of it. People tend to focus their attention on cues that are loud, very soft, or something unusual. This makes the auditory system pick up the differences in regular speaking and meaningful speech, when something significant is spoken in the discussion people home in on the message at that part of the speech but tend to lose the other part of the discussion. Our brains sense differences in speech and when those differences occur the brain encodes that part of speech into memory and the information can be recalled for future reference.
</p>
<h3 data-mw-anchor="Motivation">Motivation</h3>
<p>Motivation is a factor that encourages a person to perform and succeed at the task at hand. In an experiment done by Roebers, Moga and Schneider (2001), participants were placed in either forced report, free report or free report plus incentive groups. In each group, they found that the amount of correct information recalled did not differ, yet in the group where participants were given an incentive they had higher accuracy results. This means that presenting participants with an encouragement to provide correct information motivates them to be more precise. However, this is only true if the perception is that success is providing correct information. When it is believed that success is the completion of the task rather than the accuracy of that completion, the number of responses is higher, yet its accuracy is lowered. This shows that the results are dependent on how success is defined to the participant. In the referred experiment, the participants that were placed in the forced response group had the lowest overall accuracy; they had no motivation to provide accurate responses and were forced to respond even when they were unsure of the answer. Another study done by Hill RD, Storandt M, and Simeone C tested the impact of memory skills training and external reward on free recall of serial word lists. Effects similar to those reported in the previous study were seen in children—in contrast to older learners.
</p>
<h3 data-mw-anchor="Interference">Interference</h3>
<p>In the absence of interference, there are two factors at play when recalling a list of items: the recency and the primacy effects. The recency effect occurs when the short-term memory is used to remember the most recent items, and the primacy effect occurs when the long-term memory has encoded the earlier items. The recency effect can be eliminated if there is a period of interference between the input and the output of information extending longer than the holding time of short-term memory (15–30 seconds). This occurs when a person is given subsequent information to recall preceding the recall of the initial information. The primacy effect, however, is not affected by the interference of recall. The elimination of the last few items from memory is due to the displacement of these items from short-term memory, by the distracting task. As they have not been recited and rehearsed, they are not moved into long-term memory and are thus lost. A task as simple as counting backwards can change memory recall; however an empty delay interval has no effect. This is because the person can continue to rehearse the items in their working memory to be remembered without interference. Cohen (1989) found that there is better recall for an action in the presence of interference if that action is physically performed during the encoding phase. It has also been found that recalling some items can interfere and inhibit the recall of other items. Another stream of thought and evidence suggests that the effects of interference on recency and primacy are relative, determined by the ratio rule (retention interval to inter item presentation distractor rate) and they exhibit time-scale invariance.
</p>
<h3 data-mw-anchor="Context">Context</h3>
<p>Context-dependency effects on recall are typically interpreted as evidence that the characteristics of the environment are encoded as part of the memory trace and can be used to enhance retrieval of the other information in the trace. In other words, you can recall more when the environments are similar in both the learning and recall phases. Context cues appear to be important in the retrieval of newly learned meaningful information. In a classic study by Godden and Baddeley (1975), using free recall of wordlist demonstrated that deep-sea divers had better recall when there was a match between the learning and recalling environment. Lists learned underwater were recalled best underwater and lists learned on land were recalled best on land." An academic application would be that students may perform better on exams by studying in silence, because exams are usually done in silence.
</p>
<h3 data-mw-anchor="State-dependent_memory">State-dependent memory</h3>
<p>State-dependent retrieval is demonstrated when material learned under one State is best recalled in that same state. A study by Carter and Cassady (1998) showed this effect with antihistamine. In other words, if you study while on hay fever tablets, then you will recall more of what you studied if you test yourself while on antihistamines in comparison to testing yourself while not on antihistamines after having studied on antihistamines.
</p><p>A study by Block and Ghoneim (2000) found that, relative to a matched group of healthy, non-drug-using controls, heavy marijuana use is associated with small but significant impairments in memory retrieval.cannabis induces loss of internal control and cognitive impairment, especially impairment of attention and memory, for the duration of the intoxication period.
</p><p>Stimulants, such as cocaine, amphetamines or caffeine are known to improve recall in humans. However, the effect of prolonged use of stimulants on cognitive functioning is very different from the impact on one-time users. Some researchers have found stimulant use to lower recall rates in humans after prolonged usage. The axons, dendrites, and neurons wear out in many cases. Current research illustrates a paradoxical effect. The few exceptions undergo mental hypertrophy. Methylenedioxymethamphetamine (MDMA) users are found to exhibit difficulties encoding information into long-term memory, display impaired verbal learning, are more easily distracted, and are less efficient at focusing attention on complex tasks. The degree of executive impairment increases with the severity of use, and the impairments are relatively long-lasting. Chronic cocaine users display impaired attention, learning, memory, reaction time and cognitive flexibility. Whether or not stimulants have a positive or negative effect on recall depends on how much is used and for how long.
</p>
<h3 data-mw-anchor="Gender">Gender</h3>
<p>Consistently, females perform better than males on episodic memory tasks including delayed recall and recognition. However, males and females do not differ on working, immediate and semantic memory tasks. Neuro-psychological observations suggest that, in general, previous injuries cause greater deficits in females than in males. It has been proposed that the gender differences in memory performance reflect underlying differences in the strategies used to process information, rather than anatomical differences. However, gender differences in cerebral asymmetry received support from morphometric studies showing a greater leftward asymmetry in males than in females, meaning that men and women use each side of their brain to a different extent. There is also evidence for a negative recall bias in women, which means females in general are more likely than males to recall their mistakes. In an eyewitness study by Dan Yarmey in 1991, he found that women were significantly more accurate than men in accuracy of recall for weight of suspects.
</p><p>Studies have tested the difference between what men and women can recall after a presentation. Three speakers were involved, one being female and two being male. Men and women were put into the same lecture hall and had the same speaker talk to them. The results suggested that information presented by the women speaker was more easily recalled by all the members of the study. Researchers believe this to be a significant difference between genders because women's voices have better acoustics, ranging from low tones to high tones. Since their voices have this range, semantic encoding is increased for the pitches that stimulate the auditory component of the brain; this resonates better in the ear function. Since pitch ranges from low tones to high tones, it draws people's attention to the words attributed with the tone. As the tone changes, words stand out and from these differences memories can be stored. Recall is made easier since the association the brain can make is between words and sounds spoken.
</p><p>A distinguishing feature is how males and females process information and then recall what was presented to them. Females tend to remember nonverbal cues and associate the meaning of a discussion with gestures. Since males follow verbal cues they react more to the facts and actual words within a discussion to recall what was said, but fluctuations in the speaker's voice helps them maintain the memories. Another difference that sets males and females apart is recalling someone's voice. They tend to recall information they have read, for instance, lists of objects are better recalled for men than women. The only similarity they have is that when emotional words are used or an emotional tone is produced, males and females tend to recall those changes.
</p>
<h3 data-mw-anchor="Food_consumption">Food consumption</h3>

<p>There has been much research on whether eating prior to a cognitive recall test can affect cognitive functioning. One example was a study of the effect of breakfast timing on selected cognitive functions of elementary school students. Their results found that children who ate breakfast at school scored notably higher on most of the cognitive tests than did students who ate breakfast at home and also children who did not eat breakfast at all.
</p><p>In a study of women experiencing Premenstrual Syndrome, they were either given a placebo beverage or a carbohydrate-rich one. The patients were tested at home; their moods, cognitive performance, and food craving were measured before the consumption of the beverage and 30, 90, and 180 minutes after consumption. The results showed that the carbohydrate-rich beverage significantly decreased self-reported depression, anger, confusion, and carbohydrate craving 90 to 180 minutes after consumption. Memory word recognition also improved significantly.
</p>
<h3 data-mw-anchor="Physical_activity">Physical activity</h3>

<p>Studies have indicated that children who are inactive have poor health, but they also have poor cognitive health also. With low fitness there is a relationship to decreased cognitive functioning; for instance there are different types of cognitive problems like perception, memory, cognitive control, and there is lower academic achievement. Many tests have been conducted to identify what exactly is the reduction when children do not have physical activity. One test selected children to be in two different groups, one group was physically active the other group was not. After a while of monitoring the children the researchers tested the children in learning and recall memory to see what they were retaining and to observe the difference if available of low physical activity versus high physical activity. The results came back indicating that the children without physical activity have a later recall process than the children with physical activity. The learning part of the experiment was equally distributed on both spectrums for each group, but recall memory was the only variable that did not match both of the groups. 
Physical activity has a significant influence on the hippocampus, since this is the part of the brain that is responsible for encoding information into memory. With physical activity having such an impact on the hippocampus this can regulate other parts of the body as well like weight, memory, daily function, and many more processes that are necessary for the body to work. Since physical activity impacts all of these important parts of the brain, this form of exercise keeps the neural networks functioning well. Neural networks allow information to process and pass to the hippocampus in order to retain memory. This lets the brain be more efficient in processing and more memories are stored this way.
</p>
<h3 data-mw-anchor="Trauma_and_brain_exposure">Trauma and brain exposure</h3>

<p>There is barely any recalled memory in cases of fear and trauma exposure, brain injury, post-traumatic stress disorder, pain, or anxiety. Recall memory is very limited, since the only memory people with these problems have is the flash backs of what happened when the event took place. People can only recall the memory that happened on that day when they hear or see something that brings the memory into existence. They cannot recall how they felt or what they saw, but through images or audio people can recall that tragic event. For example, the day of September 11, 2001, first responders remember the day and what it was like; but the feelings they could not recall. The only way to recall the feelings they had were when sirens of police vehicles, fire trucks, and ambulances drove by their house they feel the exact feelings that were in effect on that day. 
Recall memory is active when a familiar sound triggers a feeling of pain from a past event, but most of the recall is shut out from traumatic event. It is similar to classical conditioning, when a dog hears a bell it begins to react to the noise rather than an exterior variable like food or an electric shock. The use of therapy is constructed for a person with this problem to help avoid the fear associated with sounds or objects, and be able to then recall other pieces of information that happened during the event.
</p>
<h2 data-mw-anchor="Phenomena">Phenomena</h2>
<p>The phenomenological account of recall is referred to as metacognition, or "knowing about knowing". This includes many states of conscious awareness known as feeling-of-knowing states, such as the tip-of-the-tongue state. It has been suggested that metacognition serves a self-regulatory purpose whereby the brain can observe errors in processing and actively devote resources to resolving the problem. It is considered an important aspect of cognition that can aid in the development of successful learning strategies that can also be generalized to other situations.
</p>
<h3 data-mw-anchor="Mnemonics_and_cognitive_strategies">Mnemonics and cognitive strategies</h3>
<p>A key technique in improving and helping recall memory is to take advantage of Mnemonic devices and other cognitive strategies. Mnemonic devices are a type of cognitive strategy that enables individuals to memorize and recall new information in an easier fashion, rather than just having to remember a list of information that is not related to one another. An example of mnemonic devices are PEMDAS or Please Excuse My Dear Aunt Sally; this is a device for arithmetic when solving equations that have parenthesis, exponents, multiplication, division, addition, or subtraction and what order to do each calculation. Words or an acronym can stand for a process that individuals need to recall. The benefits of using these types of strategies to perform tasks are that encoding becomes more organized and it is easier to remember and process information. Also this device reduces the need of intentional resources at the point of retrieval, which means that recall does not need outside sources helping an individual remember what happened yesterday. Cognitive strategies can leverage semantic connections that will allow the brain to process and work more efficiently than just having to process the information as whole parts. By using the strategies the information becomes related to each other and the information sticks. 
Another type of device people use to help their recall memory become efficient is chunking. Chunking is the process of breaking down numbers into smaller units to remember the information or data, this helps recall numbers and math facts. An example of this chunking process is a telephone number; this is chunked with three digits, three digits, then four digits. People read them off as such when reciting a phone number to another person. There has been research done about these techniques and an institution tested two groups of people to see if these types of devices work well for real people, the results came back determining a significant performance difference between the group who did not use cognitive strategies and the group who did. The group using the techniques immediately performed better than the other group and when taking a pre-test and post-test the results indicated that the group using the techniques improved while the other group did not.
</p><p>The Method of Loci (MOL) refers to an individual visualizing a spatial environment to improve later recall of information. Instead of merely reading a list of items, individuals mentally walk along a path, placing things that subsequently need to be remembered. This elaborate rehearsal provides the opportunity to manipulate information during the encoding process. For example, from the store, you need peanut butter, toothpaste, dog food, and laundry detergent. Instead of repeating the list, imagine yourself eating a peanut butter sandwich, afterwards walking to the bathroom to brush your teeth, then walking by your dog on the way to the laundry room. This improving recall method does not appear to be limited to merely recalling a list of items. Research demonstrated that this cognitive strategy improved student performance on assessments. Participants were divided into two groups, each receiving the same medical lectures, followed by either self-learning or using the Method of Loci. Each group was subsequently given the same assessment on the learned information and the Method of Loci group performed better, as measured by the number of correct responses.
</p>
<h3 data-mw-anchor="Tip-of-the-tongue">Tip-of-the-tongue</h3>

<p>A tip-of-the-tongue (TOT) state refers to the perception of a large gap between the identification or knowledge of a specific subject and being able to recall descriptors or names involving said subject. This phenomenon is also referred to as 'presque vu', a French term meaning "almost seen". There are two prevalent perspectives of TOT states: the psycholinguistic perspective and the metacognitive perspective.
</p><p>Psycholinguistics views TOT states as a failure of retrieval from lexical memory (see Cohort Model) being cued by semantic memory (facts). Since there is an observed increase in the frequency of TOT states with age, there are two mechanisms within psycholinguistics that could account for the TOT phenomenon. The first is the degradation of lexical networks with age, where degrading connections between the priming of knowledge and vocabulary increases difficulty of successfully retrieving a word from memory. The second suggests that the culmination of knowledge, experience, and vocabulary with age results in a similar situation where many connections between a diverse vocabulary and diverse knowledge also increases the difficulty of successful retrieval of a word from memory.
</p><p>The metacognitive perspective views TOT states simply as the awareness felt when such an event occurs and the perception of the experience involved. Mainly being aware of a TOT state can result in the rapid devotion of cognitive resources to resolving the state and successfully retrieving the word from memory. Such an explanation leaves much to be desired; however, the psycholinguistic perspective and the metacognitive perspective on TOT states are not mutually exclusive and both are used to observe TOT states in a laboratory setting.
</p><p>An incubation effect can be observed in TOT states, where the passage of time alone can influence the resolution of the state and result in successful recall. Also, the presence of a TOT state is a good predictor that the problem can be resolved correctly, although this has been shown to occur more frequently with older-young-adults than young-adults or seniors. This is evidence for both the metacognitive perspective as well as the psycholinguistic perspective. It demonstrates the devotion of resources to searching memory, a source of cumulative information, for the desired correct information, and it also shows that we are aware of what information we know or do not know. This is why the current debate between the psycholinguistic view of TOTs as retrieval failure and the metacognitive view of TOTs as a tool for learning continues.
</p><p>Similar phenomena include déjà vu (already seen), jamais vu (never Seen), and déjà entendu (already heard).
These occur rarely and are more prevalent in patients with traumatic head injuries, and brain disorders including epilepsy.
</p>
<h3 data-mw-anchor="Involuntary_memory_retrieval">Involuntary memory retrieval</h3>
<blockquote class="templatequote"><p>Often, even after years, mental states once present in consciousness return to it with apparent spontaneity and without any act of the will; that is, they are reproduced involuntarily. Here, also, in the majority of cases we at once recognise the returned mental state as one that has already been experienced; that is, we remember it. Under certain conditions, however, this accompanying consciousness is lacking, and we know only indirectly that the "now" must be identical with the "then"; yet we receive in this way a no less valid proof for its existence during the intervening time. As more exact observation teaches us, the occurrence of these involuntary reproductions is not an entirely random and accidental one. On the contrary they are brought about through the instrumentality of other immediately present mental images. Moreover they occur in certain regular ways which in general terms are described under the so-called 'laws of association'.
</p></blockquote>
<p>Until recently, research on this phenomenon has been relatively rare, with only two types of involuntary memory retrieval identified: involuntary autobiographical memory retrieval, and involuntary semantic memory retrieval. Both of these phenomena can be considered emergent aspects of otherwise normal and quite efficient cognitive processes.
</p>

<p><i>Involuntary autobiographical memory</i> (IAM) retrieval occurs spontaneously as the result of sensory cues as well as internal cues, such as thought or intention. These cues influence us in our day-to-day lives by constantly and automatically activating unconscious memories through priming. It has been demonstrated in many studies that our specific goals and intentions will most frequently result in the retrieval of related IAM, while the second most frequent IAM retrievals result from physical cues in the surrounding context. Autobiographical memories that are unrelated to any specific cues, whether internal or external, are the least frequent to occur. It has been suggested that in this case, an error in self-regulation of memory has occurred that results in an unrelated autobiographical memory reaching the conscious mind. These findings are consistent with metacognition as the third type of experience is often identified as the most salient one.
</p><p><b>Involuntary semantic memory retrieval</b> (ISM), or "semantic-popping", occurs in the same fashion as IAM retrieval. However, the elicited memory is devoid of personal grounding and often considered trivial, such as a random word, image, or phrase. ISM retrieval can occur as a result of spreading activation, where words, thoughts, and concepts activate related semantic memories continually. When enough related memories are primed that an interrelated concept, word, thought, or image "pops" into consciousness and you are unaware of the extent of its relatedness within your memory. Spreading activation is thought to build over a period of many hours, days, or even weeks before a random semantic memory "pops".
</p>
<h3 data-mw-anchor="False_memories">False memories</h3>

<p>False memories result from persistent beliefs, suggestions via authority figures, or statements of false information. Repeated exposure to these stimuli influence the reorganization of a person's memory, affecting its details, or implanting vivid false accounts of an event. This is usually accounted for by source-monitoring error, where a person can recall specific facts, but cannot correctly identify the source of that knowledge because of apparent loss of the association between the episodic (specific experience, or source) and semantic (concept-based, or gist) accounts of the stored knowledge. An example of this is cryptomnesia, or inadvertent plagiarism, where one duplicates a work that they have previously encountered believing it to be their original idea. False memories can also be accounted for by the generation effect, which is an observable phenomenon where repeated exposure to a belief, suggestion, or false information is better remembered with each subsequent generation. This can be seen with the misinformation effect, where an eye-witness account of an event can be influenced by a bystander account of the same event, or by suggestion via an authority figure. It is also believed to influence the recovery of repressed shocking or abusive memories in patients under hypnosis, where the recovered memory, although possibly a vivid account, could be entirely false, or have specific details influenced as the result of persistent suggestion by the therapist.
</p>
<h3 data-mw-anchor="Focal_retrograde_amnesia">Focal retrograde amnesia</h3>
<p>Retrograde amnesia is typically the result of physical or psychological trauma which manifests itself as the inability to remember information preceding the traumatic event. It is usually accompanied by some type of anterograde amnesia, or inability to acquire new knowledge. <b>Focal retrograde amnesia</b> (FRA), sometimes known as functional amnesia, refers to the presence of retrograde amnesia while knowledge acquisition remains intact (no anterograde amnesia). Memory for how to use objects and perform skills (implicit memory) may remain intact while specific knowledge of personal events or previously learned facts (explicit memory) become inaccessible or lost. Amnesia can result from a number of different causes, including encephalitis, severe traumatic brain injury, vitamin B<sub>1</sub> deficiency as seen in Korsakoff's Syndrome, and psychotic episodes, or by witnessing an emotionally traumatic event (Dissociative amnesia). Dysfunction of the temporal and frontal lobes have been observed in many cases of focal retrograde amnesia, whether metabolic or the result of lesions. However, this evidence only appears to correlate with the symptoms of retrograde amnesia as cases have been observed where patients with minor concussions, showing no visible brain damage, develop FRA. It has been suggested that FRA could represent a variety of different disorders, cognitive deficits, or conditions that result in disproportionate loss of explicit memory, hence Disproportionate Retrograde Amnesia.
</p>
<h3 data-mw-anchor="The_Face_Advantage">The Face Advantage</h3>
<p>The Face Advantage allows information and memories to be recalled easier through the presentation of a person's face rather than a person's voice. Faces and voices are very similar stimuli that reveal similar information and result in similar processes of memory recall. During face perception, there are three stages of memory recall that include recognition, followed by the remembering of semantic memory and episodic memory, and finally name recall. The Face Advantage is shown through an experiment where participants are presented with faces and voices of unfamiliar faces and recognizable celebrity faces. The stimuli are presented with a between-group design. The participants are asked to say if the face or voice is familiar. If the answer is yes, they are asked to recall semantic and episodic memories and finally the name of the face or voice. It was much easier for those presented with a celebrity's face to recall information than for those presented with a voice. The results show that in the second stage of face perception when memories are recalled, information is recalled faster and more accurate after a face is perceived, and slower, less accurate and with less detail after a voice is perceived. A possible explanation is that the connections between face representations and semantic and episodic memory are stronger than that of voices.
</p>
<h2 data-mw-anchor="In_popular_culture">In popular culture</h2>
<p>Memory phenomena are rich sources of storylines and novel situations in popular media. Two phenomena that appear regularly are total recall abilities and amnesia.
</p>
<h3 data-mw-anchor="Total_recall">Total recall</h3>

<p>The Argentinean author, Jorge Luis Borges wrote the short story <i>Funes the Memorious</i> in 1944. It depicts the life of Ireneo Funes, a fictional character who falls off his horse and experiences a head injury. After this accident, Funes has total recall abilities. He is said to recall an entire day with no mistakes, but this feat of recall takes him an entire day to accomplish. It is said that Borges was ahead of his time in his description of memory processes in this story, as it was not until the 1950s and research on the patient HM that some of what the author describes began to be understood. A more recent instance of total recall in literature is found in 
is in Stieg Larsson's books <i>The Girl with the Dragon Tattoo</i>, in which the lead character, Lisbeth Salander remembers anything she reads, indicating she has total recall ability. Another example is in Dan Brown's books <i>The Da Vinci Code</i> and <i>Angels &amp; Demons</i>, in which the main character, Dr. Robert Langdon, a religious iconography and symbology professor at Harvard University, has almost total recall ability. In <i>The Curious Incident of the Dog in the Nighttime</i> by Mark Haddon, the main character, Christopher Boone, is a 15-year-old autistic boy with total recall abilities.
</p><p>Total recall is also popular in television. It can be seen in Season 4 of the television show "Criminal Minds", in which the character Dr. Spencer Reid claims to have total recall ability. Agent Fox Mulder from the television show "The X-Files" has a photographic memory, a popular term for total recall. Also, the character of hospital resident Lexie Grey on the television show "Grey's Anatomy" has total recall ability.
</p>
<h3 data-mw-anchor="Amnesia">Amnesia</h3>
<p>Amnesia which is the damage or disruption of memory processes, has been a very popular subject in movies since 1915. Although its portrayal is usually inaccurate, there are some exceptions. <i>Memento</i> (2000) is said to be inspired by the condition of the famous amnesic patient known as HM. The main character Leonard has anterograde amnesia after a traumatic attack in which his wife dies. He maintains his identity and shows very little retrograde amnesia. He also displays some of the daily memory problems that are experiences by most amnesics, such as forgetting names or where he is going. Another fairly accurate portrayal of memory disturbances is the non-human character Dory in <i>Finding Nemo</i> (2003). This fish, like Leonard, shows memory problems faced by most amnesics where she forgets names, has difficulty storing and recalling information, and often forgets what she is doing, or why she is doing something.
</p><p>Movies tend to show amnesia as a result of head injury from accidents or attacks. The loss of identity and autobiographical memory shown in <i>Santa Who?</i> (2000) in which Santa has amnesia that destroys his identity and memory of himself is very unlikely in the real world. This is also portrayed in <i>The Bourne Identity</i> (2002) and <i>The Bourne Supremacy</i> (2004) where the main character forgets he is a trained assassin. Another misrepresentation of the reality of memory loss in the movies can be seen in Clean Slate (1994) and 50 First Dates (2004) where the characters are able to encode memory during the day but lose all memory of that day at night, while sleeping.
</p><p>Movies often restore affected person's memory through a second trauma, or through a kind of cued recall when they revisit familiar places or see familiar objects. The phenomenon of the second trauma can be seen in <i>Singing in the Dark</i> (1956) where the affected individual experiences the onset of amnesia because of the trauma of the Holocaust, but memory is restored with a blow to the head. Although neurosurgery is often the cause of amnesia, it is seen as a solution in some movies, including <i>Deluxe Annie</i> (1918) and <i>Rascals</i> (1938).
</p><p>Memory erasure is portrayed in <i>Eternal Sunshine of the Spotless Mind</i> (2004) and in the <i>Men in Black</i> movies. <i>Men in Black</i> features a device to erase the potentially harmful memories of extraterrestrial interactions in members of the general public. <i>Eternal Sunshine of the Spotless Mind</i> describes a process that targets and erases memories of interpersonal relationships the patients would rather forget so that they are no longer able to recall the experience. In <i>Paycheck</i> (2003) and <i>Total Recall</i> (1990) memory suppression is used to control and the characters are able to overcome the attempts and recall pieces of their memory.
</p>
<h2 data-mw-anchor="Consequences">Consequences</h2>
<h3 data-mw-anchor="Improving_subsequent_memory">Improving subsequent memory</h3>
<p>By repeating (or recalling [?]) an item over and over again, memory can improve. This process is also known as rehearsal.
</p>
<h3 data-mw-anchor="Impairing_subsequent_memory">Impairing subsequent memory</h3>
<p><b>Retrieval-induced forgetting</b> is a process by which retrieving an item from long-term memory impairs subsequent recall of related items.
</p>
<h2 data-mw-anchor="See_also">See also</h2>
<ul><li>Memory and retention in learning</li>
<li>List of language disorders</li></ul>
<h2 data-mw-anchor="References">References</h2>

<h2 data-mw-anchor="External_links">External links</h2>
<ul><li><span typeof="mw:File"></span> Media related to Recall (memory) at Wikimedia Commons</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Recall_(memory)#Serial_recall'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Duration neglect</h2>
<a href='https://en.wikipedia.org/wiki/Duration_neglect' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Duration neglect</b> is the psychological observation that people's judgments of the unpleasantness of painful experiences depend very little on the duration of those experiences. Multiple experiments have found that these judgments tend to be affected by two factors: the <i>peak</i> (when the experience was the most painful) and how quickly the pain diminishes. If it diminishes more slowly, the experience is judged to be less painful. Hence, the term "peak–end rule" describes this process of evaluation.
</p><p>Duration neglect is a specific form of the more general extension neglect.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Duration_neglect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Modality effect</h2>
<a href='https://en.wikipedia.org/wiki/Modality_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>modality effect</b> is a term used in experimental psychology, most often in the fields dealing with memory and learning, to refer to how learner performance depends on the presentation mode of studied items.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Modality_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Memory inhibition</h2>
<a href='https://en.wikipedia.org/wiki/Memory_inhibition' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In psychology, <b>memory inhibition</b> is the ability <i>not</i> to remember irrelevant information. The scientific concept of memory inhibition should not be confused with everyday uses of the word "inhibition". Scientifically speaking, memory inhibition is a type of cognitive inhibition, which is the stopping or overriding of a mental process, in whole or in part, with or without intention.
</p><p>Memory inhibition is a critical component of an effective memory system. While some memories are retained for a lifetime, most memories are forgotten. According to evolutionary psychologists, forgetting is adaptive because it facilitates selectivity of rapid, efficient recollection. For example, a person trying to remember where they parked their car would not want to remember every place they have ever parked. In order to remember something, therefore, it is essential not only to activate the relevant information, but also to inhibit irrelevant information. 
</p><p>There are many memory phenomena that seem to involve inhibition, although there is often debate about the distinction between interference and inhibition.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Memory_inhibition'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Primacy effect</h2>
<a href='https://en.wikipedia.org/wiki/Serial-position_effect#Primacy_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Serial-position effect</b> is the tendency of a person to recall the first and last items in a series best, and the middle items worst. The term was coined by Hermann Ebbinghaus through studies he performed on himself, and refers to the finding that recall accuracy varies as a function of an item's position within a study list. When asked to recall a list of items in any order (free recall), people tend to begin recall with the end of the list, recalling those items best (the <b>recency effect</b>). Among earlier list items, the first few items are recalled more frequently than the middle items (the <b>primacy effect</b>).
</p><p>One suggested reason for the primacy effect is that the initial items presented are most effectively stored in long-term memory because of the greater amount of processing devoted to them. (The first list item can be rehearsed by itself; the second must be rehearsed along with the first, the third along with the first and second, and so on.) The primacy effect is reduced when items are presented quickly and is enhanced when presented slowly (factors that reduce and enhance processing of each item and thus permanent storage). Longer presentation lists have been found to reduce the primacy effect.
</p><p>One theorised reason for the recency effect is that these items are still present in working memory when recall is solicited. Items that benefit from neither (the middle items) are recalled most poorly. An additional explanation for the recency effect is related to temporal context: if tested immediately after rehearsal, the current temporal context can serve as a retrieval cue, which would predict more recent items to have a higher likelihood of recall than items that were studied in a different temporal context (earlier in the list). The recency effect is reduced when an interfering task is given. Intervening tasks involve working memory, as the distractor activity, if exceeding 15 to 30 seconds in duration, can cancel out the recency effect. Additionally, if recall comes immediately after the test, the recency effect is consistent regardless of the length of the studied list, or presentation rate.
</p><p>Amnesiacs with poor ability to form permanent long-term memories do not show a primacy effect, but do show a recency effect if recall comes immediately after study. People with Alzheimer's disease exhibit a reduced primacy effect but do not produce a recency effect in recall.
</p>

<h2 data-mw-anchor="Primacy_effect">Primacy effect</h2>
<p>In psychology and sociology, the primacy effect (also known as the primacy bias) is a cognitive bias that results in a subject recalling primary information presented better than information presented later on. For example, a subject who reads a sufficiently long list of words is more likely to remember words toward the beginning than words in the middle.
</p><p>Many researchers have tried to explain this phenomenon through free recall [null tests]. Coluccia, Gamboz, and Brandimonte (2011) explain free recall as participants trying to remember information without any prompting. In some experiments in the late 20th century, it was noted that participants who knew that they were going to be tested on a list presented to them would rehearse items: as items were presented, the participants would repeat those items to themselves and as new items were presented, the participants would continue to rehearse previous items along with the newer items. It was demonstrated that the primacy effect had a greater influence on recall when there was more time between presentation of items so that participants would have a greater chance to rehearse previous (prime) items.
</p><p>Overt rehearsal was a technique that was meant to test participants' rehearsal patterns. In an experiment using this technique, participants were asked to recite out loud the items that come to mind. In this way, the experimenter was able to see that participants would repeat earlier items more than items in the middle of the list, thus rehearsing them more frequently and having a better recall of the prime items than the middle items later on.
</p><p>In another experiment, by Brodie and Murdock, the recency effect was found to be partially responsible for the primacy effect. In their experiment, they also used the overt-rehearsal technique and found that in addition to rehearsing earlier items more than later items, participants were rehearsing earlier items later on in the list. In this way, earlier items were closer to the test period by way of rehearsal and could be partially explained by the recency effect.
</p><p>In 2013, a study showed that primacy effect is also prominent in decision making based on experience in a repeated-choice paradigm, a learning process also known as operant conditioning. The authors showed that importance attached to the value of the first reward on subsequent behaviour, a phenomenon they denoted as outcome primacy.
</p><p>In another study, participants received one of two sentences. For example, one may be given "Steve is smart, diligent, critical, impulsive, and jealous." and the other "Steve is jealous, impulsive, critical, diligent, and smart." These two sentences contain the same information. The first one suggests positive trait at the beginning while the second one has negative traits. Researchers found that the subjects evaluated Steve more positively when given the first sentence, compared with the second one.
</p>
<h2 data-mw-anchor="Recency_effect">Recency effect</h2>

<p>Two traditional classes of theories explain the recency effect.
</p>
<h3 data-mw-anchor="Dual-store_models">Dual-store models</h3>
<p>These models postulate that study items listed last are retrieved from a highly accessible short-term buffer, i.e. the short-term store (STS) in human memory. This allows items that are recently studied to have an advantage over those that were studied earlier, as earlier study items have to be retrieved with greater effort from one’s long-term memory store (LTS).
</p><p>An important prediction of such models is that the presentation of a distraction, for example solving arithmetic problems for 10–30 seconds, during the retention period (the time between list presentation and test) attenuates the recency effect. Since the STS has limited capacity, the distraction displaces later study list items from the STS so that at test, these items can only be retrieved from the LTS, and have lost their earlier advantage of being more easily retrieved from the short-term buffer. As such, dual-store models successfully account for both the recency effect in immediate recall tasks, and the attenuation of such an effect in the delayed free recall task.
</p><p>A major problem with this model, however, is that it cannot predict the long-term recency effect observed in delayed recall, when a distraction intervenes between each study item during the interstimulus interval (continuous distractor task). Since the distraction is still present after the last study item, it should displace the study item from STS such that the recency effect is attenuated. The existence of this long-term recency effect thus raises the possibility that immediate and long-term recency effects share a common mechanism.
</p>
<h3 data-mw-anchor="Single-store_models">Single-store models</h3>
<p>According to single-store theories, a single mechanism is responsible for serial-position effects. A first type of model is based on relative temporal distinctiveness, in which the time lag between the study of each list item and the test determines the relative competitiveness of an item’s memory trace at retrieval. In this model, end-of-list items are thought to be more distinct, and hence more easily retrieved.
</p><p>Another type of model is based on contextual variability, which postulates that retrieval of items from memory is cued not only based on one’s mental representation of the study item itself, but also of the study context. Since context varies and increasingly changes with time, on an immediate free-recall test, when memory items compete for retrieval, more recently studied items will have more similar encoding contexts to the test context, and are more likely to be recalled.
</p><p>Outside immediate free recall, these models can also predict the presence or absence of the recency effect in delayed free recall and continual-distractor free-recall conditions. Under delayed recall conditions, the test context would have drifted away with increasing retention interval, leading to attenuated recency effect. Under continual distractor recall conditions, while increased interpresentation intervals reduce the similarities between study context and test context, the relative similarities among items remains unchanged. As long as the recall process is competitive, recent items will win out, so a recency effect is observed.
</p>
<h3 data-mw-anchor="Ratio_rule">Ratio rule</h3>
<p>Overall, an important empirical observation regarding the recency effect is that it is not the absolute duration of retention intervals (RI, the time between end of study and test period) or of inter-presentation intervals (IPI, the time between different study items) that matters. Rather, the amount of recency is determined by the ratio of RI to IPI (the ratio rule). As a result, as long as this ratio is fixed, recency will be observed regardless of the absolute values of intervals, so that recency can be observed at all time scales, a phenomenon known as<b> time-scale invariance</b>. This contradicts dual-store models, which assume that recency depends on the size of STS, and the rule governing the displacement of items in the STS.
</p><p>Potential explanations either then explain the recency effect as occurring through a single, same mechanism, or re-explain it through a different type of model that postulates two different mechanisms for immediate and long-term recency effects. One such explanation is provided by Davelaar et al. (2005), who argue that there are dissociations between immediate and long-term recency phenomena that cannot be explained by a single-component memory model, and who argues for the existence of a STS that explains immediate recency, and a second mechanism based on contextual drift that explains long-term recency. The recency effect as well as the <b>ratio</b> changes in Alzheimer's disease and therefore can be used as an indicator of this disease condition from the earliest stages of neurodegeneration 
</p>
<h2 data-mw-anchor="Related_effects">Related effects</h2>
<p>In 1977, William Crano decided to outline a study to further the previous conclusions on the nature of order effects, in particular those of primacy vs. recency, which were said to be unambiguous and opposed in their predictions. The specifics tested by Crano were:
</p>
<dl><dt>Change of meaning hypothesis</dt>
<dd>The items on the beginning of a list establish a theme that the participants expect the rest of the list to fall into. The participant modified the meaning of some of the words on the list to fit with the expectation he or she established. Watkins and Peynicioglu (1984) explain this as participants changing the meaning of words, deviating from the established theme, to reduce the amount of deviation in the information presented.</dd>
<dt>Inconsistency discounting</dt>
<dd>Participants would disregard information that was not consistent with previous items presented to them.  In other words, discounting involves thinking of inconsistent information as having less value than information that is consistent with other information presented (Devine &amp; Ostrom, 1985).</dd>
<dt>Attention decrement hypothesis</dt>
<dd>Information presented first has a greater influence on participants than information that is presented later, causing a primacy effect to occur, even if the information is consistent. Steiner and Rain (1989) explain people pay more attention to information presented at the beginning, but progressively pay less attention to the information presented to them. The primacy effect occurs because participants pay attention to the beginning information and ignore the information presented later. On the other hand, if participants are in a situation where they have to continuously pay attention to information, a recency effect may occur.</dd></dl>
<p>The <b>continuity effect</b> or lag-recency effect predicts that having made a successful recall, the next recalled item is less likely to come from a remote serial position, rather than a nearby serial position (Kahana, Howard, Zaromb &amp; Wingfiend, 2002). The difference between the two items' serial position is referred to as serial-position lag. Another factor, called the conditional-response probability, is the likelihood of recalling a certain serial-position lag. A graph of serial-position lag versus conditional response probability reveals that the next item recalled minimizes absolute lag, with a higher likelihood for the adjacent than the previous one.
</p>
<h2 data-mw-anchor="See_also">See also</h2>
<ul><li>Anchoring (cognitive bias)</li>
<li>Clive Wearing</li>
<li>Henry Molaison</li>
<li>Law of primacy in persuasion</li>
<li>Learning curve</li>
<li>List of memory biases</li>
<li>List of cognitive biases</li>
<li>Principles of learning</li>
<li>Peak–end rule</li>
<li>Reminiscence bump</li></ul>
<h2 data-mw-anchor="Notes">Notes</h2>

<h2 data-mw-anchor="References">References</h2>
<ul><li><cite id="CITEREFColucciaGambozBrandimonte2011" class="citation journal cs1">Coluccia, E.; Gamboz, N.; Brandimonte, M. A. (2011). "Normative data for a battery of free recall, cued recall and recognition tests in the elderly Italian population". <i>Neurol Sci</i>. <b>32</b> (6): <span>1103–</span>1114. doi:10.1007/s10072-011-0747-5. PMID 21918879. S2CID 22451152.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neurol+Sci&amp;rft.atitle=Normative+data+for+a+battery+of+free+recall%2C+cued+recall+and+recognition+tests+in+the+elderly+Italian+population&amp;rft.volume=32&amp;rft.issue=6&amp;rft.pages=1103-1114&amp;rft.date=2011&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A22451152%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F21918879&amp;rft_id=info%3Adoi%2F10.1007%2Fs10072-011-0747-5&amp;rft.aulast=Coluccia&amp;rft.aufirst=E.&amp;rft.au=Gamboz%2C+N.&amp;rft.au=Brandimonte%2C+M.+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASerial-position+effect"></span></li>
<li><cite id="CITEREFFrensch1994" class="citation journal cs1">Frensch, P.A. (1994). "Composition during serial learning: a serial position effect". <i>Journal of Experimental Psychology: Learning, Memory, and Cognition</i>. <b>20</b> (2): <span>423–</span>443. doi:10.1037/0278-7393.20.2.423. PMID 8151278.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Experimental+Psychology%3A+Learning%2C+Memory%2C+and+Cognition&amp;rft.atitle=Composition+during+serial+learning%3A+a+serial+position+effect&amp;rft.volume=20&amp;rft.issue=2&amp;rft.pages=423-443&amp;rft.date=1994&amp;rft_id=info%3Adoi%2F10.1037%2F0278-7393.20.2.423&amp;rft_id=info%3Apmid%2F8151278&amp;rft.aulast=Frensch&amp;rft.aufirst=P.A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASerial-position+effect"></span></li>
<li><cite id="CITEREFHealyHavasParkour2000" class="citation journal cs1">Healy, A.F.; Havas, D.A.; Parkour, J.T. (2000). "Comparing serial position effects in semantic and episodic memory using reconstruction of order tasks". <i>Journal of Memory and Language</i>. <b>42</b> (2): <span>147–</span>167. doi:10.1006/jmla.1999.2671.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Memory+and+Language&amp;rft.atitle=Comparing+serial+position+effects+in+semantic+and+episodic+memory+using+reconstruction+of+order+tasks&amp;rft.volume=42&amp;rft.issue=2&amp;rft.pages=147-167&amp;rft.date=2000&amp;rft_id=info%3Adoi%2F10.1006%2Fjmla.1999.2671&amp;rft.aulast=Healy&amp;rft.aufirst=A.F.&amp;rft.au=Havas%2C+D.A.&amp;rft.au=Parkour%2C+J.T.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASerial-position+effect"></span></li>
<li><cite id="CITEREFHowardKahana1999" class="citation journal cs1">Howard, M. W.; Kahana, M. (1999). "Contextual Variability and Serial Position Effects in Free Recall". <i>Journal of Experimental Psychology: Learning, Memory, and Cognition</i>. <b>25</b> (4): <span>923–</span>941. CiteSeerX <span title="Freely accessible">10.1.1.360.18</span>. doi:10.1037/0278-7393.25.4.923. PMID 10439501.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Experimental+Psychology%3A+Learning%2C+Memory%2C+and+Cognition&amp;rft.atitle=Contextual+Variability+and+Serial+Position+Effects+in+Free+Recall&amp;rft.volume=25&amp;rft.issue=4&amp;rft.pages=923-941&amp;rft.date=1999&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.360.18%23id-name%3DCiteSeerX&amp;rft_id=info%3Apmid%2F10439501&amp;rft_id=info%3Adoi%2F10.1037%2F0278-7393.25.4.923&amp;rft.aulast=Howard&amp;rft.aufirst=M.+W.&amp;rft.au=Kahana%2C+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASerial-position+effect"></span></li>
<li><cite id="CITEREFKahanaHowardZarombWingfield2002" class="citation journal cs1">Kahana, M. J.; Howard, M. W.; Zaromb, F.; Wingfield, A. (2002). "Age dissociates recency and lag recency effects in free recall". <i>Journal of Experimental Psychology</i>. <b>28</b> (3): <span>530–</span>540. doi:10.1037/0278-7393.28.3.530. PMID 12018505.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Experimental+Psychology&amp;rft.atitle=Age+dissociates+recency+and+lag+recency+effects+in+free+recall&amp;rft.volume=28&amp;rft.issue=3&amp;rft.pages=530-540&amp;rft.date=2002&amp;rft_id=info%3Adoi%2F10.1037%2F0278-7393.28.3.530&amp;rft_id=info%3Apmid%2F12018505&amp;rft.aulast=Kahana&amp;rft.aufirst=M.+J.&amp;rft.au=Howard%2C+M.+W.&amp;rft.au=Zaromb%2C+F.&amp;rft.au=Wingfield%2C+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASerial-position+effect"></span></li></ul>
<h2 data-mw-anchor="Further_reading">Further reading</h2>
<ul><li>Liebermann, David A. <i>Learning and memory: An integrative approach.</i> Belmont, CA: Thomson/Wadsworth, 2004, ISBN 978-0-534-61974-9.</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Serial-position_effect#Primacy_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Recency effect</h2>
<a href='https://en.wikipedia.org/wiki/Serial-position_effect#Recency_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Serial-position effect</b> is the tendency of a person to recall the first and last items in a series best, and the middle items worst. The term was coined by Hermann Ebbinghaus through studies he performed on himself, and refers to the finding that recall accuracy varies as a function of an item's position within a study list. When asked to recall a list of items in any order (free recall), people tend to begin recall with the end of the list, recalling those items best (the <b>recency effect</b>). Among earlier list items, the first few items are recalled more frequently than the middle items (the <b>primacy effect</b>).
</p><p>One suggested reason for the primacy effect is that the initial items presented are most effectively stored in long-term memory because of the greater amount of processing devoted to them. (The first list item can be rehearsed by itself; the second must be rehearsed along with the first, the third along with the first and second, and so on.) The primacy effect is reduced when items are presented quickly and is enhanced when presented slowly (factors that reduce and enhance processing of each item and thus permanent storage). Longer presentation lists have been found to reduce the primacy effect.
</p><p>One theorised reason for the recency effect is that these items are still present in working memory when recall is solicited. Items that benefit from neither (the middle items) are recalled most poorly. An additional explanation for the recency effect is related to temporal context: if tested immediately after rehearsal, the current temporal context can serve as a retrieval cue, which would predict more recent items to have a higher likelihood of recall than items that were studied in a different temporal context (earlier in the list). The recency effect is reduced when an interfering task is given. Intervening tasks involve working memory, as the distractor activity, if exceeding 15 to 30 seconds in duration, can cancel out the recency effect. Additionally, if recall comes immediately after the test, the recency effect is consistent regardless of the length of the studied list, or presentation rate.
</p><p>Amnesiacs with poor ability to form permanent long-term memories do not show a primacy effect, but do show a recency effect if recall comes immediately after study. People with Alzheimer's disease exhibit a reduced primacy effect but do not produce a recency effect in recall.
</p>

<h2 data-mw-anchor="Primacy_effect">Primacy effect</h2>
<p>In psychology and sociology, the primacy effect (also known as the primacy bias) is a cognitive bias that results in a subject recalling primary information presented better than information presented later on. For example, a subject who reads a sufficiently long list of words is more likely to remember words toward the beginning than words in the middle.
</p><p>Many researchers have tried to explain this phenomenon through free recall [null tests]. Coluccia, Gamboz, and Brandimonte (2011) explain free recall as participants trying to remember information without any prompting. In some experiments in the late 20th century, it was noted that participants who knew that they were going to be tested on a list presented to them would rehearse items: as items were presented, the participants would repeat those items to themselves and as new items were presented, the participants would continue to rehearse previous items along with the newer items. It was demonstrated that the primacy effect had a greater influence on recall when there was more time between presentation of items so that participants would have a greater chance to rehearse previous (prime) items.
</p><p>Overt rehearsal was a technique that was meant to test participants' rehearsal patterns. In an experiment using this technique, participants were asked to recite out loud the items that come to mind. In this way, the experimenter was able to see that participants would repeat earlier items more than items in the middle of the list, thus rehearsing them more frequently and having a better recall of the prime items than the middle items later on.
</p><p>In another experiment, by Brodie and Murdock, the recency effect was found to be partially responsible for the primacy effect. In their experiment, they also used the overt-rehearsal technique and found that in addition to rehearsing earlier items more than later items, participants were rehearsing earlier items later on in the list. In this way, earlier items were closer to the test period by way of rehearsal and could be partially explained by the recency effect.
</p><p>In 2013, a study showed that primacy effect is also prominent in decision making based on experience in a repeated-choice paradigm, a learning process also known as operant conditioning. The authors showed that importance attached to the value of the first reward on subsequent behaviour, a phenomenon they denoted as outcome primacy.
</p><p>In another study, participants received one of two sentences. For example, one may be given "Steve is smart, diligent, critical, impulsive, and jealous." and the other "Steve is jealous, impulsive, critical, diligent, and smart." These two sentences contain the same information. The first one suggests positive trait at the beginning while the second one has negative traits. Researchers found that the subjects evaluated Steve more positively when given the first sentence, compared with the second one.
</p>
<h2 data-mw-anchor="Recency_effect">Recency effect</h2>

<p>Two traditional classes of theories explain the recency effect.
</p>
<h3 data-mw-anchor="Dual-store_models">Dual-store models</h3>
<p>These models postulate that study items listed last are retrieved from a highly accessible short-term buffer, i.e. the short-term store (STS) in human memory. This allows items that are recently studied to have an advantage over those that were studied earlier, as earlier study items have to be retrieved with greater effort from one’s long-term memory store (LTS).
</p><p>An important prediction of such models is that the presentation of a distraction, for example solving arithmetic problems for 10–30 seconds, during the retention period (the time between list presentation and test) attenuates the recency effect. Since the STS has limited capacity, the distraction displaces later study list items from the STS so that at test, these items can only be retrieved from the LTS, and have lost their earlier advantage of being more easily retrieved from the short-term buffer. As such, dual-store models successfully account for both the recency effect in immediate recall tasks, and the attenuation of such an effect in the delayed free recall task.
</p><p>A major problem with this model, however, is that it cannot predict the long-term recency effect observed in delayed recall, when a distraction intervenes between each study item during the interstimulus interval (continuous distractor task). Since the distraction is still present after the last study item, it should displace the study item from STS such that the recency effect is attenuated. The existence of this long-term recency effect thus raises the possibility that immediate and long-term recency effects share a common mechanism.
</p>
<h3 data-mw-anchor="Single-store_models">Single-store models</h3>
<p>According to single-store theories, a single mechanism is responsible for serial-position effects. A first type of model is based on relative temporal distinctiveness, in which the time lag between the study of each list item and the test determines the relative competitiveness of an item’s memory trace at retrieval. In this model, end-of-list items are thought to be more distinct, and hence more easily retrieved.
</p><p>Another type of model is based on contextual variability, which postulates that retrieval of items from memory is cued not only based on one’s mental representation of the study item itself, but also of the study context. Since context varies and increasingly changes with time, on an immediate free-recall test, when memory items compete for retrieval, more recently studied items will have more similar encoding contexts to the test context, and are more likely to be recalled.
</p><p>Outside immediate free recall, these models can also predict the presence or absence of the recency effect in delayed free recall and continual-distractor free-recall conditions. Under delayed recall conditions, the test context would have drifted away with increasing retention interval, leading to attenuated recency effect. Under continual distractor recall conditions, while increased interpresentation intervals reduce the similarities between study context and test context, the relative similarities among items remains unchanged. As long as the recall process is competitive, recent items will win out, so a recency effect is observed.
</p>
<h3 data-mw-anchor="Ratio_rule">Ratio rule</h3>
<p>Overall, an important empirical observation regarding the recency effect is that it is not the absolute duration of retention intervals (RI, the time between end of study and test period) or of inter-presentation intervals (IPI, the time between different study items) that matters. Rather, the amount of recency is determined by the ratio of RI to IPI (the ratio rule). As a result, as long as this ratio is fixed, recency will be observed regardless of the absolute values of intervals, so that recency can be observed at all time scales, a phenomenon known as<b> time-scale invariance</b>. This contradicts dual-store models, which assume that recency depends on the size of STS, and the rule governing the displacement of items in the STS.
</p><p>Potential explanations either then explain the recency effect as occurring through a single, same mechanism, or re-explain it through a different type of model that postulates two different mechanisms for immediate and long-term recency effects. One such explanation is provided by Davelaar et al. (2005), who argue that there are dissociations between immediate and long-term recency phenomena that cannot be explained by a single-component memory model, and who argues for the existence of a STS that explains immediate recency, and a second mechanism based on contextual drift that explains long-term recency. The recency effect as well as the <b>ratio</b> changes in Alzheimer's disease and therefore can be used as an indicator of this disease condition from the earliest stages of neurodegeneration 
</p>
<h2 data-mw-anchor="Related_effects">Related effects</h2>
<p>In 1977, William Crano decided to outline a study to further the previous conclusions on the nature of order effects, in particular those of primacy vs. recency, which were said to be unambiguous and opposed in their predictions. The specifics tested by Crano were:
</p>
<dl><dt>Change of meaning hypothesis</dt>
<dd>The items on the beginning of a list establish a theme that the participants expect the rest of the list to fall into. The participant modified the meaning of some of the words on the list to fit with the expectation he or she established. Watkins and Peynicioglu (1984) explain this as participants changing the meaning of words, deviating from the established theme, to reduce the amount of deviation in the information presented.</dd>
<dt>Inconsistency discounting</dt>
<dd>Participants would disregard information that was not consistent with previous items presented to them.  In other words, discounting involves thinking of inconsistent information as having less value than information that is consistent with other information presented (Devine &amp; Ostrom, 1985).</dd>
<dt>Attention decrement hypothesis</dt>
<dd>Information presented first has a greater influence on participants than information that is presented later, causing a primacy effect to occur, even if the information is consistent. Steiner and Rain (1989) explain people pay more attention to information presented at the beginning, but progressively pay less attention to the information presented to them. The primacy effect occurs because participants pay attention to the beginning information and ignore the information presented later. On the other hand, if participants are in a situation where they have to continuously pay attention to information, a recency effect may occur.</dd></dl>
<p>The <b>continuity effect</b> or lag-recency effect predicts that having made a successful recall, the next recalled item is less likely to come from a remote serial position, rather than a nearby serial position (Kahana, Howard, Zaromb &amp; Wingfiend, 2002). The difference between the two items' serial position is referred to as serial-position lag. Another factor, called the conditional-response probability, is the likelihood of recalling a certain serial-position lag. A graph of serial-position lag versus conditional response probability reveals that the next item recalled minimizes absolute lag, with a higher likelihood for the adjacent than the previous one.
</p>
<h2 data-mw-anchor="See_also">See also</h2>
<ul><li>Anchoring (cognitive bias)</li>
<li>Clive Wearing</li>
<li>Henry Molaison</li>
<li>Law of primacy in persuasion</li>
<li>Learning curve</li>
<li>List of memory biases</li>
<li>List of cognitive biases</li>
<li>Principles of learning</li>
<li>Peak–end rule</li>
<li>Reminiscence bump</li></ul>
<h2 data-mw-anchor="Notes">Notes</h2>

<h2 data-mw-anchor="References">References</h2>
<ul><li><cite id="CITEREFColucciaGambozBrandimonte2011" class="citation journal cs1">Coluccia, E.; Gamboz, N.; Brandimonte, M. A. (2011). "Normative data for a battery of free recall, cued recall and recognition tests in the elderly Italian population". <i>Neurol Sci</i>. <b>32</b> (6): <span>1103–</span>1114. doi:10.1007/s10072-011-0747-5. PMID 21918879. S2CID 22451152.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neurol+Sci&amp;rft.atitle=Normative+data+for+a+battery+of+free+recall%2C+cued+recall+and+recognition+tests+in+the+elderly+Italian+population&amp;rft.volume=32&amp;rft.issue=6&amp;rft.pages=1103-1114&amp;rft.date=2011&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A22451152%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F21918879&amp;rft_id=info%3Adoi%2F10.1007%2Fs10072-011-0747-5&amp;rft.aulast=Coluccia&amp;rft.aufirst=E.&amp;rft.au=Gamboz%2C+N.&amp;rft.au=Brandimonte%2C+M.+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASerial-position+effect"></span></li>
<li><cite id="CITEREFFrensch1994" class="citation journal cs1">Frensch, P.A. (1994). "Composition during serial learning: a serial position effect". <i>Journal of Experimental Psychology: Learning, Memory, and Cognition</i>. <b>20</b> (2): <span>423–</span>443. doi:10.1037/0278-7393.20.2.423. PMID 8151278.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Experimental+Psychology%3A+Learning%2C+Memory%2C+and+Cognition&amp;rft.atitle=Composition+during+serial+learning%3A+a+serial+position+effect&amp;rft.volume=20&amp;rft.issue=2&amp;rft.pages=423-443&amp;rft.date=1994&amp;rft_id=info%3Adoi%2F10.1037%2F0278-7393.20.2.423&amp;rft_id=info%3Apmid%2F8151278&amp;rft.aulast=Frensch&amp;rft.aufirst=P.A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASerial-position+effect"></span></li>
<li><cite id="CITEREFHealyHavasParkour2000" class="citation journal cs1">Healy, A.F.; Havas, D.A.; Parkour, J.T. (2000). "Comparing serial position effects in semantic and episodic memory using reconstruction of order tasks". <i>Journal of Memory and Language</i>. <b>42</b> (2): <span>147–</span>167. doi:10.1006/jmla.1999.2671.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Memory+and+Language&amp;rft.atitle=Comparing+serial+position+effects+in+semantic+and+episodic+memory+using+reconstruction+of+order+tasks&amp;rft.volume=42&amp;rft.issue=2&amp;rft.pages=147-167&amp;rft.date=2000&amp;rft_id=info%3Adoi%2F10.1006%2Fjmla.1999.2671&amp;rft.aulast=Healy&amp;rft.aufirst=A.F.&amp;rft.au=Havas%2C+D.A.&amp;rft.au=Parkour%2C+J.T.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASerial-position+effect"></span></li>
<li><cite id="CITEREFHowardKahana1999" class="citation journal cs1">Howard, M. W.; Kahana, M. (1999). "Contextual Variability and Serial Position Effects in Free Recall". <i>Journal of Experimental Psychology: Learning, Memory, and Cognition</i>. <b>25</b> (4): <span>923–</span>941. CiteSeerX <span title="Freely accessible">10.1.1.360.18</span>. doi:10.1037/0278-7393.25.4.923. PMID 10439501.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Experimental+Psychology%3A+Learning%2C+Memory%2C+and+Cognition&amp;rft.atitle=Contextual+Variability+and+Serial+Position+Effects+in+Free+Recall&amp;rft.volume=25&amp;rft.issue=4&amp;rft.pages=923-941&amp;rft.date=1999&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.360.18%23id-name%3DCiteSeerX&amp;rft_id=info%3Apmid%2F10439501&amp;rft_id=info%3Adoi%2F10.1037%2F0278-7393.25.4.923&amp;rft.aulast=Howard&amp;rft.aufirst=M.+W.&amp;rft.au=Kahana%2C+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASerial-position+effect"></span></li>
<li><cite id="CITEREFKahanaHowardZarombWingfield2002" class="citation journal cs1">Kahana, M. J.; Howard, M. W.; Zaromb, F.; Wingfield, A. (2002). "Age dissociates recency and lag recency effects in free recall". <i>Journal of Experimental Psychology</i>. <b>28</b> (3): <span>530–</span>540. doi:10.1037/0278-7393.28.3.530. PMID 12018505.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Experimental+Psychology&amp;rft.atitle=Age+dissociates+recency+and+lag+recency+effects+in+free+recall&amp;rft.volume=28&amp;rft.issue=3&amp;rft.pages=530-540&amp;rft.date=2002&amp;rft_id=info%3Adoi%2F10.1037%2F0278-7393.28.3.530&amp;rft_id=info%3Apmid%2F12018505&amp;rft.aulast=Kahana&amp;rft.aufirst=M.+J.&amp;rft.au=Howard%2C+M.+W.&amp;rft.au=Zaromb%2C+F.&amp;rft.au=Wingfield%2C+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASerial-position+effect"></span></li></ul>
<h2 data-mw-anchor="Further_reading">Further reading</h2>
<ul><li>Liebermann, David A. <i>Learning and memory: An integrative approach.</i> Belmont, CA: Thomson/Wadsworth, 2004, ISBN 978-0-534-61974-9.</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Serial-position_effect#Recency_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Part–set cueing effect</h2>
<a href='https://en.wikipedia.org/wiki/Memory_inhibition#Part-set_cuing_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>In psychology, <b>memory inhibition</b> is the ability <i>not</i> to remember irrelevant information. The scientific concept of memory inhibition should not be confused with everyday uses of the word "inhibition". Scientifically speaking, memory inhibition is a type of cognitive inhibition, which is the stopping or overriding of a mental process, in whole or in part, with or without intention.
</p><p>Memory inhibition is a critical component of an effective memory system. While some memories are retained for a lifetime, most memories are forgotten. According to evolutionary psychologists, forgetting is adaptive because it facilitates selectivity of rapid, efficient recollection. For example, a person trying to remember where they parked their car would not want to remember every place they have ever parked. In order to remember something, therefore, it is essential not only to activate the relevant information, but also to inhibit irrelevant information. 
</p><p>There are many memory phenomena that seem to involve inhibition, although there is often debate about the distinction between interference and inhibition.
</p>

<h2 data-mw-anchor="History">History</h2>
<p>In the early days of psychology, the concept of inhibition was prevalent and influential (e.g., Breese, 1899; Pillsbury, 1908; Wundt, 1902). These psychologists applied the concept of inhibition (and interference) to early theories of learning and forgetting. Starting in 1894, German scientists Muller and Shumann conducted empirical studies that demonstrated how learning a second list of items interfered with memory of the first list. Based on these experiments, Muller argued that the process of attention was based on facilitation. Arguing for a different explanation, Wundt (1902) claimed that selective attention was accomplished by the active inhibition of unattended information, and that to attend to one of several simultaneous stimuli, the others had to be inhibited. American Psychologist Walter Pillsbury combined Muller and Wundt's arguments, claiming that attention both facilitates information that is wanted and inhibits information that is unwanted.
</p><p>In the face of behaviorism during the late 1920s through the 1950s, and through the early growth of cognitive psychology in the late 1950s and early 1960s, inhibition largely disappeared as a theory. Instead, classical interference theory dominated memory research until as late as 1960. By the early 1970s, however, classical interference theory began to decline due to its reliance on associationism,  its inability to explain the facts of interference or how interference applies to everyday life, and to newly published reports on proactive and retroactive inhibition.
</p><p>Since the mid-1980s, there has been a renewed interest in understanding the role of inhibition in cognition. Research on a wide variety of psychological processes, including attention, perception, learning and memory, psycholinguistics, cognitive development, aging, learning disabilities, and neuropsychology, suggests that resistance to interference (which implies capacity for inhibition) is an important part of cognition.
</p><p>More recently, researchers suggest that the hippocampus plays a role in the regulation of disliked and competing memories, and fMRI studies have shown hippocampus activity during inhibition processes.
</p>
<h2 data-mw-anchor="Empirical_research">Empirical research</h2>
<h3 data-mw-anchor="Part-set_cuing_effect"><span id="PartSet"></span>Part-set cuing effect</h3>
<p>The "part-set cuing effect" was initially discovered by Slamecka (1968), who found that providing a portion of to-be-remembered items as test cues
often impairs retrieval of the remaining un-cued items compared with performance in a no-cue (free-recall) control condition. Such an effect is intriguing because
normally cues are expected to aid recall (e.g., Tulving &amp; Pearlstone,
1966). A prominent figure in retrieval-based inhibition research, Henry L. Roediger III was another one of the first psychologists to propose the idea that retrieving an item reduces the subsequent accessibility of other stored items. Becoming aware of the part-set cueing effect reduces the effect, such that relearning part of a set of previously learned associations can improve recall of the non-relearned associations.
</p>
<h3 data-mw-anchor="Hasher_and_Zacks'_inhibition_account_of_aging" data-mw-fallback-anchor="Hasher_and_Zacks.27_inhibition_account_of_aging">Hasher and Zacks' inhibition account of aging</h3>
<p>Using inhibition to explain memory processes began with the work of Hasher and Zacks (1988), which focused on the cognitive costs associated with aging and bridging the attention-memory gap. Hasher and Zacks found that older adults show impairments on tasks that require inhibiting irrelevant information in working memory, and these impairments may lead to problems in a variety of contexts.
</p>
<h3 data-mw-anchor="Retrieval-induced_forgetting">Retrieval-induced forgetting</h3>

<p>Anderson and Spellman's model of retrieval-induced forgetting suggests that when items compete during retrieval, an inhibitory process will serve to suppress those competitors. For instance, retrieval of one meaning for a word (e.g. the verb meaning of the word <i>sock</i>) will tend to inhibit the dominant meaning of that word (e.g. the noun meaning of <i>sock</i>). In 1995, Anderson and Spellman conducted a three-phase study using their retrieval-induced forgetting model to demonstrate unlearning as inhibition.
</p>
<ul><li>Study phase: Participants study a list of category-exemplar pairings where some exemplars are semantically similar in that they belong to another category besides the one they are explicitly paired with (e.g. Food-Cracker, Food-Strawberry, Red-Tomato, Red-Blood).</li>
<li>Retrieval-practice phase: Participants are cued to practice remembering some of the exemplars given the category cue (e.g. Red-Bl__).</li>
<li>Test phase: Given each category as a cue, the participant tries to recall the exemplar (e.g. Food-C__, Food-S__, Red-T__, Red-Bl__).</li></ul>
<p>Anderson and Spellman observed that items that shared a semantic relationship with practiced information was less recallable. Using the example from above, recall of items related to practiced information, including <i>tomato</i> and <i>strawberry</i> was lower than recall for <i>cracker</i>, even though strawberry is part of a different pair. This finding suggests that associative competition by explicit category cue is not the only factor in retrieval difficulty. They theorized that the brain suppresses, or inhibits, non-practiced attributes. This explains why an item that is very similar to tomato, but not from the same pair, also exhibits decreased recall rate.
</p>
<h3 data-mw-anchor='"Think/no-think"_paradigm_and_intentional_inhibition' data-mw-fallback-anchor=".22Think.2Fno-think.22_paradigm_and_intentional_inhibition">"Think/no-think" paradigm and intentional inhibition</h3>
<p>During the recovered memory debate of the 1990s, cognitive psychologists were dubious about whether specific memories could be repressed. One stumbling block was that repression had not been demonstrated in a research study. In 2001, researchers Anderson and Green claimed to have found laboratory evidence of suppression. They trained their participants with a list of unrelated word pairs (such as ordeal-roach), so they could respond with the second member of the pair (roach) when they saw the other member (ordeal). The more frequently participants had tried to not think about a particular word, the less likely they were to retrieve it on a final memory test. This impairment even occurred when participants were given an "independent probe" test, i.e. given a similar category (insect) instead of the original cue (roach), and asked to fill in the blank on the memory test: insect-r_____. According to Anderson and Green, the fact that participants had a decreased ability to recall items they were told to forget strongly supports the existence of an inhibitory control mechanism and the idea that people have the ability to suppress unwanted memories.
</p><p>Though Anderson &amp; Green's (2001) results have been replicated several times, a group of prominent psychology researchers using the same methodology as the original study were unable to replicate even the basic result (Bulevich, Roediger, Balota, &amp; Butler, 2006). They determined that suppression is not a robust experimental phenomenon in the think/no-think paradigm and suggested that Anderson and Green's findings could be explained by retroactive interference, or simply thinking about X when told to "not think" about Y.
</p>
<h2 data-mw-anchor="Amnesia_for_trauma_or_abuse">Amnesia for trauma or abuse</h2>
<p>Amnesia, the forgetting of important personal information, usually occurs because of disease or injury to the brain, while psychogenic amnesia, which involves a loss of personal identity and has psychological causes, is rare. Nonetheless, a range of studies have concluded that at least 10% of physical and sexual abuse victims forget the abuse. Some studies claim that the rate of delayed recall of many forms of traumatic experiences (including natural disasters, kidnapping, torture and more) averages among studies at approximately 15%, with the highest rates resulting from child sexual abuse, military combat, and witnessing a family member murdered. A 1996 interview survey of 711 women reported that forgetting and later remembering childhood sexual abuse is not uncommon; more than a quarter of the respondents who reported abuse also reported forgetting the abuse for some period of time and then recalling it on their own. Of those who reported abuse, less than 2% reported that the recall of the abuse was assisted by a therapist or other professional. Other studies show that people who have experienced trauma usually remember it, not forget it. McNally (2001) found that women who report having either repressed or recovered memories of childhood sexual abuse have no worse memory for trauma cue words than women who have never been sexually abused. Similarly, McNally (1998) found that women who were sexually abused as children and who developed PTSD as a result of their abuse will not have any more trouble recalling trauma related words than healthy adult survivors of childhood sexual abuse or women who were never abused as children.
</p><p>Although the rate of recall of previously forgotten traumatic events was shown by Elliot and Briere (1996) to be unaffected by whether or not the victim had a history of being in psychotherapy, individuals who report repressed memories are more susceptible to producing false memories than individuals who could always recall the memory. Williams found that among women with confirmed histories of sexual abuse, approximately 38% did not recall the abuse 17 years later, especially when it was perpetrated by someone familiar to them. Hopper cites several studies which indicate that some abuse victims will have intervals of complete amnesia for their abuse. Peer reviewed and clinical studies have documented the existence of recovered memory; one website lists 43 legal cases where an individual whose claim to have recovered a repressed memory has been accepted by a court. Traumatic amnesia, which allegedly involves the forgetting of specific traumatic events for long periods of time, is highly controversial, as is repression, the psychodynamic explanation of traumatic amnesia. Because these concepts lack good empirical support, psychological scientists are skeptical about the validity of "recovered memories", and argue that some therapists, through suggestive techniques, have (un)knowingly encouraged false memories of victimization.
</p>
<h2 data-mw-anchor="Evidence_against">Evidence against</h2>
<p>The idea that subjects can actively inhibit a memory has many critics. MacLeod (2003) challenged the idea of inhibition in cognitive control, arguing that inhibition can be attributed to conflict resolution, which is the error-prone act of choosing between two similar values that do not necessarily have the same pair. Re-examine the pairs from above: Food-Cracker, Food-Strawberry, Red-Tomato, and Red-Blood. Memory inhibition theories suggest that recall of strawberry decreases when recall of tomato decreases because tomato's attributes are inhibited when red-blood is learned. MacLeod argues that inhibition does not take place, but instead is the result of confusion between similar word-pairs like food-tomato and red-strawberry that can lead to errors. This is different from tomato's attributes being inhibited. "In most cases where inhibitory mechanisms have been offered to explain cognitive performance", explains MacLeod, "non-inhibitory mechanisms can accomplish the same goal" (p. 203).
</p>
<h2 data-mw-anchor="See_also">See also</h2>
<ul><li>Emotion and memory</li>
<li>Interference theory</li></ul>
<h2 data-mw-anchor="References">References</h2>

<h2 data-mw-anchor="External_links">External links</h2>
<ul><li>Anderson's Memory Control Laboratory</li>
<li>Daniel Wegner's Thought Suppression Papers</li>
<li>Neural Systems Underlying the Suppression of Unwanted Memories</li>
<li><cite id="CITEREFSisonMather2007" class="citation journal cs1">Sison, Jo Ann G.; Mather, Mara (2007). "Does remembering emotional items impair recall of same-emotion items?". <i>Psychonomic Bulletin &amp; Review</i>. <b>14</b> (2): <span>282–</span>287. doi:<span title="Freely accessible">10.3758/BF03194065</span>. PMID 17694914.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Psychonomic+Bulletin+%26+Review&amp;rft.atitle=Does+remembering+emotional+items+impair+recall+of+same-emotion+items%3F&amp;rft.volume=14&amp;rft.issue=2&amp;rft.pages=282-287&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.3758%2FBF03194065&amp;rft_id=info%3Apmid%2F17694914&amp;rft.aulast=Sison&amp;rft.aufirst=Jo+Ann+G.&amp;rft.au=Mather%2C+Mara&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.3758%252FBF03194065&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AMemory+inhibition"></span> (emotional part-set cuing effects)</li>
<li>Innocence Project: an organization dedicated to exonerating wrongfully convicted individuals</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Memory_inhibition#Part-set_cuing_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Serial–position effect</h2>
<a href='https://en.wikipedia.org/wiki/Serial-position_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Serial-position effect</b> is the tendency of a person to recall the first and last items in a series best, and the middle items worst. The term was coined by Hermann Ebbinghaus through studies he performed on himself, and refers to the finding that recall accuracy varies as a function of an item's position within a study list. When asked to recall a list of items in any order (free recall), people tend to begin recall with the end of the list, recalling those items best (the <b>recency effect</b>). Among earlier list items, the first few items are recalled more frequently than the middle items (the <b>primacy effect</b>).
</p><p>One suggested reason for the primacy effect is that the initial items presented are most effectively stored in long-term memory because of the greater amount of processing devoted to them. (The first list item can be rehearsed by itself; the second must be rehearsed along with the first, the third along with the first and second, and so on.) The primacy effect is reduced when items are presented quickly and is enhanced when presented slowly (factors that reduce and enhance processing of each item and thus permanent storage). Longer presentation lists have been found to reduce the primacy effect.
</p><p>One theorised reason for the recency effect is that these items are still present in working memory when recall is solicited. Items that benefit from neither (the middle items) are recalled most poorly. An additional explanation for the recency effect is related to temporal context: if tested immediately after rehearsal, the current temporal context can serve as a retrieval cue, which would predict more recent items to have a higher likelihood of recall than items that were studied in a different temporal context (earlier in the list). The recency effect is reduced when an interfering task is given. Intervening tasks involve working memory, as the distractor activity, if exceeding 15 to 30 seconds in duration, can cancel out the recency effect. Additionally, if recall comes immediately after the test, the recency effect is consistent regardless of the length of the studied list, or presentation rate.
</p><p>Amnesiacs with poor ability to form permanent long-term memories do not show a primacy effect, but do show a recency effect if recall comes immediately after study. People with Alzheimer's disease exhibit a reduced primacy effect but do not produce a recency effect in recall.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Serial-position_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Suffix effect</h2>
<a href='https://en.wikipedia.org/wiki/List_of_cognitive_biases#Suffix_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p class="mw-empty-elt">
</p>

<p>Cognitive biases are systematic patterns of deviation from norm and/or rationality in judgment.  They are often studied in psychology, sociology and behavioral economics.
</p><p>Although the reality of most of these biases is confirmed by reproducible research, there are often controversies about how to classify these biases or how to explain them. Several theoretical causes are known for some cognitive biases, which provides a classification of biases by their common generative mechanism (such as noisy information-processing). Gerd Gigerenzer has criticized the framing of cognitive biases as errors in judgment, and favors interpreting them as arising from rational deviations from logical thought.
</p><p>Explanations include information-processing rules (i.e., mental shortcuts), called <i>heuristics</i>, that the brain uses to produce decisions or judgments. Biases have a variety of forms and appear as cognitive ("cold") bias, such as mental noise, or motivational ("hot") bias, such as when beliefs are distorted by wishful thinking. Both effects can be present at the same time.
</p><p>There are also controversies over some of these biases as to whether they count as useless or irrational, or whether they result in useful attitudes or behavior. For example, when getting to know others, people tend to ask leading questions which seem biased towards confirming their assumptions about the person. However, this kind of confirmation bias has also been argued to be an example of social skill; a way to establish a connection with the other person.
</p><p>Although this research overwhelmingly involves human subjects, some studies have found bias in non-human animals as well. For example, loss aversion has been shown in monkeys and hyperbolic discounting has been observed in rats, pigeons, and monkeys.
</p>

<h2 data-mw-anchor="Belief,_decision-making_and_behavioral" data-mw-fallback-anchor="Belief.2C_decision-making_and_behavioral">Belief, decision-making and behavioral</h2>
<p>These biases affect belief formation, reasoning processes, business and economic decisions, and human behavior in general.
</p>
<h3 data-mw-anchor="Anchoring_bias">Anchoring bias</h3>

<p>The anchoring bias, or focalism, is the tendency to rely too heavily—to "anchor"—on one trait or piece of information when making decisions (usually the first piece of information acquired on that subject).
Anchoring bias includes or involves the following:
</p>
<ul><li>Common source bias, the tendency to combine or compare research studies from the same source, or from sources that use the same methodologies or data.</li>
<li>Conservatism bias, the tendency to insufficiently revise one's belief when presented with new evidence.</li>
<li>Functional fixedness, a tendency limiting a person to using an object only in the way it is traditionally used.</li>
<li>Law of the instrument, an over-reliance on a familiar tool or methods, ignoring or under-valuing alternative approaches. "If all you have is a hammer, everything looks like a nail."</li></ul>
<h3 data-mw-anchor="Apophenia">Apophenia</h3>

<p>The tendency to perceive meaningful connections between unrelated things.
The following are types of apophenia:
</p>
<ul><li>Clustering illusion, the tendency to overestimate the importance of small runs, streaks, or clusters in large samples of random data (that is, seeing phantom patterns).</li>
<li>Illusory correlation, a tendency to inaccurately perceive a relationship between two unrelated events.</li>
<li>Pareidolia, a tendency to perceive a vague and random stimulus (often an image or sound) as significant, e.g., seeing images of animals or faces in clouds, the man in the Moon, and hearing non-existent hidden messages on records played in reverse.</li></ul>
<h3 data-mw-anchor="Availability_heuristic">Availability heuristic</h3>

<p>The availability heuristic (also known as the availability bias) is the tendency to overestimate the likelihood of events with greater "availability" in memory, which can be influenced by how recent the memories are or how unusual or emotionally charged they may be. The availability heuristic includes or involves the following:
</p>
<ul><li>Anthropocentric thinking, the tendency to use human analogies as a basis for reasoning about other, less familiar, biological phenomena.</li>
<li>Anthropomorphism is characterization of animals, objects, and abstract concepts as possessing human traits, emotions, or intentions. The opposite bias, of not attributing feelings or thoughts to another person, is dehumanised perception, a type of objectification.</li>
<li>Attentional bias, the tendency of perception to be affected by recurring thoughts.</li>
<li>Frequency illusion or Baader–Meinhof phenomenon. The frequency illusion is that once something has been noticed then every instance of that thing is noticed, leading to the belief it has a high frequency of occurrence (a form of selection bias). The Baader–Meinhof phenomenon is the illusion where something that has recently come to one's attention suddenly seems to appear with improbable frequency shortly afterwards. It was named after an incidence of frequency illusion in which the Baader–Meinhof Group was mentioned.</li>
<li>Implicit association, where the speed with which people can match words depends on how closely they are associated.</li>
<li>Salience bias, the tendency to focus on items that are more prominent or emotionally striking and ignore those that are unremarkable, even though this difference is often irrelevant by objective standards. See also von Restorff effect.</li>
<li>Selection bias, which happens when the members of a statistical sample are not chosen completely at random, which leads to the sample not being representative of the population.</li>
<li>Survivorship bias, which is concentrating on the people or things that "survived" some process and inadvertently overlooking those that did not because of their lack of visibility.</li>
<li>Quantification bias, the tendency to ascribe more weight to measured/quantified metrics than to unquantifiable values. See also: McNamara fallacy.</li>
<li>Well travelled road effect, the tendency to underestimate the duration taken to traverse oft-travelled routes and overestimate the duration taken to traverse less familiar routes.</li></ul>
<h3 data-mw-anchor="Cognitive_dissonance">Cognitive dissonance</h3>

<p>Cognitive dissonance is the perception of contradictory information and the mental toll of it.
</p>
<ul><li>Normalcy bias, a form of cognitive dissonance, is the refusal to plan for, or react to, a disaster which has never happened before.</li>
<li>Effort justification is a person's tendency to attribute greater value to an outcome if they had to put effort into achieving it. This can result in more value being applied to an outcome than it actually has. An example of this is the IKEA effect, the tendency for people to place a disproportionately high value on objects that they partially assembled themselves, such as furniture from IKEA, regardless of the quality of the end product.</li>
<li>Ben Franklin effect, where a person who has performed a favor for someone is more likely to do another favor for that person than they would be if they had <i>received</i> a favor from that person.</li></ul>
<h3 data-mw-anchor="Confirmation_bias">Confirmation bias</h3>

<p>Confirmation bias is the tendency to search for, interpret, focus on and remember information in a way that confirms one's preconceptions. There are multiple other cognitive biases which involve or are types of confirmation bias:
</p>
<ul><li>Backfire effect, a tendency to react to disconfirming evidence by strengthening one's previous beliefs.</li>
<li>Congruence bias, the tendency to test hypotheses exclusively through direct testing, instead of testing possible alternative hypotheses.</li>
<li>Experimenter's or expectation bias, the tendency for experimenters to believe, certify, and publish data that agree with their expectations for the outcome of an experiment, and to disbelieve, discard, or downgrade the corresponding weightings for data that appear to conflict with those expectations.</li>
<li>Observer-expectancy effect, when a researcher expects a given result and therefore unconsciously manipulates an experiment or misinterprets data in order to find it (see also subject-expectancy effect).</li>
<li>Selective perception, the tendency for expectations to affect perception.</li>
<li>Semmelweis reflex, the tendency to reject new evidence that contradicts a paradigm.</li></ul>
<h3 data-mw-anchor="Egocentric_bias">Egocentric bias</h3>

<p>Egocentric bias is the tendency to rely too heavily on one's own perspective and/or have a different perception of oneself relative to others. The following are forms of egocentric bias:
</p>
<ul><li>Bias blind spot, the tendency to see oneself as less biased than other people, or to be able to identify more cognitive biases in others than in oneself.</li>
<li>False consensus effect, the tendency for people to overestimate the degree to which others agree with them.</li>
<li>False uniqueness bias, the tendency of people to see their projects and themselves as more singular than they actually are.</li>
<li>Forer effect or Barnum effect, the tendency for individuals to give high accuracy ratings to descriptions of their personality that supposedly are tailored specifically for them, but are in fact vague and general enough to apply to a wide range of people. This effect can provide a partial explanation for the widespread acceptance of some beliefs and practices, such as astrology, fortune telling, graphology, and some types of personality tests.</li>
<li>Illusion of asymmetric insight, where people perceive their knowledge of their peers to surpass their peers' knowledge of them.</li>
<li>Illusion of control, the tendency to overestimate one's degree of influence over other external events.</li>
<li>Illusion of transparency, the tendency for people to overestimate the degree to which their personal mental state is known by others, and to overestimate how well they understand others' personal mental states.</li>
<li>Illusion of validity, the tendency to overestimate the accuracy of one's judgments, especially when available information is consistent or inter-correlated.</li>
<li>Illusory superiority, the tendency to overestimate one's desirable qualities, and underestimate undesirable qualities, relative to other people. (Also known as "Lake Wobegon effect", "better-than-average effect", or "superiority bias".)</li>
<li>Naïve cynicism, expecting more egocentric bias in others than in oneself.</li>
<li>Naïve realism, the belief that we see reality as it really is—objectively and without bias; that the facts are plain for all to see; that rational people will agree with us; and that those who do not are either uninformed, lazy, irrational, or biased.</li>
<li>Overconfidence effect, a tendency to have excessive confidence in one's own answers to questions. For example, for certain types of questions, answers that people rate as "99% certain" turn out to be wrong 40% of the time.</li>
<li>Planning fallacy, the tendency for people to underestimate the time it will take them to complete a given task.</li>
<li>Restraint bias, the tendency to overestimate one's ability to show restraint in the face of temptation.</li>
<li>Trait ascription bias, the tendency for people to view themselves as relatively variable in terms of personality, behavior, and mood while viewing others as much more predictable.</li>
<li>Third-person effect, a tendency to believe that mass-communicated media messages have a greater effect on others than on themselves.</li></ul>
<h3 data-mw-anchor="Extension_neglect">Extension neglect</h3>

<p>Extension neglect occurs where the quantity of the sample size is not sufficiently taken into consideration when assessing the outcome, relevance or judgement. The following are forms of extension neglect:
</p>
<ul><li>Base rate fallacy or base rate neglect, the tendency to ignore general information and focus on information only pertaining to the specific case, even when the general information is more important.</li>
<li>Compassion fade, the tendency to behave more compassionately towards a small number of identifiable victims than to a large number of anonymous ones.</li>
<li>Conjunction fallacy, the tendency to assume that specific conditions are more probable than a more general version of those same conditions.</li>
<li>Duration neglect, the neglect of the duration of an episode in determining its value.</li>
<li>Hyperbolic discounting, where discounting is the tendency for people to have a stronger preference for more immediate payoffs relative to later payoffs. Hyperbolic discounting leads to choices that are inconsistent over time—people make choices today that their future selves would prefer not to have made, despite using the same reasoning. Also known as current moment bias or present bias, and related to Dynamic inconsistency. A good example of this is a study showed that when making food choices for the coming week, 74% of participants chose fruit, whereas when the food choice was for the current day, 70% chose chocolate.</li>
<li>Insensitivity to sample size, the tendency to under-expect variation in small samples.</li>
<li>Less-is-better effect, the tendency to prefer a smaller set to a larger set judged separately, but not jointly.</li>
<li>Neglect of probability, the tendency to completely disregard probability when making a decision under uncertainty.</li>
<li>Scope neglect or scope insensitivity, the tendency to be insensitive to the size of a problem when evaluating it. For example, being willing to pay as much to save 2,000 children or 20,000 children.</li>
<li>Zero-risk bias, the preference for reducing a small risk to zero over a greater reduction in a larger risk.</li></ul>
<h3 data-mw-anchor="False_priors">False priors</h3>

<p>False priors are initial beliefs and knowledge which interfere with the unbiased evaluation of factual evidence and lead to incorrect conclusions. Biases based on false priors include:
</p>
<ul><li>Agent detection bias, the inclination to presume the purposeful intervention of a sentient or intelligent agent.</li>
<li>Automation bias, the tendency to depend excessively on automated systems which can lead to erroneous automated information overriding correct decisions.</li>
<li>Gender bias, a widespread set of implicit biases that discriminate against a gender. For example, the assumption that women are less suited to jobs requiring high intellectual ability. Or the assumption that people or animals are male in the absence of any indicators of gender.</li>
<li>Sexual overperception bias, the tendency to overestimate sexual interest of another person in oneself, and sexual underperception bias, the tendency to underestimate it.</li>
<li>Stereotyping, expecting a member of a group to have certain characteristics without having actual information about that individual.</li></ul>
<h3 data-mw-anchor="Framing_effect">Framing effect</h3>

<p>The framing effect is the tendency to draw different conclusions from the same information, depending on how that information is presented. Forms of the framing effect include:
</p>
<ul><li>Contrast effect, the enhancement or reduction of a certain stimulus's perception when compared with a recently observed, contrasting object.</li>
<li>Decoy effect, where preferences for either option A or B change in favor of option B when option C is presented, which is completely dominated by option B (inferior in all respects) and partially dominated by option A.</li>
<li>Default effect, the tendency to favor the default option when given a choice between several options.</li>
<li>Denomination effect, the tendency to spend more money when it is denominated in small amounts (e.g., coins) rather than large amounts (e.g., bills).</li>
<li>Distinction bias, the tendency to view two options as more dissimilar when evaluating them simultaneously than when evaluating them separately.</li>
<li>Domain neglect bias, the tendency to neglect relevant domain knowledge while solving interdisciplinary problems.</li>
<li>Context neglect bias, the tendency to neglect the human context of technological challenges.</li></ul>
<h3 data-mw-anchor="Logical_fallacy">Logical fallacy</h3>

<ul><li>Berkson's paradox, the tendency to misinterpret statistical experiments involving conditional probabilities.</li>
<li>Escalation of commitment, irrational escalation, or sunk cost fallacy, where people justify increased investment in a decision, based on the cumulative prior investment, despite new evidence suggesting that the decision was probably wrong.</li>
<li>G. I. Joe fallacy, the tendency to think that knowing about cognitive bias is enough to overcome it.</li>
<li>Gambler's fallacy, the tendency to think that future probabilities are altered by past events, when in reality they are unchanged. The fallacy arises from an erroneous conceptualization of the law of large numbers. For example, "I've flipped heads with this coin five times consecutively, so the chance of tails coming out on the sixth flip is much greater than heads."</li>
<li>Hot-hand fallacy (also known as "hot hand phenomenon" or "hot hand"), the belief that a person who has experienced success with a random event has a greater chance of further success in additional attempts.</li>
<li>Plan continuation bias, failure to recognize that the original plan of action is no longer appropriate for a changing situation or for a situation that is different from anticipated.</li>
<li>Subadditivity effect, the tendency to judge the probability of the whole to be less than the probabilities of the parts.</li>
<li>Time-saving bias, a tendency to underestimate the time that could be saved (or lost) when increasing (or decreasing) from a relatively low speed, and to overestimate the time that could be saved (or lost) when increasing (or decreasing) from a relatively high speed.</li>
<li>Zero-sum bias, where a situation is incorrectly perceived to be like a zero-sum game (i.e., to be a situation whereby one person gains at the expense of another).</li></ul>
<h3 data-mw-anchor="Prospect_theory">Prospect theory</h3>


<p>The following relate to prospect theory:
</p>
<ul><li>Ambiguity effect, the tendency to avoid options for which the probability of a favorable outcome is unknown.</li>
<li>Disposition effect, the tendency to sell an asset that has accumulated in value and resist selling an asset that has declined in value.</li>
<li>Dread aversion, just as losses yield double the emotional impact of gains, dread yields double the emotional impact of savouring.</li>
<li>Endowment effect, the tendency for people to demand much more to give up an object than they would be willing to pay to acquire it.</li>
<li>Loss aversion, where the perceived disutility of giving up an object is greater than the utility associated with acquiring it. (see also Sunk cost fallacy)</li>
<li>Pseudocertainty effect, the tendency to make risk-averse choices if the expected outcome is positive, but make risk-seeking choices to avoid negative outcomes.</li>
<li>Status quo bias, the tendency to prefer things to stay relatively the same.</li>
<li>System justification, the tendency to defend and bolster the status quo. Existing social, economic, and political arrangements tend to be preferred, and alternatives disparaged, sometimes even at the expense of individual and collective self-interest.</li></ul>
<h3 data-mw-anchor="Self-assessment">Self-assessment</h3>
<ul><li>Dunning–Kruger effect, the tendency for unskilled individuals to overestimate their own ability and the tendency for experts to underestimate their own ability.</li>
<li>Hot-cold empathy gap, the tendency to underestimate the influence of visceral drives on one's attitudes, preferences, and behaviors.</li>
<li>Hard–easy effect, the tendency to overestimate one's ability to accomplish hard tasks, and underestimate one's ability to accomplish easy tasks.</li>
<li>Illusion of explanatory depth, the tendency to believe that one understands a topic much better than one actually does. The effect is strongest for explanatory knowledge, whereas people tend to be better at self-assessments for procedural, narrative, or factual knowledge.</li>
<li>Impostor Syndrome, a psychological occurrence in which an individual doubts their skills, talents, or accomplishments and has a persistent internalized fear of being exposed as a fraud.  Also known as impostor phenomenon.</li>
<li>Objectivity illusion, the phenomena where people tend to believe that they are more objective and unbiased than others. This bias can apply to itself – where people are able to see when others are affected by the objectivity illusion, but unable to see it in themselves. See also <i>bias blind spot.</i></li></ul>
<h3 data-mw-anchor="Truth_judgment">Truth judgment</h3>
<ul><li>Belief bias, an effect where someone's evaluation of the logical strength of an argument is biased by the believability of the conclusion.</li>
<li>Illusory truth effect, the tendency to believe that a statement is true if it is easier to process, or if it has been stated multiple times, regardless of its actual veracity. These are specific cases of truthiness.</li>
<li>Rhyme as reason effect, where rhyming statements are perceived as more truthful.</li>
<li>Subjective validation, where statements are perceived as true if a subject's belief demands it to be true. Also assigns perceived connections between coincidences. (Compare confirmation bias.)</li></ul>
<h3 data-mw-anchor="Other">Other</h3>

<h3 data-mw-anchor="Social">Social</h3>
<h4 data-mw-anchor="Association_fallacy">Association fallacy</h4>

<p>Association fallacies include:
</p>
<ul><li>Authority bias, the tendency to attribute greater accuracy to the opinion of an authority figure (unrelated to its content) and be more influenced by that opinion.</li>
<li>Cheerleader effect, the tendency for people to appear more attractive in a group than in isolation.</li>
<li>Halo effect, the tendency for a person's positive or negative traits to "spill over" from one personality area to another in others' perceptions of them (see also physical attractiveness stereotype).</li></ul>
<h4 data-mw-anchor="Attribution_bias">Attribution bias</h4>

<p>Attribution bias includes:
</p>
<ul><li>Actor-observer bias, the tendency for explanations of other individuals' behaviors to overemphasize the influence of their personality and underemphasize the influence of their situation (see also Fundamental attribution error), and for explanations of one's own behaviors to do the opposite (that is, to overemphasize the influence of our situation and underemphasize the influence of our own personality).</li>
<li>Defensive attribution hypothesis, a tendency to attribute more blame to a harm-doer as the outcome becomes more severe or as personal or situational similarity to the victim decreases.</li>
<li>Extrinsic incentives bias, an exception to the <i>fundamental attribution error</i>, where people view others as having (situational) extrinsic motivations and (dispositional) intrinsic motivations for oneself</li>
<li>Fundamental attribution error, the tendency for people to overemphasize personality-based explanations for behaviors observed in others while under-emphasizing the role and power of situational influences on the same behavior (see also actor-observer bias, group attribution error, positivity effect, and negativity effect).</li>
<li>Group attribution error, the biased belief that the characteristics of an individual group member are reflective of the group as a whole or the tendency to assume that group decision outcomes reflect the preferences of group members, even when information is available that clearly suggests otherwise.</li>
<li>Hostile attribution bias, the tendency to interpret others' behaviors as having hostile intent, even when the behavior is ambiguous or benign.</li>
<li>Intentionality bias, the tendency to judge human action to be intentional rather than accidental.</li>
<li>Just-world fallacy, the tendency for people to want to believe that the world is fundamentally just, causing them to rationalize an otherwise inexplicable injustice as deserved by the victim(s).</li>
<li>Moral luck, the tendency for people to ascribe greater or lesser moral standing based on the outcome of an event.</li>
<li>Puritanical bias, the tendency to attribute cause of an undesirable outcome or wrongdoing by an individual to a moral deficiency or lack of self-control rather than taking into account the impact of broader societal determinants .</li>
<li>Self-serving bias, the tendency to claim more responsibility for successes than failures. It may also manifest itself as a tendency for people to evaluate ambiguous information in a way beneficial to their interests (see also group-serving bias).</li>
<li>Ultimate attribution error, similar to the fundamental attribution error, in this error a person is likely to make an internal attribution to an entire group instead of the individuals within the group.</li></ul>
<h4 data-mw-anchor="Conformity">Conformity</h4>

<p>Conformity is involved in the following:
</p>
<ul><li>Availability cascade, a self-reinforcing process in which a collective belief gains more and more plausibility through its increasing repetition in public discourse (or "repeat something long enough and it will become true"). See also availability heuristic.</li>
<li>Bandwagon effect, the tendency to do (or believe) things because many other people do (or believe) the same. Related to groupthink and herd behavior.</li>
<li><span><span id="Courtesy_bias"></span><span>Courtesy bias</span></span>, the tendency to give an opinion that is more socially correct than one's true opinion, so as to avoid offending anyone.</li>
<li>Groupthink, the psychological phenomenon that occurs within a group of people in which the desire for harmony or conformity in the group results in an irrational or dysfunctional decision-making outcome. Group members try to minimize conflict and reach a consensus decision without critical evaluation of alternative viewpoints by actively suppressing dissenting viewpoints, and by isolating themselves from outside influences.</li>
<li>Groupshift, the tendency for decisions to be more risk-seeking or risk-averse than the group as a whole, if the group is already biased in that direction</li>
<li>Social desirability bias, the tendency to over-report socially desirable characteristics or behaviours in oneself and under-report socially undesirable characteristics or behaviours. See also: § Courtesy bias.</li>
<li>Truth bias is people's inclination towards believing, to some degree, the communication of another person, regardless of whether or not that person is actually lying or being untruthful.</li></ul>
<h4 data-mw-anchor="Ingroup_bias">Ingroup bias</h4>

<p>Ingroup bias is the tendency for people to give preferential treatment to others they perceive to be members of their own groups. It is related to the following:
</p>
<ul><li>Not invented here, an aversion to contact with or use of products, research, standards, or knowledge developed outside a group.</li>
<li>Outgroup homogeneity bias, where individuals see members of other groups as being relatively less varied than members of their own group.</li></ul>
<h4 data-mw-anchor="Other_social_biases">Other social biases</h4>

<h2 data-mw-anchor="Memory">Memory <span id="Memory_biases"></span></h2>
<p>In psychology and cognitive science, a memory bias is a cognitive bias that either enhances or impairs the recall of a memory (either the chances that the memory will be recalled at all, or the amount of time it takes for it to be recalled, or both), or that alters the content of a reported memory. There are many types of memory bias, including:
</p>
<h3 data-mw-anchor="Misattribution_of_memory">Misattribution of memory</h3>


<p>The misattributions include:
</p>
<ul><li>Cryptomnesia, where a memory is mistaken for novel thought or imagination, because there is no subjective experience of it being a memory.</li>
<li>False memory, where imagination is mistaken for a memory.</li>
<li>Social cryptomnesia, a failure by people and society in general to remember the origin of a change, in which people know that a change has occurred in society, but forget how this change occurred; that is, the steps that were taken to bring this change about, and who took these steps. This has led to reduced social credit towards the minorities who made major sacrifices that led to a change in societal values.</li>
<li>Source confusion, episodic memories are confused with other information, creating distorted memories.</li>
<li>Suggestibility, where ideas suggested by a questioner are mistaken for memory.</li>
<li>The Perky effect, where real images can influence imagined images, or be misremembered as imagined rather than real</li></ul>
<h3 data-mw-anchor="Other_memory_biases">Other memory biases</h3>

<h2 data-mw-anchor="See_also">See also</h2>


<h2 data-mw-anchor="Footnotes">Footnotes</h2>

<h2 data-mw-anchor="References">References</h2>

<h2 data-mw-anchor="Further_reading">Further reading</h2>

<h2 data-mw-anchor="External_links">External links</h2>
<ul><li><span typeof="mw:File"></span> Media related to Memory biases at Wikimedia Commons</li></ul></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/List_of_cognitive_biases#Suffix_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Levels–of–processing effect</h2>
<a href='https://en.wikipedia.org/wiki/Levels-of-processing_effect' target='_blank'>Wikipedia Link</a>
<div class='content'></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Levels-of-processing_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Absent–mindedness</h2>
<a href='https://en.wikipedia.org/wiki/Absent-mindedness' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Absent-mindedness</b> is a mental state wherein a person is forgetfully inattentive. It is the opposite mental state of mindfulness.
</p><p>Absent-mindedness is often caused by things such as boredom, sleepiness, rumination, distraction, or preoccupation with one's own internal monologue. When experiencing absent-mindedness, people exhibit signs of memory lapses and weak recollection of recent events.
</p><p>Absent-mindedness can usually be a result of a variety of other conditions often diagnosed by clinicians such as attention deficit hyperactivity disorder (ADHD) and depression. In addition to absent-mindedness leading to an array of consequences affecting daily life, it can have more severe, long-term problems.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Absent-mindedness'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Testing effect</h2>
<a href='https://en.wikipedia.org/wiki/Testing_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>testing effect</b> (also known as <b>retrieval practice</b>, <b>active recall</b>, <b>practice testing</b>, or <b>test-enhanced learning</b>) suggests long-term memory is increased when part of the learning period is devoted to retrieving information from memory. It is different from the more general <i>practice effect</i>, defined in the APA Dictionary of Psychology as "any change or improvement that results from practice or repetition of task items or activities."
</p><p>Cognitive psychologists are working with educators to look at how to take advantage of tests—not as an assessment tool, but as a teaching tool  since testing prior knowledge is more beneficial for learning when compared to only reading or passively studying material (even more so when the test is more challenging for memory).
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Testing_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Next–in–line effect</h2>
<a href='https://en.wikipedia.org/wiki/Next-in-line_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>next-in-line effect</b> is the phenomenon of people being unable to recall information concerning events immediately preceding their turn to perform.
</p><p>The effect was first studied experimentally by Malcolm Brenner in 1973. In his experiment the participants were each in turn reading a word aloud from an index card, and after 25 words were asked to recall as many of all the read words as possible. The results of the experiment showed that words read aloud within approximately nine seconds before the subject's own turn were recalled worse than other words.
</p><p>The reason for the next-in-line effect appears to be a deficit in encoding the perceived information preceding a performance. That is, the information is never stored to long-term memory and thus cannot be retrieved later after the performance. One finding supporting this theory is that asking the subjects beforehand to pay more attention to events preceding their turn to perform can prevent the memory deficit and even result in overcompensation, making people remember the events before their turn better than others.
</p><p>In addition, the appearance of the next-in-line effect does not seem to be connected to the level of fear of negative evaluation. Both people with lower and higher anxiety levels are subject to the memory deficit.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Next-in-line_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Google effect</h2>
<a href='https://en.wikipedia.org/wiki/Google_effect' target='_blank'>Wikipedia Link</a>
<div class='content'><p>The <b>Google effect</b>, also called <b>digital amnesia</b>, is the tendency to forget information that can be found readily online by using Internet search engines. According to the first study about the Google effect, people are less likely to remember certain details they believe will be accessible online. However, the study also claims that people's ability to learn information offline remains the same. This effect may also be seen as a change to what information and what level of detail is considered to be important to remember.
</p></div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Google_effect'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
<div class='bias'>
<h2>Tip of the tongue phenomenon</h2>
<a href='https://en.wikipedia.org/wiki/Tip_of_the_tongue' target='_blank'>Wikipedia Link</a>
<div class='content'><p><b>Tip of the tongue</b> (also known as <b>TOT</b>, or <b>lethologica</b>) is the phenomenon of failing to retrieve a word or term from memory, combined with partial recall and the feeling that retrieval is imminent. The phenomenon's name comes from the saying, "It's on the tip of my tongue." The tip of the tongue phenomenon reveals that lexical access occurs in stages.
</p><p>People experiencing the tip-of-the-tongue phenomenon can often recall one or more <span><span id="features"></span><span>features</span></span> of the target word, such as the first letter, its syllabic stress, and words similar in sound, meaning, or both sound and meaning. Individuals report a feeling of being seized by the state, feeling something like mild anguish while searching for the word, and a sense of relief when the word is found. While many aspects of the tip-of-the-tongue state remain unclear, there are two major competing explanations for its occurrence: the <i>direct-access view</i> and the <i>inferential view</i>. Emotion and the strength of the emotional ties to what is trying to be remembered can also have an impact on the TOT phenomenon. The stronger the emotional ties, the longer it takes to retrieve the item from memory.
</p><p>TOT states should be distinguished from <b>FOK</b> (<b>feeling of knowing</b>) states. FOK, in contrast, is the feeling that one will be able to recognize⁠—from a list of items⁠—an item that is currently inaccessible. There are still currently opposing hypotheses in the psychological literature regarding the separability of the process underlying these concepts. However, there is some evidence that TOTs and FOKs draw on different parts of the brain. TOTs are associated with the anterior cingulate, right dorsolateral prefrontal cortex, and right inferior cortex while FOKs are not. FOKs can be assessed through memory-monitoring testing in which a test subject is asked to "estimate the likelihood" of recognizing when "prompted with a cue" or information that they previously failed to remember. This test aims to measure a test subject's accuracy of memory monitoring during the "memory extraction stage".
</p><p>An occasional tip-of-the-tongue state is normal for people of all ages; however, it becomes more frequent as people age. TOT can be referred as an actual medical condition, but only when it becomes frequent enough to interfere with learning or daily life. This disorder is called anomic aphasia when acquired by brain damage, usually from a head injury, stroke, or dementia.
</p><p>The tip of the tongue phenomenon has implications for research in psycholinguistics, memory, and metacognition.
</p>

</div>
<div class='attribution'>Content from <a href='https://en.wikipedia.org/wiki/Tip_of_the_tongue'>Wikipedia</a>, licensed under <a href='https://creativecommons.org/licenses/by-sa/3.0/'>CC BY-SA 3.0</a></div>
</div>
</body></html>
